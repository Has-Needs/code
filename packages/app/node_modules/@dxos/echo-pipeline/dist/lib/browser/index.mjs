import "@dxos/node-std/globals";
import {
  filterMatchObject,
  filterMatchValue
} from "./chunk-TQJTKNMS.mjs";
import {
  AuthExtension,
  AuthStatus,
  CredentialRetrieverExtension,
  CredentialServerExtension,
  MOCK_AUTH_PROVIDER,
  MOCK_AUTH_VERIFIER,
  MetadataStore,
  Pipeline,
  Space,
  SpaceManager,
  SpaceProtocol,
  SpaceProtocolSession,
  TimeframeClock,
  codec,
  createIdFromSpaceKey,
  createMappedFeedWriter,
  hasInvitationExpired,
  mapFeedIndexesToTimeframe,
  mapTimeframeToFeedIndexes,
  startAfter,
  valueEncoding
} from "./chunk-35I6ERLG.mjs";
import "./chunk-CGS2ULMK.mjs";

// packages/core/echo/echo-pipeline/src/db-host/data-service.ts
import { UpdateScheduler as UpdateScheduler2 } from "@dxos/async";
import { Stream } from "@dxos/codec-protobuf/stream";
import { invariant as invariant7 } from "@dxos/invariant";
import { SpaceId as SpaceId2 } from "@dxos/keys";
import { log as log7 } from "@dxos/log";

// packages/core/echo/echo-pipeline/src/db-host/documents-synchronizer.ts
import { next as A2 } from "@automerge/automerge";
import { UpdateScheduler } from "@dxos/async";
import { Resource as Resource5 } from "@dxos/context";
import { invariant as invariant6 } from "@dxos/invariant";
import { log as log6 } from "@dxos/log";

// packages/core/echo/echo-pipeline/src/automerge/automerge-host.ts
import { getBackend, getHeads, isAutomerge, equals as headsEquals, save } from "@automerge/automerge";
import { Repo, interpretAsDocumentId } from "@automerge/automerge-repo";
import { Event as Event2, asyncTimeout } from "@dxos/async";
import { Context, Resource as Resource3, cancelWithContext } from "@dxos/context";
import { DatabaseDirectory } from "@dxos/echo-protocol";
import { invariant as invariant2 } from "@dxos/invariant";
import { PublicKey } from "@dxos/keys";
import { log as log3 } from "@dxos/log";
import { objectPointerCodec } from "@dxos/protocols";
import { trace as trace2 } from "@dxos/tracing";
import { bufferToArray } from "@dxos/util";

// packages/core/echo/echo-pipeline/src/automerge/collection-synchronizer.ts
import { next as am } from "@automerge/automerge";
import { asyncReturn, Event, scheduleTask, scheduleTaskInterval } from "@dxos/async";
import { Resource } from "@dxos/context";
import { log } from "@dxos/log";
import { trace } from "@dxos/tracing";
import { defaultMap } from "@dxos/util";
function _ts_decorate(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/automerge/collection-synchronizer.ts";
var MIN_QUERY_INTERVAL = 5e3;
var POLL_INTERVAL = 3e4;
var CollectionSynchronizer = class extends Resource {
  constructor(params) {
    super();
    /**
    * CollectionId -> State.
    */
    this._perCollectionStates = /* @__PURE__ */ new Map();
    this._activeCollections = /* @__PURE__ */ new Set();
    this._connectedPeers = /* @__PURE__ */ new Set();
    this.remoteStateUpdated = new Event();
    this._sendCollectionState = params.sendCollectionState;
    this._queryCollectionState = params.queryCollectionState;
    this._shouldSyncCollection = params.shouldSyncCollection;
  }
  async _open(ctx) {
    scheduleTaskInterval(this._ctx, async () => {
      for (const collectionId of this._perCollectionStates.keys()) {
        if (this._activeCollections.has(collectionId)) {
          this.refreshCollection(collectionId);
          await asyncReturn();
        }
      }
    }, POLL_INTERVAL);
  }
  getRegisteredCollectionIds() {
    return [
      ...this._activeCollections
    ];
  }
  getLocalCollectionState(collectionId) {
    return this._perCollectionStates.get(collectionId)?.localState;
  }
  setLocalCollectionState(collectionId, state) {
    this._activeCollections.add(collectionId);
    log("setLocalCollectionState", {
      collectionId,
      state
    }, {
      F: __dxlog_file,
      L: 76,
      S: this,
      C: (f, a) => f(...a)
    });
    this._getOrCreatePerCollectionState(collectionId).localState = state;
    queueMicrotask(async () => {
      if (!this._ctx.disposed && this._activeCollections.has(collectionId)) {
        this._refreshInterestedPeers(collectionId);
        this.refreshCollection(collectionId);
      }
    });
  }
  clearLocalCollectionState(collectionId) {
    this._activeCollections.delete(collectionId);
    this._perCollectionStates.delete(collectionId);
    log("clearLocalCollectionState", {
      collectionId
    }, {
      F: __dxlog_file,
      L: 90,
      S: this,
      C: (f, a) => f(...a)
    });
  }
  getRemoteCollectionStates(collectionId) {
    return this._getOrCreatePerCollectionState(collectionId).remoteStates;
  }
  refreshCollection(collectionId) {
    let scheduleAnotherRefresh = false;
    const state = this._getOrCreatePerCollectionState(collectionId);
    for (const peerId of this._connectedPeers) {
      if (state.interestedPeers.has(peerId)) {
        const lastQueried = state.lastQueried.get(peerId) ?? 0;
        if (Date.now() - lastQueried > MIN_QUERY_INTERVAL) {
          state.lastQueried.set(peerId, Date.now());
          this._queryCollectionState(collectionId, peerId);
        } else {
          scheduleAnotherRefresh = true;
        }
      }
    }
    if (scheduleAnotherRefresh) {
      scheduleTask(this._ctx, () => this.refreshCollection(collectionId), MIN_QUERY_INTERVAL);
    }
  }
  /**
  * Callback when a connection to a peer is established.
  */
  onConnectionOpen(peerId) {
    const spanId = getSpanName(peerId);
    trace.spanStart({
      id: spanId,
      methodName: spanId,
      instance: this,
      parentCtx: this._ctx,
      showInBrowserTimeline: true,
      attributes: {
        peerId
      }
    });
    this._connectedPeers.add(peerId);
    queueMicrotask(async () => {
      if (this._ctx.disposed) {
        return;
      }
      for (const [collectionId, state] of this._perCollectionStates.entries()) {
        if (this._activeCollections.has(collectionId) && this._shouldSyncCollection(collectionId, peerId)) {
          state.interestedPeers.add(peerId);
          state.lastQueried.set(peerId, Date.now());
          this._queryCollectionState(collectionId, peerId);
        }
      }
    });
  }
  /**
  * Callback when a connection to a peer is closed.
  */
  onConnectionClosed(peerId) {
    this._connectedPeers.delete(peerId);
    for (const perCollectionState of this._perCollectionStates.values()) {
      perCollectionState.remoteStates.delete(peerId);
    }
  }
  /**
  * Callback when a peer queries the state of a collection.
  */
  onCollectionStateQueried(collectionId, peerId) {
    const perCollectionState = this._getOrCreatePerCollectionState(collectionId);
    if (perCollectionState.localState) {
      this._sendCollectionState(collectionId, peerId, perCollectionState.localState);
    }
  }
  /**
  * Callback when a peer sends the state of a collection.
  */
  onRemoteStateReceived(collectionId, peerId, state) {
    log("onRemoteStateReceived", {
      collectionId,
      peerId,
      state
    }, {
      F: __dxlog_file,
      L: 171,
      S: this,
      C: (f, a) => f(...a)
    });
    validateCollectionState(state);
    const perCollectionState = this._getOrCreatePerCollectionState(collectionId);
    const existingState = perCollectionState.remoteStates.get(peerId) ?? {
      documents: {}
    };
    const diff = diffCollectionState(existingState, state);
    const spanId = getSpanName(peerId);
    if (diff.different.length === 0) {
      trace.spanEnd(spanId);
    } else {
      trace.spanStart({
        id: spanId,
        methodName: spanId,
        instance: this,
        parentCtx: this._ctx,
        showInBrowserTimeline: true,
        attributes: {
          peerId
        }
      });
    }
    if (diff.missingOnLocal.length > 0 || diff.different.length > 0) {
      perCollectionState.remoteStates.set(peerId, state);
      this.remoteStateUpdated.emit({
        peerId,
        collectionId,
        newDocsAppeared: diff.missingOnLocal.length > 0
      });
    }
  }
  _getOrCreatePerCollectionState(collectionId) {
    return defaultMap(this._perCollectionStates, collectionId, () => ({
      localState: void 0,
      remoteStates: /* @__PURE__ */ new Map(),
      interestedPeers: /* @__PURE__ */ new Set(),
      lastQueried: /* @__PURE__ */ new Map()
    }));
  }
  _refreshInterestedPeers(collectionId) {
    for (const peerId of this._connectedPeers) {
      if (this._shouldSyncCollection(collectionId, peerId)) {
        this._getOrCreatePerCollectionState(collectionId).interestedPeers.add(peerId);
      } else {
        this._getOrCreatePerCollectionState(collectionId).interestedPeers.delete(peerId);
      }
    }
  }
};
CollectionSynchronizer = _ts_decorate([
  trace.resource()
], CollectionSynchronizer);
var diffCollectionState = (local, remote) => {
  const allDocuments = /* @__PURE__ */ new Set([
    ...Object.keys(local.documents),
    ...Object.keys(remote.documents)
  ]);
  const missingOnRemote = [];
  const missingOnLocal = [];
  const different = [];
  for (const documentId of allDocuments) {
    if (!local.documents[documentId]) {
      missingOnLocal.push(documentId);
    } else if (!remote.documents[documentId]) {
      missingOnRemote.push(documentId);
    } else if (!am.equals(local.documents[documentId], remote.documents[documentId])) {
      different.push(documentId);
    }
  }
  return {
    missingOnRemote,
    missingOnLocal,
    different
  };
};
var validateCollectionState = (state) => {
  Object.entries(state.documents).forEach(([documentId, heads]) => {
    if (!isValidDocumentId(documentId)) {
      throw new Error(`Invalid documentId: ${documentId}`);
    }
    if (Array.isArray(heads) && heads.some((head) => typeof head !== "string")) {
      throw new Error(`Invalid heads: ${heads}`);
    }
  });
};
var isValidDocumentId = (documentId) => {
  return typeof documentId === "string" && !documentId.includes(":");
};
var getSpanName = (peerId) => {
  return `collection-sync-${peerId}`;
};

// packages/core/echo/echo-pipeline/src/automerge/echo-network-adapter.ts
import { NetworkAdapter } from "@automerge/automerge-repo";
import { synchronized, Trigger } from "@dxos/async";
import { LifecycleState } from "@dxos/context";
import { invariant } from "@dxos/invariant";
import { log as log2 } from "@dxos/log";
import { isNonNullable } from "@dxos/util";

// packages/core/echo/echo-pipeline/src/automerge/network-protocol.ts
import { MESSAGE_TYPE_COLLECTION_QUERY, MESSAGE_TYPE_COLLECTION_STATE } from "@dxos/protocols";
var isCollectionQueryMessage = (message) => message.type === MESSAGE_TYPE_COLLECTION_QUERY;
var isCollectionStateMessage = (message) => message.type === MESSAGE_TYPE_COLLECTION_STATE;

// packages/core/echo/echo-pipeline/src/automerge/echo-network-adapter.ts
function _ts_decorate2(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file2 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/automerge/echo-network-adapter.ts";
var EchoNetworkAdapter = class extends NetworkAdapter {
  constructor(_params) {
    super(), this._params = _params, this._replicators = /* @__PURE__ */ new Set(), this._connections = /* @__PURE__ */ new Map(), this._lifecycleState = LifecycleState.CLOSED, this._connected = new Trigger(), this._ready = new Trigger();
  }
  isReady() {
    return this._lifecycleState === LifecycleState.OPEN;
  }
  whenReady() {
    return this._ready.wait();
  }
  connect(peerId, peerMetadata) {
    this.peerId = peerId;
    this.peerMetadata = peerMetadata;
    this._connected.wake();
  }
  send(message) {
    this._send(message);
  }
  disconnect() {
  }
  async open() {
    if (this._lifecycleState === LifecycleState.OPEN) {
      return;
    }
    this._lifecycleState = LifecycleState.OPEN;
    this._ready.wake();
  }
  async close() {
    if (this._lifecycleState === LifecycleState.CLOSED) {
      return this;
    }
    for (const replicator of this._replicators) {
      await replicator.disconnect();
    }
    this._replicators.clear();
    this._ready.reset();
    this._lifecycleState = LifecycleState.CLOSED;
  }
  async whenConnected() {
    await this._connected.wait({
      timeout: 1e4
    });
  }
  onConnectionAuthScopeChanged(peer) {
    const entry = this._connections.get(peer);
    if (entry) {
      this._onConnectionAuthScopeChanged(entry.connection);
    }
  }
  async addReplicator(replicator) {
    invariant(this._lifecycleState === LifecycleState.OPEN, void 0, {
      F: __dxlog_file2,
      L: 129,
      S: this,
      A: [
        "this._lifecycleState === LifecycleState.OPEN",
        ""
      ]
    });
    invariant(this.peerId, void 0, {
      F: __dxlog_file2,
      L: 130,
      S: this,
      A: [
        "this.peerId",
        ""
      ]
    });
    invariant(!this._replicators.has(replicator), void 0, {
      F: __dxlog_file2,
      L: 131,
      S: this,
      A: [
        "!this._replicators.has(replicator)",
        ""
      ]
    });
    this._replicators.add(replicator);
    await replicator.connect({
      peerId: this.peerId,
      onConnectionOpen: this._onConnectionOpen.bind(this),
      onConnectionClosed: this._onConnectionClosed.bind(this),
      onConnectionAuthScopeChanged: this._onConnectionAuthScopeChanged.bind(this),
      isDocumentInRemoteCollection: this._params.isDocumentInRemoteCollection,
      getContainingSpaceForDocument: this._params.getContainingSpaceForDocument,
      getContainingSpaceIdForDocument: async (documentId) => {
        const key = await this._params.getContainingSpaceForDocument(documentId);
        return key ? createIdFromSpaceKey(key) : null;
      }
    });
  }
  async removeReplicator(replicator) {
    invariant(this._lifecycleState === LifecycleState.OPEN, void 0, {
      F: __dxlog_file2,
      L: 150,
      S: this,
      A: [
        "this._lifecycleState === LifecycleState.OPEN",
        ""
      ]
    });
    invariant(this._replicators.has(replicator), void 0, {
      F: __dxlog_file2,
      L: 151,
      S: this,
      A: [
        "this._replicators.has(replicator)",
        ""
      ]
    });
    await replicator.disconnect();
    this._replicators.delete(replicator);
  }
  async shouldAdvertise(peerId, params) {
    const connection = this._connections.get(peerId);
    if (!connection) {
      return false;
    }
    return connection.connection.shouldAdvertise(params);
  }
  shouldSyncCollection(peerId, params) {
    const connection = this._connections.get(peerId);
    if (!connection) {
      return false;
    }
    return connection.connection.shouldSyncCollection(params);
  }
  queryCollectionState(collectionId, targetId) {
    const message = {
      type: "collection-query",
      senderId: this.peerId,
      targetId,
      collectionId
    };
    this._send(message);
  }
  sendCollectionState(collectionId, targetId, state) {
    const message = {
      type: "collection-state",
      senderId: this.peerId,
      targetId,
      collectionId,
      state
    };
    this._send(message);
  }
  // TODO(dmaretskyi): Remove.
  getPeersInterestedInCollection(collectionId) {
    return Array.from(this._connections.values()).map((connection) => {
      return connection.connection.shouldSyncCollection({
        collectionId
      }) ? connection.connection.peerId : null;
    }).filter(isNonNullable);
  }
  _send(message) {
    const connectionEntry = this._connections.get(message.targetId);
    if (!connectionEntry) {
      throw new Error("Connection not found.");
    }
    const start = Date.now();
    connectionEntry.writer.write(message).then(() => {
      this._params.monitor?.recordMessageSent(message, Date.now() - start);
    }).catch((err) => {
      if (connectionEntry.isOpen) {
        log2.catch(err, void 0, {
          F: __dxlog_file2,
          L: 221,
          S: this,
          C: (f, a) => f(...a)
        });
      }
      this._params.monitor?.recordMessageSendingFailed(message);
    });
  }
  _onConnectionOpen(connection) {
    log2("connection opened", {
      peerId: connection.peerId
    }, {
      F: __dxlog_file2,
      L: 229,
      S: this,
      C: (f, a) => f(...a)
    });
    invariant(!this._connections.has(connection.peerId), void 0, {
      F: __dxlog_file2,
      L: 230,
      S: this,
      A: [
        "!this._connections.has(connection.peerId as PeerId)",
        ""
      ]
    });
    const connectionEntry = {
      isOpen: true,
      connection,
      reader: connection.readable.getReader(),
      writer: connection.writable.getWriter()
    };
    this._connections.set(connection.peerId, connectionEntry);
    queueMicrotask(async () => {
      try {
        while (true) {
          const { done, value } = await connectionEntry.reader.read();
          if (done) {
            break;
          }
          this._onMessage(value);
        }
      } catch (err) {
        if (connectionEntry.isOpen) {
          log2.catch(err, void 0, {
            F: __dxlog_file2,
            L: 254,
            S: this,
            C: (f, a) => f(...a)
          });
        }
      }
    });
    log2("emit peer-candidate", {
      peerId: connection.peerId
    }, {
      F: __dxlog_file2,
      L: 259,
      S: this,
      C: (f, a) => f(...a)
    });
    this._emitPeerCandidate(connection);
    this._params.monitor?.recordPeerConnected(connection.peerId);
  }
  _onMessage(message) {
    if (isCollectionQueryMessage(message)) {
      this._params.onCollectionStateQueried(message.collectionId, message.senderId);
    } else if (isCollectionStateMessage(message)) {
      this._params.onCollectionStateReceived(message.collectionId, message.senderId, message.state);
    } else {
      this.emit("message", message);
    }
    this._params.monitor?.recordMessageReceived(message);
  }
  _onConnectionClosed(connection) {
    log2("connection closed", {
      peerId: connection.peerId
    }, {
      F: __dxlog_file2,
      L: 276,
      S: this,
      C: (f, a) => f(...a)
    });
    const entry = this._connections.get(connection.peerId);
    invariant(entry, void 0, {
      F: __dxlog_file2,
      L: 278,
      S: this,
      A: [
        "entry",
        ""
      ]
    });
    entry.isOpen = false;
    this.emit("peer-disconnected", {
      peerId: connection.peerId
    });
    this._params.monitor?.recordPeerDisconnected(connection.peerId);
    void entry.reader.cancel().catch((err) => log2.catch(err, void 0, {
      F: __dxlog_file2,
      L: 284,
      S: this,
      C: (f, a) => f(...a)
    }));
    void entry.writer.abort().catch((err) => log2.catch(err, void 0, {
      F: __dxlog_file2,
      L: 285,
      S: this,
      C: (f, a) => f(...a)
    }));
    this._connections.delete(connection.peerId);
  }
  /**
  * Trigger doc-synchronizer shared documents set recalculation. Happens on peer-candidate.
  * TODO(y): replace with a proper API call when sharePolicy update becomes supported by automerge-repo
  */
  _onConnectionAuthScopeChanged(connection) {
    log2("Connection auth scope changed", {
      peerId: connection.peerId
    }, {
      F: __dxlog_file2,
      L: 294,
      S: this,
      C: (f, a) => f(...a)
    });
    const entry = this._connections.get(connection.peerId);
    invariant(entry, void 0, {
      F: __dxlog_file2,
      L: 296,
      S: this,
      A: [
        "entry",
        ""
      ]
    });
    this.emit("peer-disconnected", {
      peerId: connection.peerId
    });
    this._emitPeerCandidate(connection);
  }
  _emitPeerCandidate(connection) {
    this.emit("peer-candidate", {
      peerId: connection.peerId,
      peerMetadata: createEchoPeerMetadata()
    });
  }
};
_ts_decorate2([
  synchronized
], EchoNetworkAdapter.prototype, "open", null);
_ts_decorate2([
  synchronized
], EchoNetworkAdapter.prototype, "close", null);
_ts_decorate2([
  synchronized
], EchoNetworkAdapter.prototype, "addReplicator", null);
_ts_decorate2([
  synchronized
], EchoNetworkAdapter.prototype, "removeReplicator", null);
var createEchoPeerMetadata = () => ({
  // TODO(dmaretskyi): Refactor this.
  dxos_peerSource: "EchoNetworkAdapter"
});
var isEchoPeerMetadata = (metadata) => metadata?.dxos_peerSource === "EchoNetworkAdapter";

// packages/core/echo/echo-pipeline/src/automerge/heads-store.ts
import { headsEncoding } from "@dxos/indexing";
var HeadsStore = class {
  constructor({ db }) {
    this._db = db;
  }
  setHeads(documentId, heads, batch) {
    batch.put(documentId, heads, {
      sublevel: this._db,
      keyEncoding: "utf8",
      valueEncoding: headsEncoding
    });
  }
  // TODO(dmaretskyi): Make batched.
  async getHeads(documentIds) {
    return this._db.getMany(documentIds, {
      keyEncoding: "utf8",
      valueEncoding: headsEncoding
    });
  }
};

// packages/core/echo/echo-pipeline/src/automerge/leveldb-storage-adapter.ts
import { LifecycleState as LifecycleState2, Resource as Resource2 } from "@dxos/context";
var LevelDBStorageAdapter = class extends Resource2 {
  constructor(_params) {
    super(), this._params = _params;
  }
  async load(keyArray) {
    try {
      if (this._lifecycleState !== LifecycleState2.OPEN) {
        return void 0;
      }
      const startMs = Date.now();
      const chunk = await this._params.db.get(keyArray, {
        ...encodingOptions
      });
      this._params.monitor?.recordBytesLoaded(chunk.byteLength);
      this._params.monitor?.recordLoadDuration(Date.now() - startMs);
      return chunk;
    } catch (err) {
      if (isLevelDbNotFoundError(err)) {
        return void 0;
      }
      throw err;
    }
  }
  async save(keyArray, binary) {
    if (this._lifecycleState !== LifecycleState2.OPEN) {
      return void 0;
    }
    const startMs = Date.now();
    const batch = this._params.db.batch();
    await this._params.callbacks?.beforeSave?.({
      path: keyArray,
      batch
    });
    batch.put(keyArray, Buffer.from(binary), {
      ...encodingOptions
    });
    await batch.write();
    this._params.monitor?.recordBytesStored(binary.byteLength);
    await this._params.callbacks?.afterSave?.(keyArray);
    this._params.monitor?.recordStoreDuration(Date.now() - startMs);
  }
  async remove(keyArray) {
    if (this._lifecycleState !== LifecycleState2.OPEN) {
      return void 0;
    }
    await this._params.db.del(keyArray, {
      ...encodingOptions
    });
  }
  async loadRange(keyPrefix) {
    if (this._lifecycleState !== LifecycleState2.OPEN) {
      return [];
    }
    const startMs = Date.now();
    const result = [];
    for await (const [key, value] of this._params.db.iterator({
      gte: keyPrefix,
      lte: [
        ...keyPrefix,
        "\uFFFF"
      ],
      ...encodingOptions
    })) {
      result.push({
        key,
        data: value
      });
      this._params.monitor?.recordBytesLoaded(value.byteLength);
    }
    this._params.monitor?.recordLoadDuration(Date.now() - startMs);
    return result;
  }
  async removeRange(keyPrefix) {
    if (this._lifecycleState !== LifecycleState2.OPEN) {
      return void 0;
    }
    const batch = this._params.db.batch();
    for await (const [key] of this._params.db.iterator({
      gte: keyPrefix,
      lte: [
        ...keyPrefix,
        "\uFFFF"
      ],
      ...encodingOptions
    })) {
      batch.del(key, {
        ...encodingOptions
      });
    }
    await batch.write();
  }
};
var keyEncoder = {
  encode: (key) => Buffer.from(key.map((k) => k.replaceAll("%", "%25").replaceAll("-", "%2D")).join("-")),
  decode: (key) => Buffer.from(key).toString().split("-").map((k) => k.replaceAll("%2D", "-").replaceAll("%25", "%")),
  format: "buffer"
};
var encodingOptions = {
  keyEncoding: keyEncoder,
  valueEncoding: "buffer"
};
var isLevelDbNotFoundError = (err) => err.code === "LEVEL_NOT_FOUND";

// packages/core/echo/echo-pipeline/src/automerge/automerge-host.ts
function _ts_decorate3(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file3 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/automerge/automerge-host.ts";
var FIND_PARAMS = {
  allowableStates: [
    "ready",
    "requesting"
  ]
};
var AutomergeHost = class extends Resource3 {
  constructor({ db, indexMetadataStore, dataMonitor, peerIdProvider, getSpaceKeyByRootDocumentId }) {
    super();
    this._collectionSynchronizer = new CollectionSynchronizer({
      queryCollectionState: this._queryCollectionState.bind(this),
      sendCollectionState: this._sendCollectionState.bind(this),
      shouldSyncCollection: this._shouldSyncCollection.bind(this)
    });
    this.collectionStateUpdated = new Event2();
    /**
    * Fired after a batch of documents was saved to disk.
    */
    this.documentsSaved = new Event2();
    this._db = db;
    this._storage = new LevelDBStorageAdapter({
      db: db.sublevel("automerge"),
      callbacks: {
        beforeSave: async (params) => this._beforeSave(params),
        afterSave: async (key) => this._afterSave(key)
      },
      monitor: dataMonitor
    });
    this._echoNetworkAdapter = new EchoNetworkAdapter({
      getContainingSpaceForDocument: this._getContainingSpaceForDocument.bind(this),
      isDocumentInRemoteCollection: this._isDocumentInRemoteCollection.bind(this),
      onCollectionStateQueried: this._onCollectionStateQueried.bind(this),
      onCollectionStateReceived: this._onCollectionStateReceived.bind(this),
      monitor: dataMonitor
    });
    this._headsStore = new HeadsStore({
      db: db.sublevel("heads")
    });
    this._indexMetadataStore = indexMetadataStore;
    this._peerIdProvider = peerIdProvider;
    this._getSpaceKeyByRootDocumentId = getSpaceKeyByRootDocumentId;
  }
  async _open() {
    this._peerId = `host-${this._peerIdProvider?.() ?? PublicKey.random().toHex()}`;
    await this._storage.open?.();
    this._repo = new Repo({
      peerId: this._peerId,
      sharePolicy: this._sharePolicy.bind(this),
      storage: this._storage,
      network: [
        // Upstream swarm.
        this._echoNetworkAdapter
      ]
    });
    let updatingAuthScope = false;
    Event2.wrap(this._echoNetworkAdapter, "peer-candidate").on(this._ctx, (e) => !updatingAuthScope && this._onPeerConnected(e.peerId));
    Event2.wrap(this._echoNetworkAdapter, "peer-disconnected").on(this._ctx, (e) => !updatingAuthScope && this._onPeerDisconnected(e.peerId));
    this._collectionSynchronizer.remoteStateUpdated.on(this._ctx, ({ collectionId, peerId, newDocsAppeared }) => {
      this._onRemoteCollectionStateUpdated(collectionId, peerId);
      this.collectionStateUpdated.emit({
        collectionId
      });
      if (newDocsAppeared) {
        updatingAuthScope = true;
        try {
          this._echoNetworkAdapter.onConnectionAuthScopeChanged(peerId);
        } finally {
          updatingAuthScope = false;
        }
      }
    });
    await this._echoNetworkAdapter.open();
    await this._collectionSynchronizer.open();
    await this._echoNetworkAdapter.open();
    await this._echoNetworkAdapter.whenConnected();
  }
  async _close() {
    await this._collectionSynchronizer.close();
    await this._storage.close?.();
    await this._echoNetworkAdapter.close();
    await this._ctx.dispose();
  }
  /**
  * @deprecated To be abstracted away.
  */
  get repo() {
    return this._repo;
  }
  get peerId() {
    return this._peerId;
  }
  get loadedDocsCount() {
    return Object.keys(this._repo.handles).length;
  }
  async addReplicator(replicator) {
    await this._echoNetworkAdapter.addReplicator(replicator);
  }
  async removeReplicator(replicator) {
    await this._echoNetworkAdapter.removeReplicator(replicator);
  }
  /**
  * Loads the document handle from the repo and waits for it to be ready.
  */
  async loadDoc(ctx, documentId, opts) {
    let handle;
    if (typeof documentId === "string") {
      handle = this._repo.handles[documentId];
    }
    if (!handle) {
      handle = await this._repo.find(documentId, FIND_PARAMS);
    }
    if (!handle.isReady()) {
      if (!opts?.timeout) {
        await cancelWithContext(ctx, handle.whenReady());
      } else {
        await cancelWithContext(ctx, asyncTimeout(handle.whenReady(), opts.timeout));
      }
    }
    return handle;
  }
  async exportDoc(ctx, id) {
    const documentId = interpretAsDocumentId(id);
    const chunks = await this._storage.loadRange([
      documentId
    ]);
    return bufferToArray(Buffer.concat(chunks.map((c) => c.data)));
  }
  /**
  * Create new persisted document.
  */
  createDoc(initialValue, opts) {
    if (opts?.preserveHistory) {
      if (initialValue instanceof Uint8Array) {
        return this._repo.import(initialValue);
      }
      if (!isAutomerge(initialValue)) {
        throw new TypeError("Initial value must be an Automerge document");
      }
      return this._repo.import(save(initialValue));
    } else {
      if (initialValue instanceof Uint8Array) {
        throw new Error("Cannot create document from Uint8Array without preserving history");
      }
      return this._repo.create(initialValue);
    }
  }
  async waitUntilHeadsReplicated(heads) {
    const entries = heads.entries;
    if (!entries?.length) {
      return;
    }
    const documentIds = entries.map((entry) => entry.documentId);
    const documentHeads = await this.getHeads(documentIds);
    const headsToWait = entries.filter((entry, index) => {
      const targetHeads = entry.heads;
      if (!targetHeads || targetHeads.length === 0) {
        return false;
      }
      const currentHeads = documentHeads[index];
      return !(currentHeads !== null && headsEquals(currentHeads, targetHeads));
    });
    if (headsToWait.length > 0) {
      await Promise.all(headsToWait.map(async (entry, index) => {
        const handle = await this.loadDoc(Context.default(void 0, {
          F: __dxlog_file3,
          L: 293
        }), entry.documentId);
        await waitForHeads(handle, entry.heads);
      }));
    }
    await this._repo.flush(documentIds.filter((documentId) => this._repo.handles[documentId] && this._repo.handles[documentId].isReady()));
  }
  async reIndexHeads(documentIds) {
    for (const documentId of documentIds) {
      log3("re-indexing heads for document", {
        documentId
      }, {
        F: __dxlog_file3,
        L: 307,
        S: this,
        C: (f, a) => f(...a)
      });
      const handle = await this._repo.find(documentId, FIND_PARAMS);
      if (!handle.isReady()) {
        log3.warn("document is not available locally, skipping", {
          documentId
        }, {
          F: __dxlog_file3,
          L: 310,
          S: this,
          C: (f, a) => f(...a)
        });
        continue;
      }
      const heads = handle.heads();
      const batch = this._db.batch();
      this._headsStore.setHeads(documentId, heads, batch);
      await batch.write();
    }
    log3("done re-indexing heads", void 0, {
      F: __dxlog_file3,
      L: 319,
      S: this,
      C: (f, a) => f(...a)
    });
  }
  // TODO(dmaretskyi): Share based on HALO permissions and space affinity.
  // Hosts, running in the worker, don't share documents unless requested by other peers.
  // NOTE: If both peers return sharePolicy=false the replication will not happen
  // https://github.com/automerge/automerge-repo/pull/292
  async _sharePolicy(peerId, documentId) {
    if (peerId.startsWith("client-")) {
      return false;
    }
    if (!documentId) {
      return false;
    }
    const peerMetadata = this.repo.peerMetadataByPeerId[peerId];
    if (isEchoPeerMetadata(peerMetadata)) {
      return this._echoNetworkAdapter.shouldAdvertise(peerId, {
        documentId
      });
    }
    return false;
  }
  async _beforeSave({ path, batch }) {
    const handle = this._repo.handles[path[0]];
    if (!handle || !handle.isReady()) {
      return;
    }
    const doc = handle.doc();
    if (!doc) {
      return;
    }
    const heads = getHeads(doc);
    this._headsStore.setHeads(handle.documentId, heads, batch);
    const spaceKey = DatabaseDirectory.getSpaceKey(doc) ?? void 0;
    const objectIds = Object.keys(doc.objects ?? {});
    const encodedIds = objectIds.map((objectId) => objectPointerCodec.encode({
      documentId: handle.documentId,
      objectId,
      spaceKey
    }));
    const idToLastHash = new Map(encodedIds.map((id) => [
      id,
      heads
    ]));
    this._indexMetadataStore.markDirty(idToLastHash, batch);
  }
  _shouldSyncCollection(collectionId, peerId) {
    const peerMetadata = this._repo.peerMetadataByPeerId[peerId];
    if (isEchoPeerMetadata(peerMetadata)) {
      return this._echoNetworkAdapter.shouldSyncCollection(peerId, {
        collectionId
      });
    }
    return false;
  }
  /**
  * Called by AutomergeStorageAdapter after levelDB batch commit.
  */
  async _afterSave(path) {
    this._indexMetadataStore.notifyMarkedDirty();
    const documentId = path[0];
    const document = this._repo.handles[documentId]?.doc();
    if (document) {
      const heads = getHeads(document);
      this._onHeadsChanged(documentId, heads);
    }
    this.documentsSaved.emit();
  }
  _automergePeers() {
    return this._repo.peers;
  }
  async _isDocumentInRemoteCollection(params) {
    for (const collectionId of this._collectionSynchronizer.getRegisteredCollectionIds()) {
      const remoteCollections = this._collectionSynchronizer.getRemoteCollectionStates(collectionId);
      const remotePeerDocs = remoteCollections.get(params.peerId)?.documents;
      if (remotePeerDocs && params.documentId in remotePeerDocs) {
        return true;
      }
    }
    return false;
  }
  async _getContainingSpaceForDocument(documentId) {
    const handle = this._repo.handles[documentId];
    if (handle.state === "loading") {
      await handle.whenReady();
    }
    if (handle && handle.isReady() && handle.doc()) {
      const spaceKeyHex = DatabaseDirectory.getSpaceKey(handle.doc());
      if (spaceKeyHex) {
        return PublicKey.from(spaceKeyHex);
      }
    }
    const rootDocSpaceKey = this._getSpaceKeyByRootDocumentId?.(documentId);
    if (rootDocSpaceKey) {
      return rootDocSpaceKey;
    }
    return null;
  }
  /**
  * Flush documents to disk.
  */
  async flush({ documentIds } = {}) {
    const loadedDocuments = documentIds?.filter((documentId) => {
      const handle = this._repo.handles[documentId];
      return handle && handle.isReady();
    });
    await this._repo.flush(loadedDocuments);
  }
  async getHeads(documentIds) {
    const result = [];
    const storeRequestIds = [];
    const storeResultIndices = [];
    for (const documentId of documentIds) {
      const handle = this._repo.handles[documentId];
      if (handle && handle.isReady() && handle.doc()) {
        result.push(getHeads(handle.doc()));
      } else {
        storeRequestIds.push(documentId);
        storeResultIndices.push(result.length);
        result.push(void 0);
      }
    }
    if (storeRequestIds.length > 0) {
      const storedHeads = await this._headsStore.getHeads(storeRequestIds);
      for (let i = 0; i < storedHeads.length; i++) {
        result[storeResultIndices[i]] = storedHeads[i];
      }
    }
    return result;
  }
  //
  // Collection sync.
  //
  getLocalCollectionState(collectionId) {
    return this._collectionSynchronizer.getLocalCollectionState(collectionId);
  }
  getRemoteCollectionStates(collectionId) {
    return this._collectionSynchronizer.getRemoteCollectionStates(collectionId);
  }
  refreshCollection(collectionId) {
    this._collectionSynchronizer.refreshCollection(collectionId);
  }
  async getCollectionSyncState(collectionId) {
    const result = {
      peers: []
    };
    const localState = this.getLocalCollectionState(collectionId);
    const remoteState = this.getRemoteCollectionStates(collectionId);
    if (!localState) {
      return result;
    }
    for (const [peerId, state] of remoteState) {
      const diff = diffCollectionState(localState, state);
      result.peers.push({
        peerId,
        missingOnRemote: diff.missingOnRemote.length,
        missingOnLocal: diff.missingOnLocal.length,
        differentDocuments: diff.different.length,
        localDocumentCount: Object.keys(localState.documents).length,
        remoteDocumentCount: Object.keys(state.documents).length
      });
    }
    return result;
  }
  /**
  * Update the local collection state based on the locally stored document heads.
  */
  async updateLocalCollectionState(collectionId, documentIds) {
    const heads = await this.getHeads(documentIds);
    const documents = Object.fromEntries(heads.map((heads2, index) => [
      documentIds[index],
      heads2 ?? []
    ]));
    this._collectionSynchronizer.setLocalCollectionState(collectionId, {
      documents
    });
  }
  async clearLocalCollectionState(collectionId) {
    this._collectionSynchronizer.clearLocalCollectionState(collectionId);
  }
  _onCollectionStateQueried(collectionId, peerId) {
    this._collectionSynchronizer.onCollectionStateQueried(collectionId, peerId);
  }
  _onCollectionStateReceived(collectionId, peerId, state) {
    this._collectionSynchronizer.onRemoteStateReceived(collectionId, peerId, decodeCollectionState(state));
  }
  _queryCollectionState(collectionId, peerId) {
    this._echoNetworkAdapter.queryCollectionState(collectionId, peerId);
  }
  _sendCollectionState(collectionId, peerId, state) {
    this._echoNetworkAdapter.sendCollectionState(collectionId, peerId, encodeCollectionState(state));
  }
  _onPeerConnected(peerId) {
    this._collectionSynchronizer.onConnectionOpen(peerId);
  }
  _onPeerDisconnected(peerId) {
    this._collectionSynchronizer.onConnectionClosed(peerId);
  }
  _onRemoteCollectionStateUpdated(collectionId, peerId) {
    const localState = this._collectionSynchronizer.getLocalCollectionState(collectionId);
    const remoteState = this._collectionSynchronizer.getRemoteCollectionStates(collectionId).get(peerId);
    if (!localState || !remoteState) {
      return;
    }
    const { different, missingOnLocal, missingOnRemote } = diffCollectionState(localState, remoteState);
    const toReplicate = [
      ...missingOnLocal,
      ...missingOnRemote,
      ...different
    ];
    if (toReplicate.length === 0) {
      return;
    }
    log3("replicating documents after collection sync", {
      collectionId,
      peerId,
      toReplicate,
      count: toReplicate.length
    }, {
      F: __dxlog_file3,
      L: 563,
      S: this,
      C: (f, a) => f(...a)
    });
    for (const documentId of toReplicate) {
      this._repo.findWithProgress(documentId);
    }
  }
  _onHeadsChanged(documentId, heads) {
    const collectionsChanged = /* @__PURE__ */ new Set();
    for (const collectionId of this._collectionSynchronizer.getRegisteredCollectionIds()) {
      const state = this._collectionSynchronizer.getLocalCollectionState(collectionId);
      if (state?.documents[documentId]) {
        const newState = structuredClone(state);
        newState.documents[documentId] = heads;
        this._collectionSynchronizer.setLocalCollectionState(collectionId, newState);
        collectionsChanged.add(collectionId);
      }
    }
    for (const collectionId of collectionsChanged) {
      this.collectionStateUpdated.emit({
        collectionId
      });
    }
  }
};
_ts_decorate3([
  trace2.info()
], AutomergeHost.prototype, "_peerId", void 0);
_ts_decorate3([
  trace2.info({
    depth: null
  })
], AutomergeHost.prototype, "_automergePeers", null);
_ts_decorate3([
  trace2.span({
    showInBrowserTimeline: true
  })
], AutomergeHost.prototype, "flush", null);
AutomergeHost = _ts_decorate3([
  trace2.resource()
], AutomergeHost);
var waitForHeads = async (handle, heads) => {
  const unavailableHeads = new Set(heads);
  await handle.whenReady();
  await Event2.wrap(handle, "change").waitForCondition(() => {
    for (const changeHash of unavailableHeads.values()) {
      if (changeIsPresentInDoc(handle.doc(), changeHash)) {
        unavailableHeads.delete(changeHash);
      }
    }
    return unavailableHeads.size === 0;
  });
};
var changeIsPresentInDoc = (doc, changeHash) => {
  return !!getBackend(doc).getChangeByHash(changeHash);
};
var decodeCollectionState = (state) => {
  invariant2(typeof state === "object" && state !== null, "Invalid state", {
    F: __dxlog_file3,
    L: 614,
    S: void 0,
    A: [
      "typeof state === 'object' && state !== null",
      "'Invalid state'"
    ]
  });
  return state;
};
var encodeCollectionState = (state) => {
  return state;
};

// packages/core/echo/echo-pipeline/src/automerge/mesh-echo-replicator.ts
import { invariant as invariant5 } from "@dxos/invariant";
import { PublicKey as PublicKey2 } from "@dxos/keys";
import { log as log5 } from "@dxos/log";
import { ComplexSet, defaultMap as defaultMap2 } from "@dxos/util";

// packages/core/echo/echo-pipeline/src/automerge/mesh-echo-replicator-connection.ts
import * as A from "@automerge/automerge";
import { cbor } from "@automerge/automerge-repo";
import { Resource as Resource4 } from "@dxos/context";
import { invariant as invariant3 } from "@dxos/invariant";
import { log as log4 } from "@dxos/log";
import { AutomergeReplicator } from "@dxos/teleport-extension-automerge-replicator";
var __dxlog_file4 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/automerge/mesh-echo-replicator-connection.ts";
var DEFAULT_FACTORY = (params) => new AutomergeReplicator(...params);
var MeshReplicatorConnection = class extends Resource4 {
  constructor(_params) {
    super(), this._params = _params, this.remoteDeviceKey = null, this._remotePeerId = null, this._isEnabled = false;
    let readableStreamController;
    this.readable = new ReadableStream({
      start: (controller) => {
        readableStreamController = controller;
        this._ctx.onDispose(() => controller.close());
      }
    });
    this.writable = new WritableStream({
      write: async (message, controller) => {
        invariant3(this._isEnabled, "Writing to a disabled connection", {
          F: __dxlog_file4,
          L: 51,
          S: this,
          A: [
            "this._isEnabled",
            "'Writing to a disabled connection'"
          ]
        });
        try {
          logSendSync(message);
          await this.replicatorExtension.sendSyncMessage({
            payload: cbor.encode(message)
          });
        } catch (err) {
          controller.error(err);
          this._disconnectIfEnabled();
        }
      }
    });
    const createAutomergeReplicator = this._params.replicatorFactory ?? DEFAULT_FACTORY;
    this.replicatorExtension = createAutomergeReplicator([
      {
        peerId: this._params.ownPeerId
      },
      {
        onStartReplication: async (info, remotePeerId) => {
          this.remoteDeviceKey = remotePeerId;
          this._remotePeerId = info.id;
          log4("onStartReplication", {
            id: info.id,
            thisPeerId: this.peerId,
            remotePeerId: remotePeerId.toHex()
          }, {
            F: __dxlog_file4,
            L: 80,
            S: this,
            C: (f, a) => f(...a)
          });
          this._params.onRemoteConnected();
        },
        onSyncMessage: async ({ payload }) => {
          if (!this._isEnabled) {
            return;
          }
          const message = cbor.decode(payload);
          readableStreamController.enqueue(message);
        },
        onClose: async () => {
          this._disconnectIfEnabled();
        }
      }
    ]);
  }
  _disconnectIfEnabled() {
    if (this._isEnabled) {
      this._params.onRemoteDisconnected();
    }
  }
  get peerId() {
    invariant3(this._remotePeerId != null, "Remote peer has not connected yet.", {
      F: __dxlog_file4,
      L: 106,
      S: this,
      A: [
        "this._remotePeerId != null",
        "'Remote peer has not connected yet.'"
      ]
    });
    return this._remotePeerId;
  }
  get isEnabled() {
    return this._isEnabled;
  }
  async shouldAdvertise(params) {
    return this._params.shouldAdvertise(params);
  }
  shouldSyncCollection(params) {
    return this._params.shouldSyncCollection(params);
  }
  /**
  * Start exchanging messages with the remote peer.
  * Call after the remote peer has connected.
  */
  enable() {
    invariant3(this._remotePeerId != null, "Remote peer has not connected yet.", {
      F: __dxlog_file4,
      L: 127,
      S: this,
      A: [
        "this._remotePeerId != null",
        "'Remote peer has not connected yet.'"
      ]
    });
    this._isEnabled = true;
  }
  /**
  * Stop exchanging messages with the remote peer.
  */
  disable() {
    this._isEnabled = false;
  }
};
var logSendSync = (message) => {
  log4("sendSyncMessage", () => {
    const decodedSyncMessage = message.type === "sync" && message.data ? A.decodeSyncMessage(message.data) : void 0;
    return {
      sync: decodedSyncMessage && {
        headsLength: decodedSyncMessage.heads.length,
        requesting: decodedSyncMessage.need.length > 0,
        sendingChanges: decodedSyncMessage.changes.length > 0
      },
      type: message.type,
      from: message.senderId,
      to: message.targetId
    };
  }, {
    F: __dxlog_file4,
    L: 140,
    S: void 0,
    C: (f, a) => f(...a)
  });
};

// packages/core/echo/echo-pipeline/src/automerge/space-collection.ts
import { invariant as invariant4 } from "@dxos/invariant";
import { SpaceId } from "@dxos/keys";
var __dxlog_file5 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/automerge/space-collection.ts";
var deriveCollectionIdFromSpaceId = (spaceId, rootDocumentId) => rootDocumentId ? `space:${spaceId}:${rootDocumentId}` : `space:${spaceId}`;
var getSpaceIdFromCollectionId = (collectionId) => {
  const spaceId = collectionId.split(":")[1];
  invariant4(SpaceId.isValid(spaceId), void 0, {
    F: __dxlog_file5,
    L: 16,
    S: void 0,
    A: [
      "SpaceId.isValid(spaceId)",
      ""
    ]
  });
  return spaceId;
};

// packages/core/echo/echo-pipeline/src/automerge/mesh-echo-replicator.ts
var __dxlog_file6 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/automerge/mesh-echo-replicator.ts";
var MeshEchoReplicator = class {
  constructor() {
    /**
    * We might have multiple connections open with a peer (one per space), but there'll be only one enabled
    * connection at any given moment, because there's a single repo for all the spaces.
    * When a connection closes (space was closed) it gets removed from the list and the next connection
    * in the line gets enabled.
    */
    this._connectionsPerPeer = /* @__PURE__ */ new Map();
    /**
    * A set of all connections (enabled and disabled).
    */
    this._connections = /* @__PURE__ */ new Set();
    /**
    * spaceId -> deviceKey[]
    */
    this._authorizedDevices = /* @__PURE__ */ new Map();
    this._context = null;
  }
  async connect(context) {
    this._context = context;
  }
  async disconnect() {
    for (const connection of this._connections) {
      if (connection.isEnabled) {
        this._context?.onConnectionClosed(connection);
      }
    }
    for (const connection of this._connections) {
      await connection.close();
    }
    this._connections.clear();
    this._connectionsPerPeer.clear();
    this._context = null;
  }
  createExtension(extensionFactory) {
    invariant5(this._context, void 0, {
      F: __dxlog_file6,
      L: 67,
      S: this,
      A: [
        "this._context",
        ""
      ]
    });
    const connection = new MeshReplicatorConnection({
      ownPeerId: this._context.peerId,
      replicatorFactory: extensionFactory,
      onRemoteConnected: async () => {
        log5("onRemoteConnected", {
          peerId: connection.peerId
        }, {
          F: __dxlog_file6,
          L: 73,
          S: this,
          C: (f, a) => f(...a)
        });
        invariant5(this._context, void 0, {
          F: __dxlog_file6,
          L: 74,
          S: this,
          A: [
            "this._context",
            ""
          ]
        });
        const existingConnections = this._connectionsPerPeer.get(connection.peerId);
        if (existingConnections?.length) {
          const enabledConnection = existingConnections[0];
          this._context.onConnectionAuthScopeChanged(enabledConnection);
          existingConnections.push(connection);
        } else {
          this._connectionsPerPeer.set(connection.peerId, [
            connection
          ]);
          this._context.onConnectionOpen(connection);
          connection.enable();
        }
      },
      onRemoteDisconnected: async () => {
        log5("onRemoteDisconnected", {
          peerId: connection.peerId
        }, {
          F: __dxlog_file6,
          L: 88,
          S: this,
          C: (f, a) => f(...a)
        });
        this._connections.delete(connection);
        const existingConnections = this._connectionsPerPeer.get(connection.peerId) ?? [];
        const index = existingConnections.indexOf(connection);
        if (index < 0) {
          log5.warn("disconnected connection not found", {
            peerId: connection.peerId
          }, {
            F: __dxlog_file6,
            L: 96,
            S: this,
            C: (f, a) => f(...a)
          });
          return;
        }
        existingConnections.splice(index, 1);
        if (connection.isEnabled) {
          this._context?.onConnectionClosed(connection);
          connection.disable();
          if (existingConnections.length > 0) {
            this._context?.onConnectionOpen(existingConnections[0]);
            existingConnections[0].enable();
          }
        }
      },
      shouldAdvertise: async (params) => {
        log5("shouldAdvertise", {
          peerId: connection.peerId,
          documentId: params.documentId
        }, {
          F: __dxlog_file6,
          L: 114,
          S: this,
          C: (f, a) => f(...a)
        });
        invariant5(this._context, void 0, {
          F: __dxlog_file6,
          L: 115,
          S: this,
          A: [
            "this._context",
            ""
          ]
        });
        try {
          const spaceKey = await this._context.getContainingSpaceForDocument(params.documentId);
          if (!spaceKey) {
            const remoteDocumentExists = await this._context.isDocumentInRemoteCollection({
              documentId: params.documentId,
              peerId: connection.peerId
            });
            log5("document not found locally for share policy check", {
              peerId: connection.peerId,
              documentId: params.documentId,
              acceptDocument: remoteDocumentExists
            }, {
              F: __dxlog_file6,
              L: 123,
              S: this,
              C: (f, a) => f(...a)
            });
            return remoteDocumentExists;
          }
          const spaceId = await createIdFromSpaceKey(spaceKey);
          const authorizedDevices = this._authorizedDevices.get(spaceId);
          if (!connection.remoteDeviceKey) {
            log5("device key not found for share policy check", {
              peerId: connection.peerId,
              documentId: params.documentId
            }, {
              F: __dxlog_file6,
              L: 140,
              S: this,
              C: (f, a) => f(...a)
            });
            return false;
          }
          const isAuthorized = authorizedDevices?.has(connection.remoteDeviceKey) ?? false;
          log5("share policy check", {
            localPeer: this._context.peerId,
            remotePeer: connection.peerId,
            documentId: params.documentId,
            deviceKey: connection.remoteDeviceKey,
            spaceKey,
            isAuthorized
          }, {
            F: __dxlog_file6,
            L: 148,
            S: this,
            C: (f, a) => f(...a)
          });
          return isAuthorized;
        } catch (err) {
          log5.catch(err, void 0, {
            F: __dxlog_file6,
            L: 158,
            S: this,
            C: (f, a) => f(...a)
          });
          return false;
        }
      },
      shouldSyncCollection: ({ collectionId }) => {
        const spaceId = getSpaceIdFromCollectionId(collectionId);
        const authorizedDevices = this._authorizedDevices.get(spaceId);
        if (!connection.remoteDeviceKey) {
          log5("device key not found for collection sync check", {
            peerId: connection.peerId,
            collectionId
          }, {
            F: __dxlog_file6,
            L: 168,
            S: this,
            C: (f, a) => f(...a)
          });
          return false;
        }
        const isAuthorized = authorizedDevices?.has(connection.remoteDeviceKey) ?? false;
        return isAuthorized;
      }
    });
    this._connections.add(connection);
    return connection.replicatorExtension;
  }
  async authorizeDevice(spaceKey, deviceKey) {
    log5("authorizeDevice", {
      spaceKey,
      deviceKey
    }, {
      F: __dxlog_file6,
      L: 185,
      S: this,
      C: (f, a) => f(...a)
    });
    const spaceId = await createIdFromSpaceKey(spaceKey);
    defaultMap2(this._authorizedDevices, spaceId, () => new ComplexSet(PublicKey2.hash)).add(deviceKey);
    for (const connection of this._connections) {
      if (connection.isEnabled && connection.remoteDeviceKey && connection.remoteDeviceKey.equals(deviceKey)) {
        if (this._connectionsPerPeer.has(connection.peerId)) {
          this._context?.onConnectionAuthScopeChanged(connection);
        }
      }
    }
  }
};

// packages/core/echo/echo-pipeline/src/automerge/echo-data-monitor.ts
import { trace as trace3 } from "@dxos/tracing";
import { CircularBuffer, mapValues, SlidingWindowSummary } from "@dxos/util";
function _ts_decorate4(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var PER_SECOND_RATE_AVG_WINDOW_SIZE = 5;
var DEFAULT_AVG_WINDOW_SIZE = 25;
var EchoDataMonitor = class {
  constructor(_params = {
    timeSeriesLength: 30
  }) {
    this._params = _params;
    this._lastTick = 0;
    this._activeCounters = createLocalCounters();
    this._localTimeSeries = createLocalTimeSeries();
    this._storageAverages = createStorageAverages();
    this._replicationAverages = createNetworkAverages();
    this._sizeByMessage = {};
    this._lastReceivedMessages = new CircularBuffer(100);
    this._lastSentMessages = new CircularBuffer(100);
    this._connectionsCount = 0;
  }
  tick(timeMs) {
    this._advanceTimeWindow(timeMs - this._lastTick);
    this._lastTick = timeMs;
  }
  computeStats() {
    return {
      meta: {
        rateAverageOverSeconds: PER_SECOND_RATE_AVG_WINDOW_SIZE
      },
      storage: {
        reads: {
          payloadSize: this._storageAverages.loadedChunkSize.average(),
          opDuration: this._storageAverages.loadDuration.average(),
          countPerSecond: this._storageAverages.loadsPerSecond.average()
        },
        writes: {
          payloadSize: this._storageAverages.storedChunkSize.average(),
          opDuration: this._storageAverages.storeDuration.average(),
          countPerSecond: this._storageAverages.storesPerSecond.average()
        }
      },
      replicator: {
        connections: this._connectionsCount,
        receivedMessages: {
          payloadSize: this._replicationAverages.receivedMessageSize.average(),
          countPerSecond: this._replicationAverages.receivedPerSecond.average()
        },
        sentMessages: {
          payloadSize: this._replicationAverages.sentMessageSize.average(),
          opDuration: this._replicationAverages.sendDuration.average(),
          countPerSecond: this._replicationAverages.sentPerSecond.average(),
          failedPerSecond: this._replicationAverages.sendsFailedPerSecond.average()
        },
        countByMessage: this._computeMessageHistogram("type"),
        avgSizeByMessage: mapValues(this._sizeByMessage, (summary) => summary.average())
      }
    };
  }
  get connectionsCount() {
    return this._connectionsCount;
  }
  /**
  * @internal
  */
  get lastPerSecondStats() {
    return this._lastCompleteCounters;
  }
  /**
  * @internal
  */
  get timeSeries() {
    return {
      ...this._localTimeSeries.storage,
      ...this._localTimeSeries.replication
    };
  }
  /**
  * @internal
  */
  get messagesByPeerId() {
    return this._computeMessageHistogram("peerId");
  }
  _advanceTimeWindow(millisPassed) {
    const oldMetrics = Object.freeze(this._activeCounters);
    this._activeCounters = createLocalCounters();
    this._lastCompleteCounters = oldMetrics;
    for (const peerId of Object.keys(oldMetrics.byPeerId)) {
      this._activeCounters.byPeerId[peerId] = createMessageCounter();
    }
    this._addToTimeSeries(oldMetrics.replication, this._localTimeSeries.replication);
    this._addToTimeSeries(oldMetrics.storage, this._localTimeSeries.storage);
    if (Math.abs(millisPassed - 1e3) < 100) {
      this._reportPerSecondRate(oldMetrics);
    }
  }
  _addToTimeSeries(values, timeSeries) {
    for (const [key, value] of Object.entries(values)) {
      const values2 = timeSeries[key];
      values2.push(value);
      if (values2.length > this._params.timeSeriesLength) {
        values2.shift();
      }
    }
  }
  _reportPerSecondRate(metrics) {
    const toReport = [
      [
        "storage.load",
        metrics.storage.loadedChunks,
        this._storageAverages.loadsPerSecond
      ],
      [
        "storage.store",
        metrics.storage.storedChunks,
        this._storageAverages.storesPerSecond
      ],
      [
        "network.receive",
        metrics.replication.received,
        this._replicationAverages.receivedPerSecond
      ],
      [
        "network.send",
        metrics.replication.sent,
        this._replicationAverages.sentPerSecond
      ]
    ];
    for (const [metricName, metric, summary] of toReport) {
      summary.record(metric);
      if (metric > 0) {
        trace3.metrics.distribution(`dxos.echo.${metricName}-rate`, metric);
        trace3.metrics.increment(`dxos.echo.${metricName}`, 1, {
          tags: {
            status: "busy"
          }
        });
      } else {
        trace3.metrics.increment(`dxos.echo.${metricName}`, 1, {
          tags: {
            status: "idle"
          }
        });
      }
    }
    this._replicationAverages.sendsFailedPerSecond.record(metrics.replication.failed);
  }
  recordPeerConnected(peerId) {
    this._activeCounters.byPeerId[peerId] = createMessageCounter();
    this._connectionsCount++;
  }
  recordPeerDisconnected(peerId) {
    this._connectionsCount--;
    delete this._activeCounters.byPeerId[peerId];
  }
  recordBytesStored(count) {
    this._activeCounters.storage.storedChunks++;
    this._activeCounters.storage.storedBytes += count;
    this._storageAverages.storedChunkSize.record(count);
    trace3.metrics.distribution("dxos.echo.storage.bytes-stored", count, {
      unit: "bytes"
    });
  }
  recordLoadDuration(durationMs) {
    this._storageAverages.loadDuration.record(durationMs);
  }
  recordStoreDuration(durationMs) {
    this._storageAverages.storeDuration.record(durationMs);
  }
  recordBytesLoaded(count) {
    this._activeCounters.storage.loadedChunks++;
    this._activeCounters.storage.loadedBytes += count;
    this._storageAverages.loadedChunkSize.record(count);
    trace3.metrics.distribution("dxos.echo.storage.bytes-loaded", count, {
      unit: "bytes"
    });
  }
  recordMessageSent(message, duration) {
    let metricsGroupName;
    const bytes = getByteCount(message);
    const tags = {
      type: message.type
    };
    if (isAutomergeProtocolMessage(message)) {
      this._activeCounters.replication.sent++;
      this._replicationAverages.sendDuration.record(duration);
      this._replicationAverages.sentMessageSize.record(bytes);
      metricsGroupName = "replication";
    } else {
      metricsGroupName = "collection-sync";
    }
    trace3.metrics.distribution(`dxos.echo.${metricsGroupName}.bytes-sent`, bytes, {
      unit: "bytes",
      tags
    });
    trace3.metrics.distribution(`dxos.echo.${metricsGroupName}.send-duration`, duration, {
      unit: "millisecond",
      tags
    });
    trace3.metrics.increment(`dxos.echo.${metricsGroupName}.send-status`, 1, {
      tags: {
        ...tags,
        success: true
      }
    });
    const { messageSize, messageCounts } = this._getStatsForType(message);
    messageSize.record(bytes);
    messageCounts.sent++;
    this._lastSentMessages.push({
      type: message.type,
      peerId: message.targetId
    });
  }
  recordMessageReceived(message) {
    const bytes = getByteCount(message);
    const tags = {
      type: message.type
    };
    if (isAutomergeProtocolMessage(message)) {
      this._activeCounters.replication.received++;
      this._replicationAverages.receivedMessageSize.record(bytes);
      trace3.metrics.distribution("dxos.echo.replication.bytes-received", bytes, {
        unit: "bytes",
        tags
      });
    } else {
      trace3.metrics.distribution("dxos.echo.collection-sync.bytes-received", bytes, {
        unit: "bytes",
        tags
      });
    }
    const { messageSize, messageCounts } = this._getStatsForType(message);
    messageSize.record(bytes);
    messageCounts.received++;
    this._lastReceivedMessages.push({
      type: message.type,
      peerId: message.senderId
    });
  }
  recordMessageSendingFailed(message) {
    const tags = {
      type: message.type,
      success: false
    };
    if (isAutomergeProtocolMessage(message)) {
      this._activeCounters.replication.failed++;
      trace3.metrics.increment("dxos.echo.replication.send-status", 1, {
        unit: "bytes",
        tags
      });
    } else {
      trace3.metrics.increment("dxos.echo.collection-sync.send-status", 1, {
        unit: "bytes",
        tags
      });
    }
    const { messageCounts } = this._getStatsForType(message);
    messageCounts.failed++;
  }
  _getStatsForType(message) {
    const messageSize = this._sizeByMessage[message.type] ??= createSlidingWindow();
    const messageCounts = this._activeCounters.byType[message.type] ??= createMessageCounter();
    return {
      messageCounts,
      messageSize
    };
  }
  _computeMessageHistogram(groupKey) {
    const result = {};
    for (const receivedMessage of this._lastReceivedMessages) {
      const counters = result[receivedMessage[groupKey]] ??= {
        received: 0,
        sent: 0
      };
      counters.received++;
    }
    for (const receivedMessage of this._lastSentMessages) {
      const counters = result[receivedMessage[groupKey]] ??= {
        received: 0,
        sent: 0
      };
      counters.sent++;
    }
    return result;
  }
};
EchoDataMonitor = _ts_decorate4([
  trace3.resource()
], EchoDataMonitor);
var isAutomergeProtocolMessage = (message) => {
  return !(isCollectionQueryMessage(message) || isCollectionStateMessage(message));
};
var createSlidingWindow = (overrides) => new SlidingWindowSummary({
  dataPoints: DEFAULT_AVG_WINDOW_SIZE,
  precision: 2,
  ...overrides
});
var createLocalCounters = () => ({
  storage: {
    loadedBytes: 0,
    storedBytes: 0,
    storedChunks: 0,
    loadedChunks: 0
  },
  replication: createMessageCounter(),
  byPeerId: {},
  byType: {}
});
var createLocalTimeSeries = () => ({
  storage: {
    loadedBytes: [],
    storedBytes: [],
    storedChunks: [],
    loadedChunks: []
  },
  replication: {
    sent: [],
    failed: [],
    received: []
  }
});
var createMessageCounter = () => ({
  sent: 0,
  received: 0,
  failed: 0
});
var createNetworkAverages = () => ({
  receivedMessageSize: createSlidingWindow(),
  sentMessageSize: createSlidingWindow(),
  sendDuration: createSlidingWindow(),
  receivedPerSecond: createSlidingWindow({
    dataPoints: PER_SECOND_RATE_AVG_WINDOW_SIZE
  }),
  sentPerSecond: createSlidingWindow({
    dataPoints: PER_SECOND_RATE_AVG_WINDOW_SIZE
  }),
  sendsFailedPerSecond: createSlidingWindow({
    dataPoints: PER_SECOND_RATE_AVG_WINDOW_SIZE
  })
});
var createStorageAverages = () => ({
  storedChunkSize: createSlidingWindow(),
  loadedChunkSize: createSlidingWindow(),
  loadDuration: createSlidingWindow(),
  storeDuration: createSlidingWindow(),
  loadsPerSecond: createSlidingWindow({
    dataPoints: PER_SECOND_RATE_AVG_WINDOW_SIZE
  }),
  storesPerSecond: createSlidingWindow({
    dataPoints: PER_SECOND_RATE_AVG_WINDOW_SIZE
  })
});
var getByteCount = (message) => {
  return message.type.length + message.senderId.length + message.targetId.length + (message.data?.byteLength ?? 0) + (message.documentId?.length ?? 0);
};

// packages/core/echo/echo-pipeline/src/db-host/documents-synchronizer.ts
var __dxlog_file7 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/documents-synchronizer.ts";
var MAX_UPDATE_FREQ = 10;
var DocumentsSynchronizer = class extends Resource5 {
  constructor(_params) {
    super(), this._params = _params, this._syncStates = /* @__PURE__ */ new Map(), this._pendingUpdates = /* @__PURE__ */ new Set(), this._sendUpdatesJob = void 0;
  }
  addDocuments(documentIds, retryCounter = 0) {
    if (retryCounter > 3) {
      log6.warn("Failed to load document, retry limit reached", {
        documentIds
      }, {
        F: __dxlog_file7,
        L: 52,
        S: this,
        C: (f, a) => f(...a)
      });
      return;
    }
    for (const documentId of documentIds) {
      this._params.repo.find(documentId).then(async (doc) => {
        await doc.whenReady();
        this._startSync(doc);
        this._pendingUpdates.add(doc.documentId);
        this._sendUpdatesJob.trigger();
      }).catch((error) => {
        log6.warn("Failed to load document, wraparound", {
          documentId,
          error
        }, {
          F: __dxlog_file7,
          L: 66,
          S: this,
          C: (f, a) => f(...a)
        });
        this.addDocuments([
          documentId
        ], retryCounter + 1);
      });
    }
  }
  removeDocuments(documentIds) {
    for (const documentId of documentIds) {
      this._syncStates.get(documentId)?.clearSubscriptions?.();
      this._syncStates.delete(documentId);
      this._pendingUpdates.delete(documentId);
    }
  }
  async _open() {
    this._sendUpdatesJob = new UpdateScheduler(this._ctx, this._checkAndSendUpdates.bind(this), {
      maxFrequency: MAX_UPDATE_FREQ
    });
  }
  async _close() {
    await this._sendUpdatesJob.join();
    this._syncStates.clear();
  }
  async update(updates) {
    for (const { documentId, mutation, isNew } of updates) {
      if (isNew) {
        const doc = await this._params.repo.find(documentId, FIND_PARAMS);
        doc.update((doc2) => A2.loadIncremental(doc2, mutation));
        this._startSync(doc);
      } else {
        this._writeMutation(documentId, mutation);
      }
    }
  }
  _startSync(doc) {
    if (this._syncStates.has(doc.documentId)) {
      log6("Document already being synced", {
        documentId: doc.documentId
      }, {
        F: __dxlog_file7,
        L: 105,
        S: this,
        C: (f, a) => f(...a)
      });
      return;
    }
    const syncState = {
      handle: doc
    };
    this._subscribeForChanges(syncState);
    this._syncStates.set(doc.documentId, syncState);
  }
  _subscribeForChanges(syncState) {
    const handler = () => {
      this._pendingUpdates.add(syncState.handle.documentId);
      this._sendUpdatesJob.trigger();
    };
    syncState.handle.on("heads-changed", handler);
    syncState.clearSubscriptions = () => syncState.handle.off("heads-changed", handler);
  }
  async _checkAndSendUpdates() {
    const updates = [];
    const docsWithPendingUpdates = Array.from(this._pendingUpdates);
    this._pendingUpdates.clear();
    for (const documentId of docsWithPendingUpdates) {
      const update = this._getPendingChanges(documentId);
      if (update) {
        updates.push({
          documentId,
          mutation: update
        });
      }
    }
    if (updates.length > 0) {
      this._params.sendUpdates({
        updates
      });
    }
  }
  _getPendingChanges(documentId) {
    const syncState = this._syncStates.get(documentId);
    invariant6(syncState, "Sync state for document not found", {
      F: __dxlog_file7,
      L: 146,
      S: this,
      A: [
        "syncState",
        "'Sync state for document not found'"
      ]
    });
    const handle = syncState.handle;
    if (!handle || !handle.isReady() || !handle.doc()) {
      return;
    }
    const doc = handle.doc();
    const mutation = syncState.lastSentHead ? A2.saveSince(doc, syncState.lastSentHead) : A2.save(doc);
    if (mutation.length === 0) {
      return;
    }
    syncState.lastSentHead = A2.getHeads(doc);
    return mutation;
  }
  _writeMutation(documentId, mutation) {
    const syncState = this._syncStates.get(documentId);
    invariant6(syncState, "Sync state for document not found", {
      F: __dxlog_file7,
      L: 162,
      S: this,
      A: [
        "syncState",
        "'Sync state for document not found'"
      ]
    });
    syncState.handle.update((doc) => {
      const headsBefore = A2.getHeads(doc);
      const newDoc = A2.loadIncremental(doc, mutation);
      if (A2.equals(headsBefore, syncState.lastSentHead)) {
        syncState.lastSentHead = A2.getHeads(newDoc);
      }
      return newDoc;
    });
  }
};

// packages/core/echo/echo-pipeline/src/db-host/data-service.ts
var __dxlog_file8 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/data-service.ts";
var DataServiceImpl = class {
  constructor(params) {
    /**
    * Map of subscriptions.
    * subscriptionId -> DocumentsSynchronizer
    */
    this._subscriptions = /* @__PURE__ */ new Map();
    this._automergeHost = params.automergeHost;
    this._spaceStateManager = params.spaceStateManager;
    this._updateIndexes = params.updateIndexes;
  }
  subscribe(request) {
    return new Stream(({ next, ready }) => {
      const synchronizer = new DocumentsSynchronizer({
        repo: this._automergeHost.repo,
        sendUpdates: (updates) => next(updates)
      });
      synchronizer.open().then(() => {
        this._subscriptions.set(request.subscriptionId, synchronizer);
        ready();
      }).catch((err) => log7.catch(err, void 0, {
        F: __dxlog_file8,
        L: 71,
        S: this,
        C: (f, a) => f(...a)
      }));
      return () => synchronizer.close();
    });
  }
  async updateSubscription(request) {
    const synchronizer = this._subscriptions.get(request.subscriptionId);
    invariant7(synchronizer, "Subscription not found", {
      F: __dxlog_file8,
      L: 78,
      S: this,
      A: [
        "synchronizer",
        "'Subscription not found'"
      ]
    });
    if (request.addIds?.length) {
      await synchronizer.addDocuments(request.addIds);
    }
    if (request.removeIds?.length) {
      await synchronizer.removeDocuments(request.removeIds);
    }
  }
  async update(request) {
    if (!request.updates) {
      return;
    }
    const synchronizer = this._subscriptions.get(request.subscriptionId);
    invariant7(synchronizer, "Subscription not found", {
      F: __dxlog_file8,
      L: 93,
      S: this,
      A: [
        "synchronizer",
        "'Subscription not found'"
      ]
    });
    await synchronizer.update(request.updates);
  }
  async flush(request) {
    await this._automergeHost.flush(request);
  }
  async getDocumentHeads(request) {
    const documentIds = request.documentIds;
    if (!documentIds) {
      return {
        heads: {
          entries: []
        }
      };
    }
    const heads = await this._automergeHost.getHeads(documentIds);
    return {
      heads: {
        entries: heads.map((heads2, idx) => ({
          documentId: documentIds[idx],
          heads: heads2
        }))
      }
    };
  }
  async waitUntilHeadsReplicated(request, options) {
    await this._automergeHost.waitUntilHeadsReplicated(request.heads);
  }
  async reIndexHeads(request, options) {
    await this._automergeHost.reIndexHeads(request.documentIds ?? []);
  }
  async updateIndexes() {
    await this._updateIndexes();
  }
  subscribeSpaceSyncState(request) {
    return new Stream(({ ctx, next, ready }) => {
      const spaceId = request.spaceId;
      invariant7(SpaceId2.isValid(spaceId), void 0, {
        F: __dxlog_file8,
        L: 133,
        S: this,
        A: [
          "SpaceId.isValid(spaceId)",
          ""
        ]
      });
      const rootDocumentId = this._spaceStateManager.getSpaceRootDocumentId(spaceId);
      let collectionId = rootDocumentId && deriveCollectionIdFromSpaceId(spaceId, rootDocumentId);
      this._spaceStateManager.spaceDocumentListUpdated.on(ctx, (event) => {
        const newId = deriveCollectionIdFromSpaceId(spaceId, event.spaceRootId);
        if (newId !== collectionId) {
          collectionId = newId;
          scheduler.trigger();
        }
      });
      const scheduler = new UpdateScheduler2(ctx, async () => {
        const state = collectionId ? await this._automergeHost.getCollectionSyncState(collectionId) : {
          peers: []
        };
        next({
          peers: state.peers.map((peer) => ({
            peerId: peer.peerId,
            missingOnRemote: peer.missingOnRemote,
            missingOnLocal: peer.missingOnLocal,
            differentDocuments: peer.differentDocuments,
            localDocumentCount: peer.localDocumentCount,
            remoteDocumentCount: peer.remoteDocumentCount
          }))
        });
      });
      this._automergeHost.collectionStateUpdated.on(ctx, (e) => {
        if (e.collectionId === collectionId) {
          scheduler.trigger();
        }
      });
      scheduler.trigger();
    });
  }
};

// packages/core/echo/echo-pipeline/src/db-host/echo-host.ts
import { LifecycleState as LifecycleState5, Resource as Resource9 } from "@dxos/context";
import { todo } from "@dxos/debug";
import { createIdFromSpaceKey as createIdFromSpaceKey2, SpaceDocVersion as SpaceDocVersion3 } from "@dxos/echo-protocol";
import { IndexMetadataStore, IndexStore, Indexer } from "@dxos/indexing";
import { invariant as invariant13 } from "@dxos/invariant";
import { IndexKind } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace as trace5 } from "@dxos/tracing";

// packages/core/echo/echo-pipeline/src/db-host/documents-iterator.ts
import * as A3 from "@automerge/automerge";
import { Context as Context2 } from "@dxos/context";
import { DatabaseDirectory as DatabaseDirectory2, SpaceDocVersion } from "@dxos/echo-protocol";
import { invariant as invariant8 } from "@dxos/invariant";
import { log as log8 } from "@dxos/log";
import { ObjectPointerVersion, objectPointerCodec as objectPointerCodec2 } from "@dxos/protocols";
var __dxlog_file9 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/documents-iterator.ts";
var LOG_VIEW_OPERATION_THRESHOLD = 300;
var createSelectedDocumentsIterator = (automergeHost) => (
  /**
  * Get object data blobs from Automerge Repo by ids.
  */
  // TODO(mykola): Unload automerge handles after usage.
  async function* loadDocuments(objects) {
    for (const [id, heads] of objects.entries()) {
      try {
        const { documentId, objectId } = objectPointerCodec2.decode(id);
        const handle = await automergeHost.loadDoc(Context2.default(void 0, {
          F: __dxlog_file9,
          L: 31
        }), documentId);
        let doc = handle.doc();
        invariant8(doc, void 0, {
          F: __dxlog_file9,
          L: 34,
          S: this,
          A: [
            "doc",
            ""
          ]
        });
        const currentHeads = A3.getHeads(doc);
        if (!A3.equals(currentHeads, heads)) {
          const begin = Date.now();
          doc = A3.view(doc, heads);
          const end = Date.now();
          if (end - begin > LOG_VIEW_OPERATION_THRESHOLD) {
            log8("Checking out document version is taking too long", {
              duration: end - begin,
              requestedHeads: heads,
              originalHeads: currentHeads
            }, {
              F: __dxlog_file9,
              L: 45,
              S: this,
              C: (f, a) => f(...a)
            });
          }
        }
        if (doc.version !== SpaceDocVersion.CURRENT) {
          continue;
        }
        if (!doc.objects?.[objectId]) {
          continue;
        }
        let newId = id;
        if (objectPointerCodec2.getVersion(id) === ObjectPointerVersion.V0) {
          const spaceKey = DatabaseDirectory2.getSpaceKey(doc) ?? void 0;
          newId = objectPointerCodec2.encode({
            documentId,
            objectId,
            spaceKey
          });
        }
        yield [
          {
            id: newId,
            object: doc.objects[objectId],
            heads
          }
        ];
      } catch (error) {
        log8.error("Error loading document", {
          heads,
          id,
          error
        }, {
          F: __dxlog_file9,
          L: 71,
          S: this,
          C: (f, a) => f(...a)
        });
      }
    }
  }
);

// packages/core/echo/echo-pipeline/src/db-host/query-service.ts
import { getHeads as getHeads3 } from "@automerge/automerge";
import { Schema } from "effect";
import { DeferredTask, scheduleMicroTask, synchronized as synchronized2 } from "@dxos/async";
import { Stream as Stream2 } from "@dxos/codec-protobuf/stream";
import { Context as Context4, Resource as Resource7 } from "@dxos/context";
import { raise } from "@dxos/debug";
import { DatabaseDirectory as DatabaseDirectory4, QueryAST } from "@dxos/echo-protocol";
import { log as log10 } from "@dxos/log";
import { objectPointerCodec as objectPointerCodec4 } from "@dxos/protocols";
import { trace as trace4 } from "@dxos/tracing";

// packages/core/echo/echo-pipeline/src/query/query-executor.ts
import { Match } from "effect";
import { Context as Context3, ContextDisposedError, LifecycleState as LifecycleState3, Resource as Resource6 } from "@dxos/context";
import { DatabaseDirectory as DatabaseDirectory3, isEncodedReference, ObjectStructure } from "@dxos/echo-protocol";
import { EscapedPropPath } from "@dxos/indexing";
import { invariant as invariant10 } from "@dxos/invariant";
import { DXN, PublicKey as PublicKey3 } from "@dxos/keys";
import { log as log9 } from "@dxos/log";
import { objectPointerCodec as objectPointerCodec3 } from "@dxos/protocols";
import { getDeep, isNonNullable as isNonNullable2 } from "@dxos/util";

// packages/core/echo/echo-pipeline/src/query/query-planner.ts
import { invariant as invariant9 } from "@dxos/invariant";

// packages/core/echo/echo-pipeline/src/query/errors.ts
import { BaseError } from "@dxos/errors";
var QueryError = class extends BaseError.extend("QUERY_ERROR") {
};

// packages/core/echo/echo-pipeline/src/query/plan.ts
(function(QueryPlan2) {
  QueryPlan2.Plan = Object.freeze({
    make: (steps) => ({
      steps
    })
  });
  QueryPlan2.FilterStep = Object.freeze({
    isNoop: (step) => {
      switch (step.filter.type) {
        case "object": {
          return step.filter.typename === null && (step.filter.id === void 0 || step.filter.id.length === 0) && (step.filter.props === void 0 || Object.keys(step.filter.props).length === 0) && (step.filter.foreignKeys === void 0 || step.filter.foreignKeys.length === 0);
        }
        default:
          return false;
      }
    }
  });
})(QueryPlan || (QueryPlan = {}));
var QueryPlan;

// packages/core/echo/echo-pipeline/src/query/query-planner.ts
var __dxlog_file10 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/query/query-planner.ts";
var DEFAULT_OPTIONS = {
  defaultTextSearchKind: "full-text"
};
var QueryPlanner = class {
  constructor(options) {
    this._options = {
      ...DEFAULT_OPTIONS,
      ...options
    };
  }
  createPlan(query) {
    let plan = this._generate(query, {
      ...DEFAULT_CONTEXT,
      originalQuery: query
    });
    plan = this._optimizeEmptyFilters(plan);
    plan = this._optimizeSoloUnions(plan);
    return plan;
  }
  _generate(query, context) {
    switch (query.type) {
      case "options":
        return this._generateOptionsClause(query, context);
      case "select":
        return this._generateSelectClause(query, context);
      case "filter":
        return this._generateFilterClause(query, context);
      case "incoming-references":
        return this._generateIncomingReferencesClause(query, context);
      case "relation":
        return this._generateRelationClause(query, context);
      case "relation-traversal":
        return this._generateRelationTraversalClause(query, context);
      case "reference-traversal":
        return this._generateReferenceTraversalClause(query, context);
      case "union":
        return this._generateUnionClause(query, context);
      case "set-difference":
        return this._generateSetDifferenceClause(query, context);
      default:
        throw new QueryError(`Unsupported query type: ${query.type}`, {
          context: {
            query: context.originalQuery
          }
        });
    }
  }
  _generateOptionsClause(query, context) {
    const newContext = {
      ...context
    };
    if (query.options.spaceIds) {
      newContext.selectionSpaces = query.options.spaceIds;
    }
    if (query.options.deleted) {
      newContext.deletedHandling = query.options.deleted;
    }
    return this._generate(query.query, newContext);
  }
  _generateSelectClause(query, context) {
    return this._generateSelectionFromFilter(query.filter, context);
  }
  // TODO(dmaretskyi): This can be rewritten as a function of (filter[]) -> (selection ? undefined, rest: filter[]) that recurses onto itself.
  // TODO(dmaretskyi): If the tip of the query ast is a [select, ...filter] shape we can reorder the filters so the query is most efficient.
  _generateSelectionFromFilter(filter, context) {
    switch (filter.type) {
      case "object": {
        if (context.selectionInverted && filter.id === void 0 && filter.typename === null && Object.keys(filter.props).length === 0) {
          return QueryPlan.Plan.make([
            {
              _tag: "ClearWorkingSetStep"
            },
            ...this._generateDeletedHandlingSteps(context)
          ]);
        }
        if (context.selectionInverted) {
          throw new QueryError("Query too complex", {
            context: {
              query: context.originalQuery
            }
          });
        }
        if (filter.id && filter.id?.length > 0) {
          return QueryPlan.Plan.make([
            {
              _tag: "SelectStep",
              spaces: context.selectionSpaces,
              selector: {
                _tag: "IdSelector",
                objectIds: filter.id
              }
            },
            ...this._generateDeletedHandlingSteps(context),
            {
              _tag: "FilterStep",
              filter: {
                ...filter,
                id: void 0
              }
            }
          ]);
        } else if (filter.typename) {
          return QueryPlan.Plan.make([
            {
              _tag: "SelectStep",
              spaces: context.selectionSpaces,
              selector: {
                _tag: "TypeSelector",
                typename: [
                  filter.typename
                ],
                inverted: false
              }
            },
            ...this._generateDeletedHandlingSteps(context),
            {
              _tag: "FilterStep",
              filter: {
                ...filter,
                typename: null
              }
            }
          ]);
        } else {
          return QueryPlan.Plan.make([
            {
              _tag: "SelectStep",
              spaces: context.selectionSpaces,
              selector: {
                _tag: "WildcardSelector"
              }
            },
            ...this._generateDeletedHandlingSteps(context),
            {
              _tag: "FilterStep",
              filter: {
                ...filter
              }
            }
          ]);
        }
      }
      case "text-search": {
        return QueryPlan.Plan.make([
          {
            _tag: "SelectStep",
            spaces: context.selectionSpaces,
            selector: {
              _tag: "TextSelector",
              text: filter.text,
              searchKind: filter.searchKind ?? this._options.defaultTextSearchKind
            }
          },
          ...this._generateDeletedHandlingSteps(context)
        ]);
      }
      case "compare":
        throw new QueryError("Query too complex", {
          context: {
            query: context.originalQuery
          }
        });
      case "in":
        throw new QueryError("Query too complex", {
          context: {
            query: context.originalQuery
          }
        });
      case "range":
        throw new QueryError("Query too complex", {
          context: {
            query: context.originalQuery
          }
        });
      case "not":
        return this._generateSelectionFromFilter(filter.filter, {
          ...context,
          selectionInverted: !context.selectionInverted
        });
      case "and":
        throw new QueryError("Query too complex", {
          context: {
            query: context.originalQuery
          }
        });
      case "or":
        if (filter.filters.every(isTrivialTypenameFilter)) {
          const typenames = filter.filters.map((f) => {
            invariant9(f.type === "object" && f.typename !== null, void 0, {
              F: __dxlog_file10,
              L: 191,
              S: this,
              A: [
                "f.type === 'object' && f.typename !== null",
                ""
              ]
            });
            return f.typename;
          });
          return QueryPlan.Plan.make([
            {
              _tag: "SelectStep",
              spaces: context.selectionSpaces,
              selector: {
                _tag: "TypeSelector",
                typename: typenames,
                inverted: context.selectionInverted
              }
            },
            ...this._generateDeletedHandlingSteps(context)
          ]);
        } else {
          throw new QueryError("Query too complex", {
            context: {
              query: context.originalQuery
            }
          });
        }
      default:
        throw new QueryError(`Unsupported filter type: ${filter.type}`, {
          context: {
            query: context.originalQuery
          }
        });
    }
  }
  _generateDeletedHandlingSteps(context) {
    switch (context.deletedHandling) {
      case "include":
        return [];
      case "exclude":
        return [
          {
            _tag: "FilterDeletedStep",
            mode: "only-non-deleted"
          }
        ];
      case "only":
        return [
          {
            _tag: "FilterDeletedStep",
            mode: "only-deleted"
          }
        ];
    }
  }
  _generateUnionClause(query, context) {
    return QueryPlan.Plan.make([
      {
        _tag: "UnionStep",
        plans: query.queries.map((query2) => this._generate(query2, context))
      }
    ]);
  }
  _generateSetDifferenceClause(query, context) {
    return QueryPlan.Plan.make([
      {
        _tag: "SetDifferenceStep",
        source: this._generate(query.source, context),
        exclude: this._generate(query.exclude, context)
      }
    ]);
  }
  _generateReferenceTraversalClause(query, context) {
    return QueryPlan.Plan.make([
      ...this._generate(query.anchor, context).steps,
      {
        _tag: "TraverseStep",
        traversal: {
          _tag: "ReferenceTraversal",
          direction: "outgoing",
          property: query.property
        }
      },
      ...this._generateDeletedHandlingSteps(context)
    ]);
  }
  _generateIncomingReferencesClause(query, context) {
    return QueryPlan.Plan.make([
      ...this._generate(query.anchor, context).steps,
      {
        _tag: "TraverseStep",
        traversal: {
          _tag: "ReferenceTraversal",
          direction: "incoming",
          property: query.property
        }
      },
      ...this._generateDeletedHandlingSteps(context),
      {
        _tag: "FilterStep",
        filter: {
          type: "object",
          typename: query.typename,
          props: {}
        }
      }
    ]);
  }
  _generateRelationTraversalClause(query, context) {
    switch (query.direction) {
      case "source": {
        return QueryPlan.Plan.make([
          ...this._generate(query.anchor, context).steps,
          createRelationTraversalStep("relation-to-source"),
          ...this._generateDeletedHandlingSteps(context)
        ]);
      }
      case "target": {
        return QueryPlan.Plan.make([
          ...this._generate(query.anchor, context).steps,
          createRelationTraversalStep("relation-to-target"),
          ...this._generateDeletedHandlingSteps(context)
        ]);
      }
      case "both": {
        const anchorPlan = this._generate(query.anchor, context);
        return QueryPlan.Plan.make([
          ...anchorPlan.steps,
          {
            _tag: "UnionStep",
            plans: [
              QueryPlan.Plan.make([
                createRelationTraversalStep("relation-to-source")
              ]),
              QueryPlan.Plan.make([
                createRelationTraversalStep("relation-to-target")
              ])
            ]
          },
          ...this._generateDeletedHandlingSteps(context)
        ]);
      }
    }
  }
  _generateRelationClause(query, context) {
    switch (query.direction) {
      case "outgoing": {
        return QueryPlan.Plan.make([
          ...this._generate(query.anchor, context).steps,
          createRelationTraversalStep("source-to-relation"),
          ...this._generateDeletedHandlingSteps(context),
          {
            _tag: "FilterStep",
            filter: query.filter ?? NOOP_FILTER
          }
        ]);
      }
      case "incoming": {
        return QueryPlan.Plan.make([
          ...this._generate(query.anchor, context).steps,
          createRelationTraversalStep("target-to-relation"),
          ...this._generateDeletedHandlingSteps(context),
          {
            _tag: "FilterStep",
            filter: query.filter ?? NOOP_FILTER
          }
        ]);
      }
      case "both": {
        const anchorPlan = this._generate(query.anchor, context);
        return QueryPlan.Plan.make([
          ...anchorPlan.steps,
          {
            _tag: "UnionStep",
            plans: [
              QueryPlan.Plan.make([
                createRelationTraversalStep("source-to-relation")
              ]),
              QueryPlan.Plan.make([
                createRelationTraversalStep("target-to-relation")
              ])
            ]
          },
          ...this._generateDeletedHandlingSteps(context),
          {
            _tag: "FilterStep",
            filter: query.filter ?? NOOP_FILTER
          }
        ]);
      }
    }
  }
  _generateFilterClause(query, context) {
    return QueryPlan.Plan.make([
      ...this._generate(query.selection, context).steps,
      {
        _tag: "FilterStep",
        filter: query.filter
      }
    ]);
  }
  /**
  * Removes filter steps that have no predicates.
  */
  _optimizeEmptyFilters(plan) {
    return QueryPlan.Plan.make(plan.steps.filter((step) => {
      if (step._tag === "FilterStep") {
        return !QueryPlan.FilterStep.isNoop(step);
      } else {
        return true;
      }
    }).map((step) => {
      if (step._tag === "UnionStep") {
        return {
          _tag: "UnionStep",
          plans: step.plans.map((plan2) => this._optimizeEmptyFilters(plan2))
        };
      } else {
        return step;
      }
    }));
  }
  /**
  * Removes union steps that have only one child.
  */
  _optimizeSoloUnions(plan) {
    return plan;
  }
};
var DEFAULT_CONTEXT = {
  originalQuery: null,
  selectionSpaces: [],
  deletedHandling: "exclude",
  selectionInverted: false
};
var NOOP_FILTER = {
  type: "object",
  typename: null,
  id: [],
  props: {}
};
var createRelationTraversalStep = (direction) => ({
  _tag: "TraverseStep",
  traversal: {
    _tag: "RelationTraversal",
    direction
  }
});
var isTrivialTypenameFilter = (filter) => {
  return filter.type === "object" && filter.typename !== null && Object.keys(filter.props).length === 0 && (filter.id === void 0 || filter.id.length === 0) && (filter.foreignKeys === void 0 || filter.foreignKeys.length === 0);
};

// packages/core/echo/echo-pipeline/src/query/query-executor.ts
var __dxlog_file11 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/query/query-executor.ts";
var ExecutionTrace = Object.freeze({
  makeEmpty: () => ({
    name: "Empty",
    details: "",
    objectCount: 0,
    documentsLoaded: 0,
    indexHits: 0,
    indexQueryTime: 0,
    documentLoadTime: 0,
    executionTime: 0,
    children: []
  }),
  format: (trace6) => {
    const go = (trace7, indent) => {
      return [
        `${" ".repeat(indent)} - ${trace7.name}(${trace7.details})`,
        `${" ".repeat(indent)}   objects: ${trace7.objectCount}  docs: ${trace7.documentsLoaded}  index hits: ${trace7.indexHits} | total: ${trace7.executionTime.toFixed(0)}ms  index: ${trace7.indexQueryTime.toFixed(0)}ms  load: ${trace7.documentLoadTime.toFixed(0)}ms`,
        "",
        ...trace7.children.map((child) => go(child, indent + 2))
      ].join("\n");
    };
    return go(trace6, 0);
  }
});
var TRACE_QUERY_EXECUTION = false;
var QueryExecutor = class extends Resource6 {
  constructor(options) {
    super();
    this._trace = ExecutionTrace.makeEmpty();
    this._lastResultSet = [];
    this._indexer = options.indexer;
    this._automergeHost = options.automergeHost;
    this._spaceStateManager = options.spaceStateManager;
    this._id = options.queryId;
    this._query = options.query;
    this._reactivity = options.reactivity;
    const queryPlanner = new QueryPlanner();
    this._plan = queryPlanner.createPlan(this._query);
  }
  get query() {
    return this._query;
  }
  get plan() {
    return this._plan;
  }
  get trace() {
    return this._trace;
  }
  async _open(ctx) {
  }
  async _close(ctx) {
  }
  getResults() {
    return this._lastResultSet.map((item) => ({
      id: item.objectId,
      documentId: item.documentId,
      spaceId: item.spaceId,
      // TODO(dmaretskyi): Plumb through the rank.
      rank: 0
    }));
  }
  async execQuery() {
    invariant10(this._lifecycleState === LifecycleState3.OPEN, void 0, {
      F: __dxlog_file11,
      L: 173,
      S: this,
      A: [
        "this._lifecycleState === LifecycleState.OPEN",
        ""
      ]
    });
    const prevResultSet = this._lastResultSet;
    const { workingSet, trace: trace6 } = await this._execPlan(this._plan, []);
    this._lastResultSet = workingSet;
    trace6.name = "Root";
    trace6.details = JSON.stringify({
      id: this._id
    });
    this._trace = trace6;
    const changed = prevResultSet.length !== workingSet.length || prevResultSet.some((item, index) => workingSet[index].objectId !== item.objectId || workingSet[index].spaceId !== item.spaceId || workingSet[index].documentId !== item.documentId);
    if (TRACE_QUERY_EXECUTION) {
      console.log(ExecutionTrace.format(trace6));
    }
    return {
      changed
    };
  }
  async _execPlan(plan, workingSet) {
    const trace6 = ExecutionTrace.makeEmpty();
    const begin = performance.now();
    for (const step of plan.steps) {
      if (this._ctx.disposed) {
        throw new ContextDisposedError();
      }
      const result = await this._execStep(step, workingSet);
      workingSet = result.workingSet;
      trace6.children.push(result.trace);
    }
    trace6.objectCount = workingSet.length;
    trace6.executionTime = performance.now() - begin;
    return {
      workingSet,
      trace: trace6
    };
  }
  async _execStep(step, workingSet) {
    if (this._ctx.disposed) {
      return {
        workingSet,
        trace: ExecutionTrace.makeEmpty()
      };
    }
    let newWorkingSet, trace6;
    const begin = performance.now();
    switch (step._tag) {
      case "ClearWorkingSetStep":
        newWorkingSet = [];
        trace6 = ExecutionTrace.makeEmpty();
        break;
      case "SelectStep":
        ({ workingSet: newWorkingSet, trace: trace6 } = await this._execSelectStep(step, workingSet));
        break;
      case "FilterStep":
        ({ workingSet: newWorkingSet, trace: trace6 } = await this._execFilterStep(step, workingSet));
        break;
      case "FilterDeletedStep":
        ({ workingSet: newWorkingSet, trace: trace6 } = await this._execFilterDeletedStep(step, workingSet));
        break;
      case "UnionStep":
        ({ workingSet: newWorkingSet, trace: trace6 } = await this._execUnionStep(step, workingSet));
        break;
      case "SetDifferenceStep":
        ({ workingSet: newWorkingSet, trace: trace6 } = await this._execSetDifferenceStep(step, workingSet));
        break;
      case "TraverseStep":
        ({ workingSet: newWorkingSet, trace: trace6 } = await this._execTraverseStep(step, workingSet));
        break;
      default:
        throw new Error(`Unknown step type: ${step._tag}`);
    }
    trace6.executionTime = performance.now() - begin;
    return {
      workingSet: newWorkingSet,
      trace: trace6
    };
  }
  async _execSelectStep(step, workingSet) {
    workingSet = [
      ...workingSet
    ];
    const trace6 = {
      ...ExecutionTrace.makeEmpty(),
      name: "Select",
      details: JSON.stringify(step.selector)
    };
    switch (step.selector._tag) {
      case "WildcardSelector": {
        const beginIndexQuery = performance.now();
        const indexHits = await this._indexer.execQuery({
          typenames: [],
          inverted: false
        });
        trace6.indexHits = +indexHits.length;
        trace6.indexQueryTime += performance.now() - beginIndexQuery;
        if (this._ctx.disposed) {
          return {
            workingSet,
            trace: trace6
          };
        }
        const documentLoadStart = performance.now();
        const results = await this._loadDocumentsAfterIndexQuery(indexHits);
        trace6.documentsLoaded += results.length;
        trace6.documentLoadTime += performance.now() - documentLoadStart;
        workingSet.push(...results.filter(isNonNullable2).filter((item) => step.spaces.includes(item.spaceId)));
        trace6.objectCount = workingSet.length;
        break;
      }
      case "IdSelector": {
        const beginLoad = performance.now();
        const items = await Promise.all(step.selector.objectIds.map((id) => this._loadFromDXN(DXN.fromLocalObjectId(id), {
          sourceSpaceId: step.spaces[0]
        })));
        trace6.documentLoadTime += performance.now() - beginLoad;
        workingSet.push(...items.filter(isNonNullable2));
        trace6.objectCount = workingSet.length;
        break;
      }
      case "TypeSelector": {
        const beginIndexQuery = performance.now();
        const indexHits = await this._indexer.execQuery({
          typenames: step.selector.typename,
          inverted: step.selector.inverted
        });
        trace6.indexHits = +indexHits.length;
        trace6.indexQueryTime += performance.now() - beginIndexQuery;
        if (this._ctx.disposed) {
          return {
            workingSet,
            trace: trace6
          };
        }
        const documentLoadStart = performance.now();
        const results = await this._loadDocumentsAfterIndexQuery(indexHits);
        trace6.documentsLoaded += results.length;
        trace6.documentLoadTime += performance.now() - documentLoadStart;
        workingSet.push(...results.filter(isNonNullable2).filter((item) => step.spaces.includes(item.spaceId)));
        trace6.objectCount = workingSet.length;
        break;
      }
      case "TextSelector": {
        const beginIndexQuery = performance.now();
        const indexHits = await this._indexer.execQuery({
          typenames: [],
          text: {
            query: step.selector.text,
            kind: Match.type().pipe(Match.withReturnType(), Match.when("full-text", () => "text"), Match.when("vector", () => "vector"), Match.orElseAbsurd)(step.selector.searchKind)
          }
        });
        trace6.indexHits = +indexHits.length;
        trace6.indexQueryTime += performance.now() - beginIndexQuery;
        if (this._ctx.disposed) {
          return {
            workingSet,
            trace: trace6
          };
        }
        const documentLoadStart = performance.now();
        const results = await this._loadDocumentsAfterIndexQuery(indexHits);
        trace6.documentsLoaded += results.length;
        trace6.documentLoadTime += performance.now() - documentLoadStart;
        workingSet.push(...results.filter(isNonNullable2).filter((item) => step.spaces.includes(item.spaceId)));
        trace6.objectCount = workingSet.length;
        break;
      }
      default:
        throw new Error(`Unknown selector type: ${step.selector._tag}`);
    }
    return {
      workingSet,
      trace: trace6
    };
  }
  async _execFilterStep(step, workingSet) {
    const result = workingSet.filter((item) => filterMatchObject(step.filter, {
      id: item.objectId,
      spaceId: item.spaceId,
      doc: item.doc
    }));
    return {
      workingSet: result,
      trace: {
        ...ExecutionTrace.makeEmpty(),
        name: "Filter",
        details: JSON.stringify(step.filter),
        objectCount: result.length
      }
    };
  }
  async _execFilterDeletedStep(step, workingSet) {
    if (workingSet.length === 6) {
      log9.info("FilterDeletedStep", {
        step,
        workingSet
      }, {
        F: __dxlog_file11,
        L: 386,
        S: this,
        C: (f, a) => f(...a)
      });
    }
    const expected = step.mode === "only-deleted";
    const result = workingSet.filter((item) => ObjectStructure.isDeleted(item.doc) === expected);
    return {
      workingSet: result,
      trace: {
        ...ExecutionTrace.makeEmpty(),
        name: "FilterDeleted",
        details: step.mode,
        objectCount: result.length
      }
    };
  }
  // TODO(dmaretskyi): This needs to be completed.
  async _execTraverseStep(step, workingSet) {
    const trace6 = {
      ...ExecutionTrace.makeEmpty(),
      name: "Traverse",
      details: JSON.stringify(step.traversal)
    };
    const newWorkingSet = [];
    switch (step.traversal._tag) {
      case "ReferenceTraversal": {
        switch (step.traversal.direction) {
          case "outgoing": {
            const property = EscapedPropPath.unescape(step.traversal.property);
            const refs = workingSet.flatMap((item) => {
              const ref = getDeep(item.doc.data, property);
              const refs2 = Array.isArray(ref) ? ref : [
                ref
              ];
              return refs2.map((ref2) => {
                try {
                  return isEncodedReference(ref2) ? {
                    ref: DXN.parse(ref2["/"]),
                    spaceId: item.spaceId
                  } : null;
                } catch {
                  log9.warn("Invalid reference", {
                    ref: ref2["/"]
                  }, {
                    F: __dxlog_file11,
                    L: 431,
                    S: this,
                    C: (f, a) => f(...a)
                  });
                  return null;
                }
              });
            }).filter(isNonNullable2);
            const beginLoad = performance.now();
            const items = await Promise.all(refs.map(({ ref, spaceId }) => this._loadFromDXN(ref, {
              sourceSpaceId: spaceId
            })));
            trace6.documentLoadTime += performance.now() - beginLoad;
            newWorkingSet.push(...items.filter(isNonNullable2));
            trace6.objectCount = newWorkingSet.length;
            break;
          }
          case "incoming": {
            const indexHits = await this._indexer.execQuery({
              typenames: [],
              inverted: false,
              graph: {
                kind: "inbound-reference",
                property: step.traversal.property,
                anchors: workingSet.map((item) => item.objectId)
              }
            });
            trace6.indexHits += indexHits.length;
            const documentLoadStart = performance.now();
            const results = await this._loadDocumentsAfterIndexQuery(indexHits);
            trace6.documentsLoaded += results.length;
            trace6.documentLoadTime += performance.now() - documentLoadStart;
            newWorkingSet.push(...results.filter(isNonNullable2));
            trace6.objectCount = newWorkingSet.length;
            break;
          }
        }
        break;
      }
      case "RelationTraversal": {
        switch (step.traversal.direction) {
          case "relation-to-source":
          case "relation-to-target": {
            const refs = workingSet.map((item) => {
              const ref = step.traversal.direction === "relation-to-source" ? ObjectStructure.getRelationSource(item.doc) : ObjectStructure.getRelationTarget(item.doc);
              if (!isEncodedReference(ref)) {
                return null;
              }
              try {
                return {
                  ref: DXN.parse(ref["/"]),
                  spaceId: item.spaceId
                };
              } catch {
                log9.warn("Invalid reference", {
                  ref: ref["/"]
                }, {
                  F: __dxlog_file11,
                  L: 494,
                  S: this,
                  C: (f, a) => f(...a)
                });
                return null;
              }
            }).filter(isNonNullable2);
            const beginLoad = performance.now();
            const items = await Promise.all(refs.map(({ ref, spaceId }) => this._loadFromDXN(ref, {
              sourceSpaceId: spaceId
            })));
            trace6.documentLoadTime += performance.now() - beginLoad;
            newWorkingSet.push(...items.filter(isNonNullable2));
            trace6.objectCount = newWorkingSet.length;
            break;
          }
          case "source-to-relation":
          case "target-to-relation": {
            const indexHits = await this._indexer.execQuery({
              typenames: [],
              inverted: false,
              graph: {
                kind: step.traversal.direction === "source-to-relation" ? "relation-source" : "relation-target",
                anchors: workingSet.map((item) => item.objectId),
                property: null
              }
            });
            trace6.indexHits += indexHits.length;
            const documentLoadStart = performance.now();
            const results = await this._loadDocumentsAfterIndexQuery(indexHits);
            trace6.documentsLoaded += results.length;
            trace6.documentLoadTime += performance.now() - documentLoadStart;
            newWorkingSet.push(...results.filter(isNonNullable2));
            trace6.objectCount = newWorkingSet.length;
            break;
          }
        }
        break;
      }
      default:
        throw new Error(`Unknown traversal type: ${step.traversal._tag}`);
    }
    return {
      workingSet: newWorkingSet,
      trace: trace6
    };
  }
  async _execUnionStep(step, workingSet) {
    const results = /* @__PURE__ */ new Map();
    const resultSets = await Promise.all(step.plans.map((plan) => this._execPlan(plan, [
      ...workingSet
    ])));
    const trace6 = {
      ...ExecutionTrace.makeEmpty(),
      name: "Union"
    };
    for (const resultSet of resultSets) {
      for (const item of resultSet.workingSet) {
        results.set(`${item.spaceId}:${item.documentId}:${item.objectId}`, item);
      }
      trace6.children.push(resultSet.trace);
    }
    return {
      workingSet: [
        ...results.values()
      ],
      trace: trace6
    };
  }
  async _execSetDifferenceStep(step, workingSet) {
    const trace6 = {
      ...ExecutionTrace.makeEmpty(),
      name: "SetDifference"
    };
    const sourceResult = await this._execPlan(step.source, [
      ...workingSet
    ]);
    const excludeResult = await this._execPlan(step.exclude, [
      ...workingSet
    ]);
    trace6.children.push(sourceResult.trace, excludeResult.trace);
    return {
      workingSet: sourceResult.workingSet.filter((item) => {
        const index = excludeResult.workingSet.findIndex((i) => i.objectId === item.objectId);
        return index === -1;
      }),
      trace: trace6
    };
  }
  async _loadDocumentsAfterIndexQuery(indexHits) {
    return Promise.all(indexHits.map(async (hit) => {
      return this._loadFromIndexHit(hit);
    }));
  }
  async _loadFromIndexHit(hit) {
    const { objectId, documentId, spaceKey: spaceKeyInIndex } = objectPointerCodec3.decode(hit.id);
    const handle = await this._automergeHost.loadDoc(Context3.default(void 0, {
      F: __dxlog_file11,
      L: 604
    }), documentId);
    const doc = handle.doc();
    if (!doc) {
      return null;
    }
    const spaceKey = spaceKeyInIndex ?? DatabaseDirectory3.getSpaceKey(doc);
    if (!spaceKey) {
      return null;
    }
    const object = DatabaseDirectory3.getInlineObject(doc, objectId);
    if (!object) {
      return null;
    }
    return {
      objectId,
      documentId,
      spaceId: await createIdFromSpaceKey(PublicKey3.from(spaceKey)),
      doc: object
    };
  }
  async _loadFromDXN(dxn, { sourceSpaceId }) {
    const echoDxn = dxn.asEchoDXN();
    if (!echoDxn) {
      log9.warn("unable to resolve DXN", {
        dxn
      }, {
        F: __dxlog_file11,
        L: 631,
        S: this,
        C: (f, a) => f(...a)
      });
      return null;
    }
    const spaceId = echoDxn.spaceId ?? sourceSpaceId;
    const spaceRoot = this._spaceStateManager.getRootBySpaceId(spaceId);
    if (!spaceRoot) {
      log9.warn("no space state found for", {
        spaceId
      }, {
        F: __dxlog_file11,
        L: 639,
        S: this,
        C: (f, a) => f(...a)
      });
      return null;
    }
    const dbDirectory = spaceRoot.doc();
    if (!dbDirectory) {
      log9.warn("no space state found for", {
        spaceId
      }, {
        F: __dxlog_file11,
        L: 644,
        S: this,
        C: (f, a) => f(...a)
      });
      return null;
    }
    const inlineObject = DatabaseDirectory3.getInlineObject(dbDirectory, echoDxn.echoId);
    if (inlineObject) {
      return {
        objectId: echoDxn.echoId,
        documentId: spaceRoot.documentId,
        spaceId,
        doc: inlineObject
      };
    }
    const link = DatabaseDirectory3.getLink(dbDirectory, echoDxn.echoId);
    if (!link) {
      return null;
    }
    const handle = await this._automergeHost.loadDoc(Context3.default(void 0, {
      F: __dxlog_file11,
      L: 663
    }), link);
    const doc = handle.doc();
    if (!doc) {
      return null;
    }
    const object = DatabaseDirectory3.getInlineObject(doc, echoDxn.echoId);
    if (!object) {
      return null;
    }
    return {
      objectId: echoDxn.echoId,
      documentId: handle.documentId,
      spaceId,
      doc: object
    };
  }
};

// packages/core/echo/echo-pipeline/src/db-host/query-service.ts
function _ts_decorate5(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file12 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/query-service.ts";
var QueryServiceImpl = class extends Resource7 {
  // TODO(burdon): OK for options, but not params. Pass separately and type readonly here.
  constructor(_params) {
    super(), this._params = _params, this._queries = /* @__PURE__ */ new Set();
    trace4.diagnostic({
      id: "active-queries",
      name: "Active Queries",
      fetch: () => {
        return Array.from(this._queries).map((query) => {
          return {
            query: JSON.stringify(query.executor.query),
            plan: JSON.stringify(query.executor.plan),
            trace: JSON.stringify(query.executor.trace)
          };
        });
      }
    });
  }
  async _open() {
    this._params.indexer.updated.on(this._ctx, () => this.invalidateQueries());
    this._updateQueries = new DeferredTask(this._ctx, this._executeQueries.bind(this));
  }
  async _close() {
    await this._updateQueries.join();
    await Promise.all(Array.from(this._queries).map((query) => query.close()));
  }
  async setConfig(config) {
    await this._params.indexer.setConfig(config);
  }
  execQuery(request) {
    return new Stream2(({ next, close, ctx }) => {
      const queryEntry = this._createQuery(ctx, request, next, close, close);
      scheduleMicroTask(ctx, async () => {
        await queryEntry.executor.open();
        queryEntry.open = true;
        this._updateQueries.schedule();
      });
      return queryEntry.close;
    });
  }
  /**
  * Re-index all loaded documents.
  */
  async reindex() {
    log10("Reindexing all documents...", void 0, {
      F: __dxlog_file12,
      L: 113,
      S: this,
      C: (f, a) => f(...a)
    });
    const iterator = createDocumentsIterator(this._params.automergeHost);
    const ids = /* @__PURE__ */ new Map();
    for await (const documents of iterator()) {
      for (const { id, heads } of documents) {
        ids.set(id, heads);
      }
      if (ids.size % 100 === 0) {
        log10("Collected documents...", {
          count: ids.size
        }, {
          F: __dxlog_file12,
          L: 121,
          S: this,
          C: (f, a) => f(...a)
        });
      }
    }
    log10("Marking all documents as dirty...", {
      count: ids.size
    }, {
      F: __dxlog_file12,
      L: 125,
      S: this,
      C: (f, a) => f(...a)
    });
    await this._params.indexer.reindex(ids);
  }
  /**
  * Schedule re-execution of all queries.
  */
  invalidateQueries() {
    for (const query of this._queries) {
      query.dirty = true;
    }
    this._updateQueries.schedule();
  }
  _createQuery(ctx, request, onResults, onError, onClose) {
    const parsedQuery = QueryAST.Query.pipe(Schema.decodeUnknownSync)(JSON.parse(request.query));
    const queryEntry = {
      executor: new QueryExecutor({
        indexer: this._params.indexer,
        automergeHost: this._params.automergeHost,
        queryId: request.queryId ?? raise(new Error("query id required")),
        query: parsedQuery,
        reactivity: request.reactivity,
        spaceStateManager: this._params.spaceStateManager
      }),
      dirty: true,
      open: false,
      firstResult: true,
      sendResults: (results) => {
        if (ctx.disposed) {
          return;
        }
        onResults({
          queryId: request.queryId,
          results
        });
      },
      onError,
      close: async () => {
        onClose();
        await queryEntry.executor.close();
        this._queries.delete(queryEntry);
      }
    };
    this._queries.add(queryEntry);
    return queryEntry;
  }
  async _executeQueries() {
    const begin = performance.now();
    let count = 0;
    await Promise.all(Array.from(this._queries).map(async (query) => {
      if (!query.dirty || !query.open) {
        return;
      }
      count++;
      try {
        const { changed } = await query.executor.execQuery();
        query.dirty = false;
        if (changed || query.firstResult) {
          query.firstResult = false;
          query.sendResults(query.executor.getResults());
        }
      } catch (err) {
        log10.catch(err, void 0, {
          F: __dxlog_file12,
          L: 196,
          S: this,
          C: (f, a) => f(...a)
        });
      }
    }));
    log10.verbose("executed queries", {
      count,
      duration: performance.now() - begin
    }, {
      F: __dxlog_file12,
      L: 200,
      S: this,
      C: (f, a) => f(...a)
    });
  }
};
_ts_decorate5([
  synchronized2
], QueryServiceImpl.prototype, "_close", null);
_ts_decorate5([
  trace4.span({
    showInBrowserTimeline: true
  })
], QueryServiceImpl.prototype, "_executeQueries", null);
QueryServiceImpl = _ts_decorate5([
  trace4.resource()
], QueryServiceImpl);
var createDocumentsIterator = (automergeHost) => (
  /**
  * Recursively get all object data blobs from loaded documents from Automerge Repo.
  */
  // TODO(mykola): Unload automerge handles after usage.
  async function* getAllDocuments() {
    const visited = /* @__PURE__ */ new Set();
    async function* getObjectsFromHandle(handle) {
      if (visited.has(handle.documentId) || !handle.isReady()) {
        return;
      }
      const doc = handle.doc();
      const spaceKey = DatabaseDirectory4.getSpaceKey(doc) ?? void 0;
      if (doc.objects) {
        yield Object.entries(doc.objects).map(([objectId, object]) => {
          return {
            id: objectPointerCodec4.encode({
              documentId: handle.documentId,
              objectId,
              spaceKey
            }),
            object,
            heads: getHeads3(doc)
          };
        });
      }
      if (doc.links) {
        for (const id of Object.values(doc.links)) {
          const urlString = id.toString();
          if (visited.has(urlString)) {
            continue;
          }
          const linkHandle = await automergeHost.loadDoc(Context4.default(void 0, {
            F: __dxlog_file12,
            L: 240
          }), urlString);
          for await (const result of getObjectsFromHandle(linkHandle)) {
            yield result;
          }
        }
      }
      visited.add(handle.documentId);
    }
    for (const handle of Object.values(automergeHost.repo.handles)) {
      if (visited.has(handle.documentId)) {
        continue;
      }
      for await (const result of getObjectsFromHandle(handle)) {
        yield result;
      }
      visited.add(handle.documentId);
    }
  }
);

// packages/core/echo/echo-pipeline/src/db-host/space-state-manager.ts
import { interpretAsDocumentId as interpretAsDocumentId3 } from "@automerge/automerge-repo";
import isEqual from "lodash.isequal";
import { Event as Event3, UpdateScheduler as UpdateScheduler3 } from "@dxos/async";
import { Resource as Resource8, Context as Context5, LifecycleState as LifecycleState4 } from "@dxos/context";
import { invariant as invariant12 } from "@dxos/invariant";

// packages/core/echo/echo-pipeline/src/db-host/database-root.ts
import { interpretAsDocumentId as interpretAsDocumentId2 } from "@automerge/automerge-repo";
import { DatabaseDirectory as DatabaseDirectory5, SpaceDocVersion as SpaceDocVersion2 } from "@dxos/echo-protocol";
import { invariant as invariant11 } from "@dxos/invariant";

// packages/core/echo/echo-pipeline/src/db-host/automerge-metrics.ts
import * as A4 from "@automerge/automerge";
import { log as log11 } from "@dxos/log";
var __dxlog_file13 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/automerge-metrics.ts";
var measureDocMetrics = (doc) => {
  const snapshot = A4.save(doc);
  const start = Date.now();
  const temp = A4.load(snapshot);
  const end = Date.now();
  A4.free(temp);
  const getAllChangesStart = Date.now();
  const mutationCount = A4.getAllChanges(doc).length;
  const getAllChangesEnd = Date.now();
  if (getAllChangesEnd - getAllChangesStart > 300) {
    log11.warn("getAllChanges took too long", {
      elapsed: getAllChangesEnd - getAllChangesStart
    }, {
      F: __dxlog_file13,
      L: 31,
      S: void 0,
      C: (f, a) => f(...a)
    });
  }
  return {
    compressedByteSize: snapshot.byteLength,
    loadTime: end - start,
    mutationCount
  };
};

// packages/core/echo/echo-pipeline/src/db-host/database-root.ts
var __dxlog_file14 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/database-root.ts";
var DatabaseRoot = class {
  static mapLinks(doc, mapping) {
    doc.change((d) => {
      if (!d.links) {
        return;
      }
      for (const [key, value] of Object.entries(d.links)) {
        const documentId = interpretAsDocumentId2(value.toString());
        if (mapping[documentId]) {
          d.links[key] = `automerge:${mapping[documentId]}`;
        }
      }
    });
  }
  constructor(_rootHandle) {
    this._rootHandle = _rootHandle;
  }
  get documentId() {
    return this._rootHandle.documentId;
  }
  get url() {
    return this._rootHandle.url;
  }
  get isLoaded() {
    return this._rootHandle.isReady();
  }
  get handle() {
    return this._rootHandle;
  }
  doc() {
    return this._rootHandle.isReady() ? this._rootHandle.doc() : null;
  }
  getVersion() {
    const doc = this.doc();
    if (!doc) {
      return null;
    }
    return doc.version ?? SpaceDocVersion2.LEGACY;
  }
  getSpaceKey() {
    const doc = this.doc();
    if (!doc) {
      return null;
    }
    return DatabaseDirectory5.getSpaceKey(doc);
  }
  getInlineObjectCount() {
    const doc = this.doc();
    if (!doc) {
      return null;
    }
    return Object.keys(doc.objects ?? {}).length;
  }
  getLinkedObjectCount() {
    const doc = this.doc();
    if (!doc) {
      return null;
    }
    return Object.keys(doc.links ?? {}).length;
  }
  getAllLinkedDocuments() {
    const doc = this.doc();
    invariant11(doc, void 0, {
      F: __dxlog_file14,
      L: 88,
      S: this,
      A: [
        "doc",
        ""
      ]
    });
    return Object.values(doc.links ?? {}).map((s) => s.toString());
  }
  measureMetrics() {
    const doc = this.doc();
    if (!doc) {
      return null;
    }
    return measureDocMetrics(doc);
  }
};

// packages/core/echo/echo-pipeline/src/db-host/space-state-manager.ts
var __dxlog_file15 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/space-state-manager.ts";
var SpaceStateManager = class extends Resource8 {
  constructor() {
    super(...arguments);
    this._roots = /* @__PURE__ */ new Map();
    this._rootBySpace = /* @__PURE__ */ new Map();
    this._perRootContext = /* @__PURE__ */ new Map();
    this._lastSpaceDocumentList = /* @__PURE__ */ new Map();
    this.spaceDocumentListUpdated = new Event3();
  }
  async _close(ctx) {
    for (const [_, rootCtx] of this._perRootContext) {
      await rootCtx.dispose();
    }
    this._roots.clear();
  }
  get roots() {
    return this._roots;
  }
  getRootByDocumentId(documentId) {
    return this._roots.get(documentId);
  }
  getSpaceRootDocumentId(spaceId) {
    return this._rootBySpace.get(spaceId);
  }
  getRootBySpaceId(spaceId) {
    invariant12(this._lifecycleState === LifecycleState4.OPEN, void 0, {
      F: __dxlog_file15,
      L: 44,
      S: this,
      A: [
        "this._lifecycleState === LifecycleState.OPEN",
        ""
      ]
    });
    const documentId = this._rootBySpace.get(spaceId);
    if (!documentId) {
      return void 0;
    }
    return this._roots.get(documentId);
  }
  async assignRootToSpace(spaceId, handle) {
    let root;
    if (this._roots.has(handle.documentId)) {
      root = this._roots.get(handle.documentId);
    } else {
      root = new DatabaseRoot(handle);
      this._roots.set(handle.documentId, root);
    }
    if (this._rootBySpace.get(spaceId) === root.handle.documentId) {
      return root;
    }
    const prevRootId = this._rootBySpace.get(spaceId);
    if (prevRootId) {
      void this._perRootContext.get(prevRootId)?.dispose();
      this._perRootContext.delete(prevRootId);
    }
    this._rootBySpace.set(spaceId, root.handle.documentId);
    const ctx = new Context5(void 0, {
      F: __dxlog_file15,
      L: 72
    });
    this._perRootContext.set(root.handle.documentId, ctx);
    await root.handle.whenReady();
    const documentListCheckScheduler = new UpdateScheduler3(ctx, async () => {
      const documentIds = [
        root.documentId,
        ...root.getAllLinkedDocuments().map((url) => interpretAsDocumentId3(url))
      ];
      if (!isEqual(documentIds, this._lastSpaceDocumentList.get(spaceId))) {
        this._lastSpaceDocumentList.set(spaceId, documentIds);
        this.spaceDocumentListUpdated.emit(new SpaceDocumentListUpdatedEvent(spaceId, root.documentId, prevRootId, documentIds));
      }
    }, {
      maxFrequency: 50
    });
    const triggerCheckOnChange = () => documentListCheckScheduler.trigger();
    root.handle.addListener("change", triggerCheckOnChange);
    ctx.onDispose(() => root.handle.removeListener("change", triggerCheckOnChange));
    documentListCheckScheduler.trigger();
    return root;
  }
};
var SpaceDocumentListUpdatedEvent = class {
  constructor(spaceId, spaceRootId, previousRootId, documentIds) {
    this.spaceId = spaceId;
    this.spaceRootId = spaceRootId;
    this.previousRootId = previousRootId;
    this.documentIds = documentIds;
  }
};

// packages/core/echo/echo-pipeline/src/db-host/echo-host.ts
var __dxlog_file16 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/db-host/echo-host.ts";
var DEFAULT_INDEXING_CONFIG = {
  // TODO(dmaretskyi): Disabled by default since embedding generation is expensive.
  fullText: false,
  vector: false
};
var EchoHost = class extends Resource9 {
  constructor({ kv, indexing = {}, peerIdProvider, getSpaceKeyByRootDocumentId }) {
    super();
    this._spaceStateManager = new SpaceStateManager();
    const indexingConfig = {
      ...DEFAULT_INDEXING_CONFIG,
      ...indexing
    };
    this._indexMetadataStore = new IndexMetadataStore({
      db: kv.sublevel("index-metadata")
    });
    this._echoDataMonitor = new EchoDataMonitor();
    this._automergeHost = new AutomergeHost({
      db: kv,
      dataMonitor: this._echoDataMonitor,
      indexMetadataStore: this._indexMetadataStore,
      peerIdProvider,
      getSpaceKeyByRootDocumentId
    });
    this._indexer = new Indexer({
      db: kv,
      indexStore: new IndexStore({
        db: kv.sublevel("index-storage")
      }),
      metadataStore: this._indexMetadataStore,
      loadDocuments: createSelectedDocumentsIterator(this._automergeHost),
      indexCooldownTime: false ? 0 : void 0
    });
    void this._indexer.setConfig({
      enabled: true,
      indexes: [
        //
        {
          kind: IndexKind.Kind.SCHEMA_MATCH
        },
        {
          kind: IndexKind.Kind.GRAPH
        },
        ...indexingConfig.fullText ? [
          {
            kind: IndexKind.Kind.FULL_TEXT
          }
        ] : [],
        ...indexingConfig.vector ? [
          {
            kind: IndexKind.Kind.VECTOR
          }
        ] : []
      ]
    });
    this._queryService = new QueryServiceImpl({
      automergeHost: this._automergeHost,
      indexer: this._indexer,
      spaceStateManager: this._spaceStateManager
    });
    this._dataService = new DataServiceImpl({
      automergeHost: this._automergeHost,
      spaceStateManager: this._spaceStateManager,
      updateIndexes: async () => {
        await this._indexer.updateIndexes();
      }
    });
    trace5.diagnostic({
      id: "echo-stats",
      name: "Echo Stats",
      fetch: async () => {
        return {
          dataStats: this._echoDataMonitor.computeStats(),
          loadedDocsCount: this._automergeHost.loadedDocsCount
        };
      }
    });
    trace5.diagnostic({
      id: "database-roots",
      name: "Database Roots",
      fetch: async () => {
        return Array.from(this._spaceStateManager.roots.values()).map((root) => ({
          url: root.url,
          isLoaded: root.isLoaded,
          spaceKey: root.getSpaceKey(),
          inlineObjects: root.getInlineObjectCount(),
          linkedObjects: root.getLinkedObjectCount()
        }));
      }
    });
    trace5.diagnostic({
      id: "database-root-metrics",
      name: "Database Roots (with metrics)",
      fetch: async () => {
        return Array.from(this._spaceStateManager.roots.values()).map((root) => ({
          url: root.url,
          isLoaded: root.isLoaded,
          spaceKey: root.getSpaceKey(),
          inlineObjects: root.getInlineObjectCount(),
          linkedObjects: root.getLinkedObjectCount(),
          ...root.measureMetrics() ?? {}
        }));
      }
    });
  }
  get queryService() {
    return this._queryService;
  }
  get dataService() {
    return this._dataService;
  }
  /**
  * @deprecated To be abstracted away.
  */
  get automergeRepo() {
    return this._automergeHost.repo;
  }
  get roots() {
    return this._spaceStateManager.roots;
  }
  async _open(ctx) {
    await this._automergeHost.open();
    await this._indexer.open(ctx);
    await this._queryService.open(ctx);
    await this._spaceStateManager.open(ctx);
    this._spaceStateManager.spaceDocumentListUpdated.on(this._ctx, (e) => {
      if (e.previousRootId) {
        void this._automergeHost.clearLocalCollectionState(deriveCollectionIdFromSpaceId(e.spaceId, e.previousRootId));
      }
      void this._automergeHost.updateLocalCollectionState(deriveCollectionIdFromSpaceId(e.spaceId), e.documentIds);
      void this._automergeHost.updateLocalCollectionState(deriveCollectionIdFromSpaceId(e.spaceId, e.spaceRootId), e.documentIds);
    });
    this._automergeHost.documentsSaved.on(this._ctx, () => {
      this._queryService.invalidateQueries();
    });
  }
  async _close(ctx) {
    await this._queryService.close(ctx);
    await this._spaceStateManager.close(ctx);
    await this._indexer.close(ctx);
    await this._automergeHost.close();
  }
  /**
  * Flush all pending writes to the underlying storage.
  */
  async flush() {
    await this._automergeHost.repo.flush();
  }
  /**
  * Perform any pending index updates.
  */
  async updateIndexes() {
    await this._indexer.updateIndexes();
  }
  /**
  * Loads the document handle from the repo and waits for it to be ready.
  */
  async loadDoc(ctx, documentId, opts) {
    return await this._automergeHost.loadDoc(ctx, documentId, opts);
  }
  async exportDoc(ctx, id) {
    return await this._automergeHost.exportDoc(ctx, id);
  }
  /**
  * Create new persisted document.
  */
  createDoc(initialValue, opts) {
    return this._automergeHost.createDoc(initialValue, opts);
  }
  /**
  * Create new space root.
  */
  async createSpaceRoot(spaceKey) {
    invariant13(this._lifecycleState === LifecycleState5.OPEN, void 0, {
      F: __dxlog_file16,
      L: 255,
      S: this,
      A: [
        "this._lifecycleState === LifecycleState.OPEN",
        ""
      ]
    });
    const spaceId = await createIdFromSpaceKey2(spaceKey);
    const automergeRoot = this._automergeHost.createDoc({
      version: SpaceDocVersion3.CURRENT,
      access: {
        spaceKey: spaceKey.toHex()
      },
      // Better to initialize them right away to avoid merge conflicts and data loss that can occur if those maps get created on the fly.
      objects: {},
      links: {}
    });
    await this._automergeHost.flush({
      documentIds: [
        automergeRoot.documentId
      ]
    });
    return await this.openSpaceRoot(spaceId, automergeRoot.url);
  }
  // TODO(dmaretskyi): Change to document id.
  async openSpaceRoot(spaceId, automergeUrl) {
    invariant13(this._lifecycleState === LifecycleState5.OPEN, void 0, {
      F: __dxlog_file16,
      L: 274,
      S: this,
      A: [
        "this._lifecycleState === LifecycleState.OPEN",
        ""
      ]
    });
    const handle = await this._automergeHost.repo.find(automergeUrl, FIND_PARAMS);
    await handle.whenReady();
    return this._spaceStateManager.assignRootToSpace(spaceId, handle);
  }
  // TODO(dmaretskyi): Change to document id.
  async closeSpaceRoot(automergeUrl) {
    todo();
  }
  /**
  * Install data replicator.
  */
  async addReplicator(replicator) {
    await this._automergeHost.addReplicator(replicator);
  }
  /**
  * Remove data replicator.
  */
  async removeReplicator(replicator) {
    await this._automergeHost.removeReplicator(replicator);
  }
};

// packages/core/echo/echo-pipeline/src/edge/echo-edge-replicator.ts
import { cbor as cbor2 } from "@automerge/automerge-repo";
import { Mutex, scheduleTask as scheduleTask2, scheduleMicroTask as scheduleMicroTask2 } from "@dxos/async";
import { Context as Context6, Resource as Resource11 } from "@dxos/context";
import { randomUUID } from "@dxos/crypto";
import { invariant as invariant14 } from "@dxos/invariant";
import { log as log13 } from "@dxos/log";
import { EdgeService } from "@dxos/protocols";
import { buf } from "@dxos/protocols/buf";
import { MessageSchema as RouterMessageSchema } from "@dxos/protocols/buf/dxos/edge/messenger_pb";
import { bufferToArray as bufferToArray2 } from "@dxos/util";

// packages/core/echo/echo-pipeline/src/edge/inflight-request-limiter.ts
import { Trigger as Trigger2 } from "@dxos/async";
import { Resource as Resource10 } from "@dxos/context";
import { log as log12 } from "@dxos/log";
var __dxlog_file17 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/edge/inflight-request-limiter.ts";
var InflightRequestLimiter = class extends Resource10 {
  constructor(_config) {
    super(), this._config = _config, this._inflightRequestBalance = 0, this._requestBarrier = new Trigger2();
  }
  async _open() {
    this._inflightRequestBalance = 0;
    this._requestBarrier.reset();
    this._requestBarrier.wake();
  }
  async _close() {
    this._inflightRequestBalance = 0;
    this._requestBarrier.throw(new Error("Rate limiter closed."));
    clearTimeout(this._resetBalanceTimeout);
  }
  async rateLimit(message) {
    if (message.type !== "sync") {
      return;
    }
    while (this._inflightRequestBalance >= this._config.maxInflightRequests) {
      await this._requestBarrier.wait();
    }
    this._inflightRequestBalance++;
    if (this._inflightRequestBalance === this._config.maxInflightRequests) {
      this._requestBarrier.reset();
      this._resetBalanceTimeout = setTimeout(() => {
        log12.warn("Request balance has not changed during specified timeout, resetting request limiter.", void 0, {
          F: __dxlog_file17,
          L: 52,
          S: this,
          C: (f, a) => f(...a)
        });
        this._inflightRequestBalance = 0;
        this._requestBarrier.wake();
      }, this._config.resetBalanceTimeoutMs);
    }
  }
  handleResponse(message) {
    if (message.type !== "sync") {
      return;
    }
    this._inflightRequestBalance--;
    if (this._inflightRequestBalance + 1 === this._config.maxInflightRequests) {
      this._requestBarrier.wake();
      clearInterval(this._resetBalanceTimeout);
    }
  }
};

// packages/core/echo/echo-pipeline/src/edge/echo-edge-replicator.ts
function _ts_add_disposable_resource(env, value, async) {
  if (value !== null && value !== void 0) {
    if (typeof value !== "object" && typeof value !== "function") throw new TypeError("Object expected.");
    var dispose, inner;
    if (async) {
      if (!Symbol.asyncDispose) throw new TypeError("Symbol.asyncDispose is not defined.");
      dispose = value[Symbol.asyncDispose];
    }
    if (dispose === void 0) {
      if (!Symbol.dispose) throw new TypeError("Symbol.dispose is not defined.");
      dispose = value[Symbol.dispose];
      if (async) inner = dispose;
    }
    if (typeof dispose !== "function") throw new TypeError("Object not disposable.");
    if (inner) dispose = function() {
      try {
        inner.call(this);
      } catch (e) {
        return Promise.reject(e);
      }
    };
    env.stack.push({
      value,
      dispose,
      async
    });
  } else if (async) {
    env.stack.push({
      async: true
    });
  }
  return value;
}
function _ts_dispose_resources(env) {
  var _SuppressedError = typeof SuppressedError === "function" ? SuppressedError : function(error, suppressed, message) {
    var e = new Error(message);
    return e.name = "SuppressedError", e.error = error, e.suppressed = suppressed, e;
  };
  return (_ts_dispose_resources = function _ts_dispose_resources2(env2) {
    function fail(e) {
      env2.error = env2.hasError ? new _SuppressedError(e, env2.error, "An error was suppressed during disposal.") : e;
      env2.hasError = true;
    }
    var r, s = 0;
    function next() {
      while (r = env2.stack.pop()) {
        try {
          if (!r.async && s === 1) return s = 0, env2.stack.push(r), Promise.resolve().then(next);
          if (r.dispose) {
            var result = r.dispose.call(r.value);
            if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) {
              fail(e);
              return next();
            });
          } else s |= 1;
        } catch (e) {
          fail(e);
        }
      }
      if (s === 1) return env2.hasError ? Promise.reject(env2.error) : Promise.resolve();
      if (env2.hasError) throw env2.error;
    }
    return next();
  })(env);
}
var __dxlog_file18 = "/home/runner/work/dxos/dxos/packages/core/echo/echo-pipeline/src/edge/echo-edge-replicator.ts";
var INITIAL_RESTART_DELAY = 500;
var RESTART_DELAY_JITTER = 250;
var MAX_RESTART_DELAY = 5e3;
var EchoEdgeReplicator = class {
  constructor({ edgeConnection, disableSharePolicy }) {
    this._mutex = new Mutex();
    this._ctx = void 0;
    this._context = null;
    this._connectedSpaces = /* @__PURE__ */ new Set();
    this._connections = /* @__PURE__ */ new Map();
    this._sharePolicyEnabled = true;
    this._edgeConnection = edgeConnection;
    this._sharePolicyEnabled = !disableSharePolicy;
  }
  async connect(context) {
    log13("connecting...", {
      peerId: context.peerId,
      connectedSpaces: this._connectedSpaces.size
    }, {
      F: __dxlog_file18,
      L: 61,
      S: this,
      C: (f, a) => f(...a)
    });
    this._context = context;
    this._ctx = Context6.default(void 0, {
      F: __dxlog_file18,
      L: 63
    });
    this._ctx.onDispose(this._edgeConnection.onReconnected(() => {
      this._ctx && scheduleMicroTask2(this._ctx, () => this._handleReconnect());
    }));
  }
  async _handleReconnect() {
    const env = {
      stack: [],
      error: void 0,
      hasError: false
    };
    try {
      const _guard = _ts_add_disposable_resource(env, await this._mutex.acquire(), false);
      const spaces = [
        ...this._connectedSpaces
      ];
      for (const connection of this._connections.values()) {
        await connection.close();
      }
      this._connections.clear();
      if (this._context !== null) {
        for (const spaceId of spaces) {
          await this._openConnection(spaceId);
        }
      }
    } catch (e) {
      env.error = e;
      env.hasError = true;
    } finally {
      _ts_dispose_resources(env);
    }
  }
  async disconnect() {
    const env = {
      stack: [],
      error: void 0,
      hasError: false
    };
    try {
      const _guard = _ts_add_disposable_resource(env, await this._mutex.acquire(), false);
      await this._ctx?.dispose();
      for (const connection of this._connections.values()) {
        await connection.close();
      }
      this._connections.clear();
    } catch (e) {
      env.error = e;
      env.hasError = true;
    } finally {
      _ts_dispose_resources(env);
    }
  }
  async connectToSpace(spaceId) {
    const env = {
      stack: [],
      error: void 0,
      hasError: false
    };
    try {
      const _guard = _ts_add_disposable_resource(env, await this._mutex.acquire(), false);
      if (this._connectedSpaces.has(spaceId)) {
        return;
      }
      this._connectedSpaces.add(spaceId);
      if (this._context !== null) {
        await this._openConnection(spaceId);
      }
    } catch (e) {
      env.error = e;
      env.hasError = true;
    } finally {
      _ts_dispose_resources(env);
    }
  }
  async disconnectFromSpace(spaceId) {
    const env = {
      stack: [],
      error: void 0,
      hasError: false
    };
    try {
      const _guard = _ts_add_disposable_resource(env, await this._mutex.acquire(), false);
      this._connectedSpaces.delete(spaceId);
      const connection = this._connections.get(spaceId);
      if (connection) {
        await connection.close();
        this._connections.delete(spaceId);
      }
    } catch (e) {
      env.error = e;
      env.hasError = true;
    } finally {
      _ts_dispose_resources(env);
    }
  }
  async _openConnection(spaceId, reconnects = 0) {
    invariant14(this._context, void 0, {
      F: __dxlog_file18,
      L: 124,
      S: this,
      A: [
        "this._context",
        ""
      ]
    });
    invariant14(!this._connections.has(spaceId), void 0, {
      F: __dxlog_file18,
      L: 125,
      S: this,
      A: [
        "!this._connections.has(spaceId)",
        ""
      ]
    });
    let restartScheduled = false;
    const connection = new EdgeReplicatorConnection({
      edgeConnection: this._edgeConnection,
      spaceId,
      context: this._context,
      sharedPolicyEnabled: this._sharePolicyEnabled,
      onRemoteConnected: async () => {
        this._context?.onConnectionOpen(connection);
      },
      onRemoteDisconnected: async () => {
        this._context?.onConnectionClosed(connection);
      },
      onRestartRequested: async () => {
        if (!this._ctx || restartScheduled) {
          return;
        }
        const restartDelay = Math.min(MAX_RESTART_DELAY, INITIAL_RESTART_DELAY * reconnects) + Math.random() * RESTART_DELAY_JITTER;
        log13("connection restart scheduled", {
          spaceId,
          reconnects,
          restartDelay
        }, {
          F: __dxlog_file18,
          L: 148,
          S: this,
          C: (f, a) => f(...a)
        });
        restartScheduled = true;
        scheduleTask2(this._ctx, async () => {
          const env = {
            stack: [],
            error: void 0,
            hasError: false
          };
          try {
            const _guard = _ts_add_disposable_resource(env, await this._mutex.acquire(), false);
            if (this._connections.get(spaceId) !== connection) {
              return;
            }
            const ctx = this._ctx;
            await connection.close();
            this._connections.delete(spaceId);
            if (ctx?.disposed) {
              return;
            }
            await this._openConnection(spaceId, reconnects + 1);
          } catch (e) {
            env.error = e;
            env.hasError = true;
          } finally {
            _ts_dispose_resources(env);
          }
        }, restartDelay);
      }
    });
    this._connections.set(spaceId, connection);
    await connection.open();
  }
};
var MAX_INFLIGHT_REQUESTS = 5;
var MAX_RATE_LIMIT_WAIT_TIME_MS = 3e3;
var EdgeReplicatorConnection = class extends Resource11 {
  constructor({ edgeConnection, spaceId, context, sharedPolicyEnabled, onRemoteConnected, onRemoteDisconnected, onRestartRequested }) {
    super();
    this._remotePeerId = null;
    this._requestLimiter = new InflightRequestLimiter({
      maxInflightRequests: MAX_INFLIGHT_REQUESTS,
      resetBalanceTimeoutMs: MAX_RATE_LIMIT_WAIT_TIME_MS
    });
    this._edgeConnection = edgeConnection;
    this._spaceId = spaceId;
    this._context = context;
    this._remotePeerId = `${EdgeService.AUTOMERGE_REPLICATOR}:${spaceId}-${randomUUID()}`;
    this._targetServiceId = `${EdgeService.AUTOMERGE_REPLICATOR}:${spaceId}`;
    this._sharedPolicyEnabled = sharedPolicyEnabled;
    this._onRemoteConnected = onRemoteConnected;
    this._onRemoteDisconnected = onRemoteDisconnected;
    this._onRestartRequested = onRestartRequested;
    this.readable = new ReadableStream({
      start: (controller) => {
        this._readableStreamController = controller;
      }
    });
    this.writable = new WritableStream({
      write: async (message, controller) => {
        await this._requestLimiter.rateLimit(message);
        await this._sendMessage(message);
      }
    });
  }
  async _open(ctx) {
    log13("opening...", void 0, {
      F: __dxlog_file18,
      L: 251,
      S: this,
      C: (f, a) => f(...a)
    });
    await this._requestLimiter.open();
    this._ctx.onDispose(this._edgeConnection.onMessage((msg) => {
      this._onMessage(msg);
    }));
    await this._onRemoteConnected();
  }
  async _close() {
    log13("closing...", void 0, {
      F: __dxlog_file18,
      L: 266,
      S: this,
      C: (f, a) => f(...a)
    });
    this._readableStreamController.close();
    await this._requestLimiter.close();
    await this._onRemoteDisconnected();
  }
  get peerId() {
    invariant14(this._remotePeerId, "Not connected", {
      F: __dxlog_file18,
      L: 275,
      S: this,
      A: [
        "this._remotePeerId",
        "'Not connected'"
      ]
    });
    return this._remotePeerId;
  }
  async shouldAdvertise(params) {
    if (!this._sharedPolicyEnabled) {
      return true;
    }
    const spaceId = await this._context.getContainingSpaceIdForDocument(params.documentId);
    if (!spaceId) {
      const remoteDocumentExists = await this._context.isDocumentInRemoteCollection({
        documentId: params.documentId,
        peerId: this._remotePeerId
      });
      log13.verbose("document not found locally for share policy check", {
        documentId: params.documentId,
        acceptDocument: remoteDocumentExists,
        remoteId: this._remotePeerId
      }, {
        F: __dxlog_file18,
        L: 290,
        S: this,
        C: (f, a) => f(...a)
      });
      return remoteDocumentExists;
    }
    return spaceId === this._spaceId;
  }
  shouldSyncCollection(params) {
    if (!this._sharedPolicyEnabled) {
      return true;
    }
    const spaceId = getSpaceIdFromCollectionId(params.collectionId);
    return spaceId === this._spaceId && params.collectionId.split(":").length === 3;
  }
  _onMessage(message) {
    if (message.serviceId !== this._targetServiceId) {
      return;
    }
    const payload = cbor2.decode(message.payload.value);
    log13.verbose("received", {
      type: payload.type,
      documentId: payload.type === "sync" && payload.documentId,
      remoteId: this._remotePeerId
    }, {
      F: __dxlog_file18,
      L: 319,
      S: this,
      C: (f, a) => f(...a)
    });
    payload.senderId = this._remotePeerId;
    this._processMessage(payload);
  }
  _processMessage(message) {
    if (isForbiddenErrorMessage(message)) {
      this._onRestartRequested();
      return;
    }
    this._requestLimiter.handleResponse(message);
    this._readableStreamController.enqueue(message);
  }
  async _sendMessage(message) {
    message.targetId = this._targetServiceId;
    log13.verbose("sending...", {
      type: message.type,
      documentId: message.type === "sync" && message.documentId,
      remoteId: this._remotePeerId
    }, {
      F: __dxlog_file18,
      L: 348,
      S: this,
      C: (f, a) => f(...a)
    });
    const encoded = cbor2.encode(message);
    await this._edgeConnection.send(buf.create(RouterMessageSchema, {
      serviceId: this._targetServiceId,
      source: {
        identityKey: this._edgeConnection.identityKey,
        peerKey: this._edgeConnection.peerKey
      },
      payload: {
        value: bufferToArray2(encoded)
      }
    }));
  }
};
var isForbiddenErrorMessage = (message) => message.type === "error" && message.message === "Forbidden";

// packages/core/echo/echo-pipeline/src/util.ts
import { decodeReference, ObjectStructure as ObjectStructure2 } from "@dxos/echo-protocol";
var findInlineObjectOfType = (spaceDoc, typename) => {
  for (const id in spaceDoc.objects ?? {}) {
    const obj = spaceDoc.objects[id];
    const objType = ObjectStructure2.getTypeReference(obj);
    if (objType && decodeReference(objType).objectId === typename) {
      return [
        id,
        obj
      ];
    }
  }
  return void 0;
};
export {
  AuthExtension,
  AuthStatus,
  AutomergeHost,
  CredentialRetrieverExtension,
  CredentialServerExtension,
  DataServiceImpl,
  DatabaseRoot,
  DocumentsSynchronizer,
  EchoDataMonitor,
  EchoEdgeReplicator,
  EchoHost,
  ExecutionTrace,
  FIND_PARAMS,
  LevelDBStorageAdapter,
  MOCK_AUTH_PROVIDER,
  MOCK_AUTH_VERIFIER,
  MeshEchoReplicator,
  MetadataStore,
  Pipeline,
  QueryExecutor,
  QueryPlan,
  QueryPlanner,
  QueryServiceImpl,
  Space,
  SpaceDocumentListUpdatedEvent,
  SpaceManager,
  SpaceProtocol,
  SpaceProtocolSession,
  SpaceStateManager,
  TimeframeClock,
  codec,
  createIdFromSpaceKey,
  createMappedFeedWriter,
  deriveCollectionIdFromSpaceId,
  diffCollectionState,
  encodingOptions,
  filterMatchObject,
  filterMatchValue,
  findInlineObjectOfType,
  getSpaceIdFromCollectionId,
  hasInvitationExpired,
  mapFeedIndexesToTimeframe,
  mapTimeframeToFeedIndexes,
  startAfter,
  valueEncoding
};
//# sourceMappingURL=index.mjs.map
