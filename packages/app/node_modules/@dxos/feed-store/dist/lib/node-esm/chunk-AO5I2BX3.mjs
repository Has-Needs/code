import { createRequire } from 'node:module';const require = createRequire(import.meta.url);

// packages/common/feed-store/src/feed-wrapper.ts
import { inspect } from "node:util";
import { Readable, Transform } from "streamx";
import { Trigger } from "@dxos/async";
import { inspectObject, StackTrace } from "@dxos/debug";
import { invariant } from "@dxos/invariant";
import { log } from "@dxos/log";
import { arrayToBuffer, createBinder, rangeFromTo } from "@dxos/util";
var __dxlog_file = "/home/runner/work/dxos/dxos/packages/common/feed-store/src/feed-wrapper.ts";
var FeedWrapper = class {
  constructor(_hypercore, _key, _storageDirectory) {
    this._hypercore = _hypercore;
    this._key = _key;
    this._storageDirectory = _storageDirectory;
    this._pendingWrites = /* @__PURE__ */ new Set();
    this._binder = createBinder(this._hypercore);
    this._writeLock = new Trigger();
    this._closed = false;
    this.on = this._binder.fn(this._hypercore.on);
    this.off = this._binder.fn(this._hypercore.off);
    this.open = this._binder.async(this._hypercore.open);
    this._close = this._binder.async(this._hypercore.close);
    this.close = async () => {
      if (this._pendingWrites.size) {
        log.warn("Closing feed with pending writes", {
          feed: this._key,
          count: this._pendingWrites.size,
          pendingWrites: Array.from(this._pendingWrites.values()).map((stack) => stack.getStack())
        }, {
          F: __dxlog_file,
          L: 173,
          S: this,
          C: (f, a) => f(...a)
        });
      }
      this._closed = true;
      await this.flushToDisk();
      await this._close();
    };
    this.has = this._binder.fn(this._hypercore.has);
    this.get = this._binder.async(this._hypercore.get);
    this.append = this._binder.async(this._hypercore.append);
    this.download = this._binder.fn(this._hypercore.download);
    this.undownload = this._binder.fn(this._hypercore.undownload);
    this.setDownloading = this._binder.fn(this._hypercore.setDownloading);
    this.replicate = this._binder.fn(this._hypercore.replicate);
    this.clear = this._binder.async(this._hypercore.clear);
    this.proof = this._binder.async(this._hypercore.proof);
    this.put = this._binder.async(this._hypercore.put);
    this.putBuffer = this._binder.async(this._hypercore._putBuffer);
    invariant(this._hypercore, void 0, {
      F: __dxlog_file,
      L: 37,
      S: this,
      A: [
        "this._hypercore",
        ""
      ]
    });
    invariant(this._key, void 0, {
      F: __dxlog_file,
      L: 38,
      S: this,
      A: [
        "this._key",
        ""
      ]
    });
    this._writeLock.wake();
  }
  [inspect.custom]() {
    return inspectObject(this);
  }
  toJSON() {
    return {
      feedKey: this._key,
      length: this.properties.length,
      opened: this.properties.opened,
      closed: this.properties.closed
    };
  }
  get key() {
    return this._key;
  }
  get core() {
    return this._hypercore;
  }
  // TODO(burdon): Create proxy.
  get properties() {
    return this._hypercore;
  }
  createReadableStream(opts) {
    const self = this;
    const transform = new Transform({
      transform(data, cb) {
        void self._writeLock.wait().then(() => {
          this.push(data);
          cb();
        });
      }
    });
    const readStream = opts?.batch !== void 0 && opts?.batch > 1 ? new BatchedReadStream(this._hypercore, opts) : this._hypercore.createReadStream(opts);
    readStream.pipe(transform, (err) => {
    });
    return transform;
  }
  createFeedWriter() {
    return {
      write: async (data, { afterWrite } = {}) => {
        log("write", {
          feed: this._key,
          seq: this._hypercore.length
        }, {
          F: __dxlog_file,
          L: 97,
          S: this,
          C: (f, a) => f(...a)
        });
        invariant(!this._closed, "Feed closed", {
          F: __dxlog_file,
          L: 98,
          S: this,
          A: [
            "!this._closed",
            "'Feed closed'"
          ]
        });
        const stackTrace = new StackTrace();
        try {
          this._pendingWrites.add(stackTrace);
          if (this._pendingWrites.size === 1) {
            this._writeLock.reset();
          }
          const receipt = await this.appendWithReceipt(data);
          await this.flushToDisk();
          await afterWrite?.(receipt);
          return receipt;
        } finally {
          this._pendingWrites.delete(stackTrace);
          if (this._pendingWrites.size === 0) {
            this._writeLock.wake();
          }
        }
      }
    };
  }
  async appendWithReceipt(data) {
    const seq = await this.append(data);
    invariant(seq < this.length, "Invalid seq after write", {
      F: __dxlog_file,
      L: 129,
      S: this,
      A: [
        "seq < this.length",
        "'Invalid seq after write'"
      ]
    });
    log("write complete", {
      feed: this._key,
      seq
    }, {
      F: __dxlog_file,
      L: 130,
      S: this,
      C: (f, a) => f(...a)
    });
    const receipt = {
      feedKey: this.key,
      seq
    };
    return receipt;
  }
  /**
  * Flush pending changes to disk.
  * Calling this is not required unless you want to explicitly wait for data to be written.
  */
  async flushToDisk() {
    await this._storageDirectory.flush();
  }
  get opened() {
    return this._hypercore.opened;
  }
  get closed() {
    return this._hypercore.closed;
  }
  get readable() {
    return this._hypercore.readable;
  }
  get length() {
    return this._hypercore.length;
  }
  get byteLength() {
    return this._hypercore.byteLength;
  }
  /**
  * Clear and check for integrity.
  */
  async safeClear(from, to) {
    invariant(from >= 0 && from < to && to <= this.length, "Invalid range", {
      F: __dxlog_file,
      L: 210,
      S: this,
      A: [
        "from >= 0 && from < to && to <= this.length",
        "'Invalid range'"
      ]
    });
    const CHECK_MESSAGES = 20;
    const checkBegin = to;
    const checkEnd = Math.min(checkBegin + CHECK_MESSAGES, this.length);
    const messagesBefore = await Promise.all(rangeFromTo(checkBegin, checkEnd).map((idx) => this.get(idx, {
      valueEncoding: {
        decode: (x) => x
      }
    })));
    await this.clear(from, to);
    const messagesAfter = await Promise.all(rangeFromTo(checkBegin, checkEnd).map((idx) => this.get(idx, {
      valueEncoding: {
        decode: (x) => x
      }
    })));
    for (let i = 0; i < messagesBefore.length; i++) {
      const before = arrayToBuffer(messagesBefore[i]);
      const after = arrayToBuffer(messagesAfter[i]);
      if (!before.equals(after)) {
        throw new Error("Feed corruption on clear. There has likely been a data loss.");
      }
    }
  }
};
var BatchedReadStream = class extends Readable {
  constructor(feed, opts = {}) {
    super({
      objectMode: true
    });
    this._reading = false;
    invariant(opts.live === true, "Only live mode supported", {
      F: __dxlog_file,
      L: 252,
      S: this,
      A: [
        "opts.live === true",
        "'Only live mode supported'"
      ]
    });
    invariant(opts.batch !== void 0 && opts.batch > 1, void 0, {
      F: __dxlog_file,
      L: 253,
      S: this,
      A: [
        "opts.batch !== undefined && opts.batch > 1",
        ""
      ]
    });
    this._feed = feed;
    this._batch = opts.batch;
    this._cursor = opts.start ?? 0;
  }
  _open(cb) {
    this._feed.ready(cb);
  }
  _read(cb) {
    if (this._reading) {
      return;
    }
    if (this._feed.bitfield.total(this._cursor, this._cursor + this._batch) === this._batch) {
      this._batchedRead(cb);
    } else {
      this._nonBatchedRead(cb);
    }
  }
  _nonBatchedRead(cb) {
    this._feed.get(this._cursor, {
      wait: true
    }, (err, data) => {
      if (err) {
        cb(err);
      } else {
        this._cursor++;
        this._reading = false;
        this.push(data);
        cb(null);
      }
    });
  }
  _batchedRead(cb) {
    this._feed.getBatch(this._cursor, this._cursor + this._batch, {
      wait: true
    }, (err, data) => {
      if (err) {
        cb(err);
      } else {
        this._cursor += data.length;
        this._reading = false;
        for (const item of data) {
          this.push(item);
        }
        cb(null);
      }
    });
  }
};

// packages/common/feed-store/src/feed-factory.ts
import defaultsDeep from "lodash.defaultsdeep";
import { subtleCrypto } from "@dxos/crypto";
import { failUndefined } from "@dxos/debug";
import { createCrypto, hypercore } from "@dxos/hypercore";
import { log as log2 } from "@dxos/log";
var __dxlog_file2 = "/home/runner/work/dxos/dxos/packages/common/feed-store/src/feed-factory.ts";
var FeedFactory = class {
  constructor({ root, signer, hypercore: hypercore2 }) {
    log2("FeedFactory", {
      options: hypercore2
    }, {
      F: __dxlog_file2,
      L: 43,
      S: this,
      C: (f, a) => f(...a)
    });
    this._root = root ?? failUndefined();
    this._signer = signer;
    this._hypercoreOptions = hypercore2;
  }
  get storageRoot() {
    return this._root;
  }
  async createFeed(publicKey, options) {
    if (options?.writable && !this._signer) {
      throw new Error("Signer required to create writable feeds.");
    }
    if (options?.secretKey) {
      log2.warn("Secret key ignored due to signer.", void 0, {
        F: __dxlog_file2,
        L: 58,
        S: this,
        C: (f, a) => f(...a)
      });
    }
    const key = await subtleCrypto.digest("SHA-256", Buffer.from(publicKey.toHex()));
    const opts = defaultsDeep({}, this._hypercoreOptions, {
      secretKey: this._signer && options?.writable ? Buffer.from("secret") : void 0,
      crypto: this._signer ? createCrypto(this._signer, publicKey) : void 0,
      onwrite: options?.onwrite,
      noiseKeyPair: {}
    }, options);
    const storageDir = this._root.createDirectory(publicKey.toHex());
    const makeStorage = (filename) => {
      const { type, native } = storageDir.getOrCreateFile(filename);
      log2("created", {
        path: `${type}:${this._root.path}/${publicKey.truncate()}/${filename}`
      }, {
        F: __dxlog_file2,
        L: 82,
        S: this,
        C: (f, a) => f(...a)
      });
      return native;
    };
    const core = hypercore(makeStorage, Buffer.from(key), opts);
    return new FeedWrapper(core, publicKey, storageDir);
  }
};

// packages/common/feed-store/src/feed-store.ts
import { Event, Mutex } from "@dxos/async";
import { failUndefined as failUndefined2 } from "@dxos/debug";
import { invariant as invariant2 } from "@dxos/invariant";
import { PublicKey } from "@dxos/keys";
import { log as log3 } from "@dxos/log";
import { ComplexMap, defaultMap } from "@dxos/util";
var __dxlog_file3 = "/home/runner/work/dxos/dxos/packages/common/feed-store/src/feed-store.ts";
var FeedStore = class {
  constructor({ factory }) {
    this._feeds = new ComplexMap(PublicKey.hash);
    this._mutexes = new ComplexMap(PublicKey.hash);
    this._closed = false;
    this.feedOpened = new Event();
    this._factory = factory ?? failUndefined2();
  }
  get size() {
    return this._feeds.size;
  }
  get feeds() {
    return Array.from(this._feeds.values());
  }
  /**
  * Get the open feed if it exists.
  */
  getFeed(publicKey) {
    return this._feeds.get(publicKey);
  }
  /**
  * Gets or opens a feed.
  * The feed is readonly unless a secret key is provided.
  */
  async openFeed(feedKey, { writable, sparse } = {}) {
    log3("opening feed", {
      feedKey
    }, {
      F: __dxlog_file3,
      L: 55,
      S: this,
      C: (f, a) => f(...a)
    });
    invariant2(feedKey, void 0, {
      F: __dxlog_file3,
      L: 56,
      S: this,
      A: [
        "feedKey",
        ""
      ]
    });
    invariant2(!this._closed, "Feed store is closed", {
      F: __dxlog_file3,
      L: 57,
      S: this,
      A: [
        "!this._closed",
        "'Feed store is closed'"
      ]
    });
    const mutex = defaultMap(this._mutexes, feedKey, () => new Mutex());
    return mutex.executeSynchronized(async () => {
      let feed = this.getFeed(feedKey);
      if (feed) {
        if (writable && !feed.properties.writable) {
          throw new Error(`Read-only feed is already open: ${feedKey.truncate()}`);
        } else if ((sparse ?? false) !== feed.properties.sparse) {
          throw new Error(`Feed already open with different sparse setting: ${feedKey.truncate()} [${sparse} !== ${feed.properties.sparse}]`);
        } else {
          await feed.open();
          return feed;
        }
      }
      feed = await this._factory.createFeed(feedKey, {
        writable,
        sparse
      });
      this._feeds.set(feed.key, feed);
      await feed.open();
      this.feedOpened.emit(feed);
      log3("opened", {
        feedKey
      }, {
        F: __dxlog_file3,
        L: 85,
        S: this,
        C: (f, a) => f(...a)
      });
      return feed;
    });
  }
  /**
  * Close all feeds.
  */
  async close() {
    log3("closing...", void 0, {
      F: __dxlog_file3,
      L: 94,
      S: this,
      C: (f, a) => f(...a)
    });
    this._closed = true;
    await Promise.all(Array.from(this._feeds.values()).map(async (feed) => {
      await feed.close();
      invariant2(feed.closed, void 0, {
        F: __dxlog_file3,
        L: 99,
        S: this,
        A: [
          "feed.closed",
          ""
        ]
      });
    }));
    this._feeds.clear();
    log3("closed", void 0, {
      F: __dxlog_file3,
      L: 108,
      S: this,
      C: (f, a) => f(...a)
    });
  }
};

export {
  FeedWrapper,
  FeedFactory,
  FeedStore
};
//# sourceMappingURL=chunk-AO5I2BX3.mjs.map
