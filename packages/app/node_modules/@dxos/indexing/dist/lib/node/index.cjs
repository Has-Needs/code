"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var node_exports = {};
__export(node_exports, {
  EscapedPropPath: () => EscapedPropPath,
  IndexMetadataStore: () => IndexMetadataStore,
  IndexStore: () => IndexStore,
  Indexer: () => Indexer,
  headsEncoding: () => headsEncoding,
  staticImplements: () => staticImplements
});
module.exports = __toCommonJS(node_exports);
var import_lodash = __toESM(require("lodash.isequal"));
var import_async = require("@dxos/async");
var import_context = require("@dxos/context");
var import_invariant = require("@dxos/invariant");
var import_log = require("@dxos/log");
var import_indexing = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_tracing = require("@dxos/tracing");
var Orama = __toESM(require("@orama/orama"));
var import_async2 = require("@dxos/async");
var import_context2 = require("@dxos/context");
var import_invariant2 = require("@dxos/invariant");
var import_keys = require("@dxos/keys");
var import_log2 = require("@dxos/log");
var import_indexing2 = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_tracing2 = require("@dxos/tracing");
var import_echo_protocol = require("@dxos/echo-protocol");
var import_util = require("@dxos/util");
var import_effect = require("effect");
var import_invariant3 = require("@dxos/invariant");
var import_async3 = require("@dxos/async");
var import_context3 = require("@dxos/context");
var import_echo_protocol2 = require("@dxos/echo-protocol");
var import_echo_schema = require("@dxos/echo-schema");
var import_keys2 = require("@dxos/keys");
var import_log3 = require("@dxos/log");
var import_indexing3 = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_tracing3 = require("@dxos/tracing");
var import_util2 = require("@dxos/util");
var import_indexing4 = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_effect2 = require("effect");
var import_async4 = require("@dxos/async");
var import_context4 = require("@dxos/context");
var import_echo_protocol3 = require("@dxos/echo-protocol");
var import_echo_schema2 = require("@dxos/echo-schema");
var import_errors = require("@dxos/errors");
var import_keys3 = require("@dxos/keys");
var import_log4 = require("@dxos/log");
var import_protocols = require("@dxos/protocols");
var import_indexing5 = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_tracing4 = require("@dxos/tracing");
var import_util3 = require("@dxos/util");
var Orama2 = __toESM(require("@orama/orama"));
var import_async5 = require("@dxos/async");
var import_context5 = require("@dxos/context");
var import_invariant4 = require("@dxos/invariant");
var import_keys4 = require("@dxos/keys");
var import_log5 = require("@dxos/log");
var import_indexing6 = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_tracing5 = require("@dxos/tracing");
var import_transformers = require("@xenova/transformers");
var import_context6 = require("@dxos/context");
var import_async6 = require("@dxos/async");
var import_context7 = require("@dxos/context");
var import_invariant5 = require("@dxos/invariant");
var import_log6 = require("@dxos/log");
var import_indexing7 = require("@dxos/protocols/proto/dxos/echo/indexing");
var import_tracing6 = require("@dxos/tracing");
var import_util4 = require("@dxos/util");
var import_lodash2 = __toESM(require("lodash.isequal"));
var import_invariant6 = require("@dxos/invariant");
var import_tracing7 = require("@dxos/tracing");
var import_async7 = require("@dxos/async");
var import_invariant7 = require("@dxos/invariant");
var import_log7 = require("@dxos/log");
var import_protocols2 = require("@dxos/protocols");
var import_proto = require("@dxos/protocols/proto");
var import_tracing8 = require("@dxos/tracing");
var import_util5 = require("@dxos/util");
var IGNORED_TYPENAMES = [
  "dxos.org/type/Canvas"
];
var extractTextBlocks = (object) => {
  const type = import_echo_protocol.ObjectStructure.getTypeReference(object);
  const dxnType = type && (0, import_echo_protocol.decodeReference)(type).toDXN();
  if (IGNORED_TYPENAMES.includes(dxnType?.asTypeDXN()?.type ?? "")) {
    return [];
  }
  const blocks = [];
  const go = (value, _key) => {
    if ((0, import_echo_protocol.isEncodedReference)(value)) {
      return;
    }
    if (typeof value === "string") {
      blocks.push({
        content: value
      });
    }
    (0, import_util.visitValues)(value, go);
  };
  (0, import_util.visitValues)(object.data, go);
  return blocks;
};
var __dxlog_file = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/types.ts";
var staticImplements = () => (constructor) => {
  return constructor;
};
var EscapedPropPath = class extends import_effect.Schema.String.annotations({
  title: "EscapedPropPath"
}) {
  static escape(path) {
    return path.map((p) => p.toString().replaceAll("\\", "\\\\").replaceAll(".", "\\.")).join(".");
  }
  static unescape(path) {
    const parts = [];
    let current = "";
    for (let i = 0; i < path.length; i++) {
      if (path[i] === "\\") {
        (0, import_invariant3.invariant)(i + 1 < path.length && (path[i + 1] === "." || path[i + 1] === "\\"), "Malformed escaping.", {
          F: __dxlog_file,
          L: 134,
          S: this,
          A: [
            "i + 1 < path.length && (path[i + 1] === '.' || path[i + 1] === '\\\\')",
            "'Malformed escaping.'"
          ]
        });
        current = current + path[i + 1];
        i++;
      } else if (path[i] === ".") {
        parts.push(current);
        current = "";
      } else {
        current += path[i];
      }
    }
    parts.push(current);
    return parts;
  }
};
function _ts_decorate(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file2 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-text.ts";
var IndexText = class _IndexText extends import_context2.Resource {
  constructor() {
    super(...arguments);
    this._identifier = import_keys.PublicKey.random().toString();
    this.kind = {
      kind: import_indexing2.IndexKind.Kind.FULL_TEXT
    };
    this.updated = new import_async2.Event();
    this._orama = void 0;
  }
  async _open() {
    this._orama = await Orama.create({
      schema: {
        chunks: "string[]"
      }
    });
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    const blocks = extractTextBlocks(object);
    (0, import_invariant2.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 63,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama.remove(this._orama, id);
    await Orama.insert(this._orama, {
      id,
      chunks: blocks.map((block) => block.content)
    });
    return true;
  }
  async remove(id) {
    (0, import_invariant2.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 73,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama.remove(this._orama, id);
  }
  async find(filter) {
    (0, import_invariant2.invariant)(filter.typenames.length === 0, "Typenames are not supported", {
      F: __dxlog_file2,
      L: 79,
      S: this,
      A: [
        "filter.typenames.length === 0",
        "'Typenames are not supported'"
      ]
    });
    (0, import_invariant2.invariant)(!filter.inverted, "Inverted search is not supported", {
      F: __dxlog_file2,
      L: 80,
      S: this,
      A: [
        "!filter.inverted",
        "'Inverted search is not supported'"
      ]
    });
    (0, import_invariant2.invariant)(!filter.graph, "Graph search is not supported", {
      F: __dxlog_file2,
      L: 81,
      S: this,
      A: [
        "!filter.graph",
        "'Graph search is not supported'"
      ]
    });
    (0, import_invariant2.invariant)(typeof filter.text?.query === "string", void 0, {
      F: __dxlog_file2,
      L: 82,
      S: this,
      A: [
        "typeof filter.text?.query === 'string'",
        ""
      ]
    });
    (0, import_invariant2.invariant)(filter.text?.kind === "text", void 0, {
      F: __dxlog_file2,
      L: 83,
      S: this,
      A: [
        "filter.text?.kind === 'text'",
        ""
      ]
    });
    (0, import_invariant2.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 85,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    const results = await Orama.search(this._orama, {
      mode: "fulltext",
      term: filter.text.query,
      // TODO(dmaretskyi): Add a way to configure these.
      limit: 10,
      offset: 0
    });
    import_log2.log.info("Text search results", {
      query: filter.text.query,
      results
    }, {
      F: __dxlog_file2,
      L: 95,
      S: this,
      C: (f, a) => f(...a)
    });
    return results.hits.map((hit) => ({
      id: hit.id,
      rank: hit.score
    }));
  }
  async serialize() {
    (0, import_invariant2.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 105,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    return JSON.stringify(await Orama.save(this._orama), null, 2);
  }
  static async load({ serialized, identifier }) {
    const deserialized = JSON.parse(serialized);
    const index = new _IndexText();
    await index.open();
    (0, import_invariant2.invariant)(index._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 115,
      S: this,
      A: [
        "index._orama",
        "'Index is not initialized'"
      ]
    });
    index._identifier = identifier;
    await Orama.load(index._orama, deserialized);
    return index;
  }
};
_ts_decorate([
  import_tracing2.trace.span({
    showInBrowserTimeline: true
  })
], IndexText.prototype, "update", null);
_ts_decorate([
  import_tracing2.trace.span({
    showInBrowserTimeline: true
  })
], IndexText.prototype, "find", null);
_ts_decorate([
  import_tracing2.trace.span({
    showInBrowserTimeline: true
  })
], IndexText.prototype, "serialize", null);
_ts_decorate([
  import_tracing2.trace.span({
    showInBrowserTimeline: true
  })
], IndexText, "load", null);
IndexText = _ts_decorate([
  import_tracing2.trace.resource(),
  staticImplements()
], IndexText);
function _ts_decorate2(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file3 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-schema.ts";
var IndexSchema = class _IndexSchema extends import_context3.Resource {
  constructor() {
    super(...arguments);
    this._identifier = import_keys2.PublicKey.random().toString();
    this.kind = {
      kind: import_indexing3.IndexKind.Kind.SCHEMA_MATCH
    };
    this.updated = new import_async3.Event();
    this._index = /* @__PURE__ */ new Map();
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    if (this._index.get(getTypeFromObject(object))?.has(id)) {
      return false;
    }
    (0, import_util2.defaultMap)(this._index, getTypeFromObject(object), /* @__PURE__ */ new Set()).add(id);
    return true;
  }
  async remove(id) {
    for (const [_, ids] of this._index.entries()) {
      if (ids.has(id)) {
        ids.delete(id);
        return;
      }
    }
  }
  async find(filter) {
    if (filter.inverted) {
      return Array.from(this._index.entries()).filter(([key]) => !filter.typenames.includes(key ?? import_echo_schema.EXPANDO_TYPENAME) === false).flatMap(([, value]) => Array.from(value)).map((id) => ({
        id,
        rank: 0
      }));
    }
    if (filter.typenames.length === 0) {
      return Array.from(this._index.values()).flatMap((ids) => Array.from(ids)).map((id) => ({
        id,
        rank: 0
      }));
    }
    const results = [];
    for (const typename of filter.typenames) {
      if (typename === import_echo_schema.EXPANDO_TYPENAME || import_keys2.DXN.isDXNString(typename) && import_keys2.DXN.parse(typename).asTypeDXN()?.type === import_echo_schema.EXPANDO_TYPENAME) {
        results.push(...Array.from(this._index.get(null) ?? []).map((id) => ({
          id,
          rank: 0
        })));
      } else if (import_keys2.DXN.isDXNString(typename)) {
        const dxn = import_keys2.DXN.parse(typename);
        if (dxn.isLocalObjectId()) {
          const objectId = dxn.parts[1];
          results.push(...Array.from(this._index.get(objectId) ?? []).map((id) => ({
            id,
            rank: 0
          })));
        } else if (dxn.kind === import_keys2.DXN.kind.TYPE) {
          const typename2 = dxn.parts[0];
          results.push(...Array.from(this._index.get(typename2) ?? []).map((id) => ({
            id,
            rank: 0
          })));
        } else {
          import_log3.log.warn("Unsupported DXN", {
            dxn
          }, {
            F: __dxlog_file3,
            L: 95,
            S: this,
            C: (f, a) => f(...a)
          });
        }
      } else {
        results.push(...Array.from(this._index.get(typename) ?? []).map((id) => ({
          id,
          rank: 0
        })));
      }
    }
    return results.flat();
  }
  async serialize() {
    return JSON.stringify({
      index: Array.from(this._index.entries()).map(([type, ids]) => ({
        type,
        ids: Array.from(ids)
      }))
    });
  }
  static async load({ serialized, identifier }) {
    const index = new _IndexSchema();
    const serializedIndex = JSON.parse(serialized).index;
    index._identifier = identifier;
    for (const { type, ids } of serializedIndex) {
      index._index.set(type, new Set(ids));
    }
    return index;
  }
};
_ts_decorate2([
  import_tracing3.trace.span({
    showInBrowserTimeline: true
  })
], IndexSchema.prototype, "update", null);
_ts_decorate2([
  import_tracing3.trace.span({
    showInBrowserTimeline: true
  })
], IndexSchema.prototype, "find", null);
_ts_decorate2([
  import_tracing3.trace.span({
    showInBrowserTimeline: true
  })
], IndexSchema.prototype, "serialize", null);
_ts_decorate2([
  import_tracing3.trace.span({
    showInBrowserTimeline: true
  })
], IndexSchema, "load", null);
IndexSchema = _ts_decorate2([
  import_tracing3.trace.resource(),
  staticImplements()
], IndexSchema);
var getTypeFromObject = (object) => object.system?.type ? (0, import_echo_protocol2.decodeReference)(object.system.type).objectId ?? null : null;
function _ts_decorate3(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file4 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-graph.ts";
var IndexGraph = class _IndexGraph extends import_context4.Resource {
  constructor() {
    super(...arguments);
    this._identifier = import_keys3.PublicKey.random().toString();
    this.kind = {
      kind: import_indexing5.IndexKind.Kind.GRAPH
    };
    this.updated = new import_async4.Event();
    this._inboundReferences = /* @__PURE__ */ new Map();
    this._relationTargets = /* @__PURE__ */ new Map();
    this._relationSources = /* @__PURE__ */ new Map();
    this._objectToTargets = /* @__PURE__ */ new Map();
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    const kind = import_echo_protocol3.ObjectStructure.getEntityKind(object);
    switch (kind) {
      case import_echo_schema2.EntityKind.Object: {
        this._removeReferencesFrom(id);
        this._trackOutgoingReferences(id, object);
        break;
      }
      case import_echo_schema2.EntityKind.Relation: {
        this._removeReferencesFrom(id);
        this._trackOutgoingReferences(id, object);
        const targetMapping = (0, import_util3.defaultMap)(this._objectToTargets, id, () => /* @__PURE__ */ new Set());
        const source = import_echo_protocol3.ObjectStructure.getRelationSource(object);
        const target = import_echo_protocol3.ObjectStructure.getRelationTarget(object);
        if (source) {
          const sourceObject = (0, import_echo_protocol3.decodeReference)(source).toDXN().asEchoDXN()?.echoId;
          if (sourceObject) {
            (0, import_util3.defaultMap)(this._relationSources, sourceObject, () => /* @__PURE__ */ new Set()).add(id);
            targetMapping.add(sourceObject);
          }
        } else {
          import_log4.log.warn("relation has no source", {
            id
          }, {
            F: __dxlog_file4,
            L: 98,
            S: this,
            C: (f, a) => f(...a)
          });
        }
        if (target) {
          const targetObject = (0, import_echo_protocol3.decodeReference)(target).toDXN().asEchoDXN()?.echoId;
          if (targetObject) {
            (0, import_util3.defaultMap)(this._relationTargets, targetObject, () => /* @__PURE__ */ new Set()).add(id);
            targetMapping.add(targetObject);
          }
        } else {
          import_log4.log.warn("relation has no target", {
            id
          }, {
            F: __dxlog_file4,
            L: 107,
            S: this,
            C: (f, a) => f(...a)
          });
        }
        break;
      }
      default: {
        import_log4.log.warn("unknown entity kind", {
          kind
        }, {
          F: __dxlog_file4,
          L: 112,
          S: this,
          C: (f, a) => f(...a)
        });
        break;
      }
    }
    return true;
  }
  async remove(id) {
    this._removeReferencesFrom(id);
  }
  _removeReferencesFrom(id) {
    for (const target of this._objectToTargets.get(id) ?? []) {
      const perField = this._inboundReferences.get(target);
      if (!perField) {
        continue;
      }
      for (const field of perField.keys()) {
        perField.get(field)?.delete(id);
      }
      this._relationTargets.get(target)?.delete(id);
      this._relationSources.get(target)?.delete(id);
    }
    this._objectToTargets.get(id)?.clear();
  }
  _trackOutgoingReferences(id, object) {
    const targetMapping = (0, import_util3.defaultMap)(this._objectToTargets, id, () => /* @__PURE__ */ new Set());
    const references = import_echo_protocol3.ObjectStructure.getAllOutgoingReferences(object);
    for (const { path, reference } of references) {
      const targetObject = (0, import_echo_protocol3.decodeReference)(reference).toDXN().asEchoDXN()?.echoId;
      if (!targetObject) {
        continue;
      }
      const escapedPath = EscapedPropPath.escape(path);
      (0, import_effect2.pipe)(this._inboundReferences, (map) => (0, import_util3.defaultMap)(map, targetObject, () => /* @__PURE__ */ new Map()), (map) => (0, import_util3.defaultMap)(map, escapedPath, () => /* @__PURE__ */ new Set())).add(id);
      targetMapping.add(targetObject);
    }
  }
  async find(filter) {
    if (filter.inverted || filter.typenames.length > 0 || !filter.graph) {
      throw new import_errors.InternalError("Invalid filter for graph query");
    }
    const { kind, anchors, property } = filter.graph;
    switch (kind) {
      case "inbound-reference": {
        const results = [];
        for (const anchor of anchors) {
          const sources = this._inboundReferences.get(anchor);
          if (!sources) {
            continue;
          }
          if (property !== null) {
            for (const [escapedProp, source] of sources.entries()) {
              const prop = EscapedPropPath.unescape(escapedProp);
              const firstSegmentMatches = prop[0] === property;
              const secondSegmentIsNumeric = !isNaN(Number(prop[1]));
              if (firstSegmentMatches && (prop.length === 1 || prop.length === 2 && secondSegmentIsNumeric)) {
                results.push(...Array.from(source).map((id) => ({
                  id,
                  rank: 0
                })));
              }
            }
          } else {
            for (const source of sources.values()) {
              results.push(...Array.from(source).map((id) => ({
                id,
                rank: 0
              })));
            }
          }
        }
        return results;
      }
      case "relation-source": {
        const results = [];
        for (const anchor of anchors) {
          const sources = this._relationSources.get(anchor);
          if (!sources) {
            continue;
          }
          results.push(...Array.from(sources).map((id) => ({
            id,
            rank: 0
          })));
        }
        return results;
      }
      case "relation-target": {
        const results = [];
        for (const anchor of anchors) {
          const sources = this._relationTargets.get(anchor);
          if (!sources) {
            continue;
          }
          results.push(...Array.from(sources).map((id) => ({
            id,
            rank: 0
          })));
        }
        return results;
      }
      default: {
        throw new TypeError("Unknown graph query kind");
      }
    }
  }
  async serialize() {
    const data = {
      inboundReferences: Object.fromEntries([
        ...this._inboundReferences.entries()
      ].map(([target, perProp]) => [
        target,
        Object.fromEntries([
          ...perProp.entries()
        ].map(([prop, sources]) => [
          prop,
          Array.from(sources)
        ]))
      ])),
      relationTargets: Object.fromEntries([
        ...this._relationTargets.entries()
      ].map(([target, sources]) => [
        target,
        Array.from(sources)
      ])),
      relationSources: Object.fromEntries([
        ...this._relationSources.entries()
      ].map(([target, sources]) => [
        target,
        Array.from(sources)
      ])),
      objectToTargets: Object.fromEntries([
        ...this._objectToTargets.entries()
      ].map(([target, sources]) => [
        target,
        Array.from(sources)
      ]))
    };
    return JSON.stringify(data);
  }
  static async load({ serialized, identifier }) {
    const index = new _IndexGraph();
    await index.open();
    const data = GraphIndexData.pipe(import_effect2.Schema.decodeUnknownSync)(JSON.parse(serialized));
    index._loadFrom(data);
    return index;
  }
  _loadFrom(data) {
    this._inboundReferences.clear();
    this._relationTargets.clear();
    this._relationSources.clear();
    this._objectToTargets.clear();
    for (const [target, perProp] of (0, import_util3.entries)(data.inboundReferences)) {
      const propMap = /* @__PURE__ */ new Map();
      this._inboundReferences.set(target, propMap);
      for (const [prop, sources] of (0, import_util3.entries)(perProp)) {
        propMap.set(prop, new Set(sources));
      }
    }
    for (const [target, sources] of (0, import_util3.entries)(data.relationTargets)) {
      this._relationTargets.set(target, new Set(sources));
    }
    for (const [target, sources] of (0, import_util3.entries)(data.relationSources)) {
      this._relationSources.set(target, new Set(sources));
    }
    for (const [target, sources] of (0, import_util3.entries)(data.objectToTargets)) {
      this._objectToTargets.set(target, new Set(sources));
    }
  }
};
_ts_decorate3([
  import_tracing4.trace.span({
    showInBrowserTimeline: true
  })
], IndexGraph.prototype, "update", null);
_ts_decorate3([
  import_tracing4.trace.span({
    showInBrowserTimeline: true
  })
], IndexGraph.prototype, "find", null);
_ts_decorate3([
  import_tracing4.trace.span({
    showInBrowserTimeline: true
  })
], IndexGraph.prototype, "serialize", null);
_ts_decorate3([
  import_tracing4.trace.span({
    showInBrowserTimeline: true
  })
], IndexGraph, "load", null);
IndexGraph = _ts_decorate3([
  import_tracing4.trace.resource(),
  staticImplements()
], IndexGraph);
var GraphIndexData = import_effect2.Schema.Struct({
  inboundReferences: import_effect2.Schema.Record({
    key: import_echo_schema2.ObjectId,
    value: import_effect2.Schema.Record({
      key: EscapedPropPath,
      value: import_effect2.Schema.Array(import_protocols.ObjectPointerEncoded)
    })
  }),
  relationTargets: import_effect2.Schema.Record({
    key: import_echo_schema2.ObjectId,
    value: import_effect2.Schema.Array(import_protocols.ObjectPointerEncoded)
  }),
  relationSources: import_effect2.Schema.Record({
    key: import_echo_schema2.ObjectId,
    value: import_effect2.Schema.Array(import_protocols.ObjectPointerEncoded)
  }),
  objectToTargets: import_effect2.Schema.Record({
    key: import_protocols.ObjectPointerEncoded,
    value: import_effect2.Schema.Array(import_echo_schema2.ObjectId)
  })
});
var DEFAULT_OPTIONS = {
  model: "Xenova/all-MiniLM-L6-v2",
  chunkCombination: "mean",
  maxChunkSize: 500
};
var EmbeddingExtractor = class extends import_context6.Resource {
  constructor(options = {}) {
    super();
    this._extractor = void 0;
    this._options = {
      ...DEFAULT_OPTIONS,
      ...options
    };
  }
  async _open() {
    this._extractor = await (0, import_transformers.pipeline)("feature-extraction", this._options.model);
  }
  async _close() {
    await this._extractor?.dispose();
  }
  /**
  * Extracts embeddings from the object.
  * @returns Embeddings for each chunk of the object or a single embedding if chunks are combined.
  */
  async extract(data) {
    const extractor = await (0, import_transformers.pipeline)("feature-extraction", this._options.model);
    const chunks = breakIntoChunks(data, this._options.maxChunkSize);
    const embedding = await extractor(chunks.map((block) => block.content), {
      pooling: "mean",
      normalize: true
    });
    let vectors = embedding.tolist();
    vectors = combineChunks(vectors, this._options.chunkCombination);
    return vectors;
  }
};
var combineChunks = (vectors, chunkCombination) => {
  switch (chunkCombination) {
    case "mean": {
      const combined = Array(vectors[0].length).fill(0);
      for (const vector of vectors) {
        for (let i = 0; i < vector.length; i++) {
          combined[i] += vector[i] / vectors.length;
        }
      }
      return [
        combined.map((value) => value / vectors.length)
      ];
    }
    case "max": {
      const combined = Array(vectors[0].length).fill(0);
      for (const vector of vectors) {
        for (let i = 0; i < vector.length; i++) {
          combined[i] = Math.max(combined[i], vector[i]);
        }
      }
      return [
        combined
      ];
    }
    case "disabled":
      return vectors;
  }
};
var breakIntoChunks = (data, maxChunkSize) => {
  const chunks = [];
  for (const block of data) {
    const paragraphs = block.content.split(/\n\s*\n/);
    for (const paragraph of paragraphs) {
      const content = paragraph.trim();
      if (!content) {
        continue;
      }
      if (content.length <= maxChunkSize) {
        chunks.push({
          ...block,
          content
        });
        continue;
      }
      const sentences = content.split(/([.!?]+\s+)/);
      let currentChunk = "";
      for (let i = 0; i < sentences.length; i += 2) {
        const sentence = sentences[i];
        const delimiter = sentences[i + 1] || "";
        const sentenceContent = sentence.trim() + delimiter;
        if (!sentenceContent) {
          continue;
        }
        if (currentChunk.length + sentenceContent.length > maxChunkSize) {
          if (currentChunk) {
            chunks.push({
              ...block,
              content: currentChunk
            });
            currentChunk = "";
          }
          if (sentenceContent.length > maxChunkSize) {
            const words = sentenceContent.split(/(\s+)/);
            currentChunk = "";
            for (let j = 0; j < words.length; j += 2) {
              const word = words[j];
              const wordDelimiter = words[j + 1] || "";
              const wordContent = word.trim() + wordDelimiter;
              if (!wordContent) {
                continue;
              }
              if (currentChunk.length + wordContent.length > maxChunkSize) {
                if (currentChunk) {
                  chunks.push({
                    ...block,
                    content: currentChunk
                  });
                  currentChunk = "";
                }
                if (wordContent.length > maxChunkSize) {
                  for (let k = 0; k < wordContent.length; k += maxChunkSize) {
                    chunks.push({
                      ...block,
                      content: wordContent.slice(k, k + maxChunkSize)
                    });
                  }
                } else {
                  currentChunk = wordContent;
                }
              } else {
                currentChunk += wordContent;
              }
            }
          } else {
            currentChunk = sentenceContent;
          }
        } else {
          currentChunk += sentenceContent;
        }
      }
      if (currentChunk) {
        chunks.push({
          ...block,
          content: currentChunk
        });
      }
    }
  }
  return chunks;
};
function _ts_decorate4(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file5 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-vector.ts";
var VECTOR_DIMENSION = 384;
var IndexVector = class _IndexVector extends import_context5.Resource {
  constructor() {
    super(...arguments);
    this._identifier = import_keys4.PublicKey.random().toString();
    this._extractor = new EmbeddingExtractor();
    this.kind = {
      kind: import_indexing6.IndexKind.Kind.VECTOR
    };
    this.updated = new import_async5.Event();
    this._orama = void 0;
  }
  async _open() {
    await this._extractor.open();
    this._orama = await Orama2.create({
      schema: {
        embedding: `vector[${VECTOR_DIMENSION}]`
      }
    });
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    const blocks = extractTextBlocks(object);
    (0, import_log5.log)("Extracting embeddings", {
      id,
      blocks
    }, {
      F: __dxlog_file5,
      L: 73,
      S: this,
      C: (f, a) => f(...a)
    });
    if (blocks.length === 0) {
      (0, import_invariant4.invariant)(this._orama, "Index is not initialized", {
        F: __dxlog_file5,
        L: 75,
        S: this,
        A: [
          "this._orama",
          "'Index is not initialized'"
        ]
      });
      await Orama2.remove(this._orama, id);
      return true;
    }
    const embeddings = await this._extractor.extract(blocks);
    (0, import_invariant4.invariant)(embeddings.length === 1, "Vectors must be combined", {
      F: __dxlog_file5,
      L: 81,
      S: this,
      A: [
        "embeddings.length === 1",
        "'Vectors must be combined'"
      ]
    });
    (0, import_invariant4.invariant)(embeddings[0].length === VECTOR_DIMENSION, "Vector dimension mismatch", {
      F: __dxlog_file5,
      L: 82,
      S: this,
      A: [
        "embeddings[0].length === VECTOR_DIMENSION",
        "'Vector dimension mismatch'"
      ]
    });
    (0, import_invariant4.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 84,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama2.remove(this._orama, id);
    await Orama2.insert(this._orama, {
      id,
      embedding: embeddings[0]
    });
    return true;
  }
  async remove(id) {
    (0, import_invariant4.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 94,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama2.remove(this._orama, id);
  }
  async find(filter) {
    (0, import_invariant4.invariant)(filter.typenames.length === 0, "Typenames are not supported", {
      F: __dxlog_file5,
      L: 100,
      S: this,
      A: [
        "filter.typenames.length === 0",
        "'Typenames are not supported'"
      ]
    });
    (0, import_invariant4.invariant)(!filter.inverted, "Inverted search is not supported", {
      F: __dxlog_file5,
      L: 101,
      S: this,
      A: [
        "!filter.inverted",
        "'Inverted search is not supported'"
      ]
    });
    (0, import_invariant4.invariant)(!filter.graph, "Graph search is not supported", {
      F: __dxlog_file5,
      L: 102,
      S: this,
      A: [
        "!filter.graph",
        "'Graph search is not supported'"
      ]
    });
    (0, import_invariant4.invariant)(typeof filter.text?.query === "string", void 0, {
      F: __dxlog_file5,
      L: 103,
      S: this,
      A: [
        "typeof filter.text?.query === 'string'",
        ""
      ]
    });
    (0, import_invariant4.invariant)(filter.text?.kind === "vector", void 0, {
      F: __dxlog_file5,
      L: 104,
      S: this,
      A: [
        "filter.text?.kind === 'vector'",
        ""
      ]
    });
    const embeddings = await this._extractor.extract([
      {
        content: filter.text.query
      }
    ]);
    (0, import_invariant4.invariant)(embeddings.length === 1, "Vectors must be combined", {
      F: __dxlog_file5,
      L: 107,
      S: this,
      A: [
        "embeddings.length === 1",
        "'Vectors must be combined'"
      ]
    });
    (0, import_invariant4.invariant)(embeddings[0].length === VECTOR_DIMENSION, "Vector dimension mismatch", {
      F: __dxlog_file5,
      L: 108,
      S: this,
      A: [
        "embeddings[0].length === VECTOR_DIMENSION",
        "'Vector dimension mismatch'"
      ]
    });
    (0, import_invariant4.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 110,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    const results = await Orama2.search(this._orama, {
      mode: "vector",
      vector: {
        value: embeddings[0],
        property: "embedding"
      },
      // TODO(dmaretskyi): Add a way to configure these.
      similarity: 0.2,
      includeVectors: true,
      limit: 10,
      offset: 0
    });
    import_log5.log.info("Vector search results", {
      query: filter.text.query,
      results
    }, {
      F: __dxlog_file5,
      L: 125,
      S: this,
      C: (f, a) => f(...a)
    });
    return results.hits.map((hit) => ({
      id: hit.id,
      rank: hit.score
    }));
  }
  async serialize() {
    (0, import_invariant4.invariant)(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 135,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    return JSON.stringify(await Orama2.save(this._orama), null, 2);
  }
  static async load({ serialized, identifier }) {
    const deserialized = JSON.parse(serialized);
    const index = new _IndexVector();
    await index.open();
    (0, import_invariant4.invariant)(index._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 145,
      S: this,
      A: [
        "index._orama",
        "'Index is not initialized'"
      ]
    });
    index._identifier = identifier;
    await Orama2.load(index._orama, deserialized);
    return index;
  }
};
_ts_decorate4([
  import_tracing5.trace.span({
    showInBrowserTimeline: true
  })
], IndexVector.prototype, "update", null);
_ts_decorate4([
  import_tracing5.trace.span({
    showInBrowserTimeline: true
  })
], IndexVector.prototype, "find", null);
_ts_decorate4([
  import_tracing5.trace.span({
    showInBrowserTimeline: true
  })
], IndexVector.prototype, "serialize", null);
_ts_decorate4([
  import_tracing5.trace.span({
    showInBrowserTimeline: true
  })
], IndexVector, "load", null);
IndexVector = _ts_decorate4([
  import_tracing5.trace.resource(),
  staticImplements()
], IndexVector);
var IndexConstructors = {
  [import_indexing4.IndexKind.Kind.SCHEMA_MATCH]: IndexSchema,
  [import_indexing4.IndexKind.Kind.GRAPH]: IndexGraph,
  [import_indexing4.IndexKind.Kind.VECTOR]: IndexVector,
  [import_indexing4.IndexKind.Kind.FULL_TEXT]: IndexText
};
function _ts_decorate5(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file6 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexing-engine.ts";
var IndexingEngine = class extends import_context7.Resource {
  constructor(options) {
    super();
    this._indexes = new import_util4.ComplexMap((kind) => kind.kind === import_indexing7.IndexKind.Kind.FIELD_MATCH ? `${kind.kind}:${kind.field}` : kind.kind);
    this._newIndexes = [];
    this._db = options.db;
    this._metadataStore = options.metadataStore;
    this._indexStore = options.indexStore;
    this._documentLoader = options.documentLoader;
  }
  async _open(ctx) {
  }
  async _close(ctx) {
    for (const index of this._indexes.values()) {
      await index.close();
    }
    this._newIndexes.length = 0;
    this._indexes.clear();
  }
  get indexKinds() {
    return [
      ...this._indexes.keys()
    ];
  }
  get indexes() {
    return [
      ...this._indexes.values()
    ];
  }
  get newIndexCount() {
    return this._newIndexes.length;
  }
  getIndex(kind) {
    return this._indexes.get(kind);
  }
  deleteIndex(kind) {
    this._indexes.delete(kind);
  }
  async addPersistentIndex(index) {
    this._indexes.set(index.kind, index);
    await index.open();
  }
  async addNewIndex(index) {
    this._newIndexes.push(index);
    await index.open();
  }
  async loadIndexKindsFromDisk() {
    return this._indexStore.loadIndexKindsFromDisk();
  }
  async loadIndexFromDisk(identifier) {
    const index = await this._indexStore.load(identifier);
    this._indexes.set(index.kind, index);
    await index.open();
  }
  async removeIndexFromDisk(identifier) {
    await this._indexStore.remove(identifier);
  }
  /**
  * Promotes new indexes to the main indexes.
  */
  async promoteNewIndexes() {
    const documentsToIndex = await this._metadataStore.getAllIndexedDocuments();
    for await (const documents of this._documentLoader.loadDocuments(documentsToIndex)) {
      if (this._ctx.disposed) {
        return;
      }
      await this._updateIndexes(this._newIndexes, documents);
    }
    this._newIndexes.forEach((index) => this._indexes.set(index.kind, index));
    this._newIndexes.length = 0;
    await this._saveIndexes();
  }
  /**
  * Indexes updated objects.
  * @returns completed - whether the indexing was completed
  * @returns updated - whether the indexing updated any indexes
  */
  async indexUpdatedObjects(options) {
    let completed = true;
    let updated = false;
    if (this._ctx.disposed) {
      return {
        completed,
        updated
      };
    }
    const idToHeads = await this._metadataStore.getDirtyDocuments();
    (0, import_log6.log)("dirty objects to index", {
      count: idToHeads.size
    }, {
      F: __dxlog_file6,
      L: 162,
      S: this,
      C: (f, a) => f(...a)
    });
    if (idToHeads.size === 0 || this._ctx.disposed) {
      return {
        completed,
        updated
      };
    }
    const startTime = Date.now();
    const documentsUpdated = [];
    const saveIndexChanges = async () => {
      (0, import_log6.log)("Saving index changes", {
        count: documentsUpdated.length,
        timeSinceStart: Date.now() - startTime
      }, {
        F: __dxlog_file6,
        L: 170,
        S: this,
        C: (f, a) => f(...a)
      });
      await this._saveIndexes();
      const batch = this._db.batch();
      this._metadataStore.markClean(new Map(documentsUpdated.map((document) => [
        document.id,
        document.heads
      ])), batch);
      await batch.write();
    };
    const updates = [];
    for await (const documents of this._documentLoader.loadDocuments(idToHeads)) {
      if (this._ctx.disposed) {
        return {
          completed,
          updated
        };
      }
      updates.push(...await this._updateIndexes(Array.from(this._indexes.values()), documents));
      documentsUpdated.push(...documents);
      if (documentsUpdated.length >= options.indexUpdateBatchSize) {
        await saveIndexChanges();
        documentsUpdated.length = 0;
      }
      if (Date.now() - startTime > options.indexTimeBudget) {
        if (documentsUpdated.length > 0) {
          await saveIndexChanges();
        }
        (0, import_log6.log)("Indexing time budget exceeded", {
          time: Date.now() - startTime
        }, {
          F: __dxlog_file6,
          L: 192,
          S: this,
          C: (f, a) => f(...a)
        });
        completed = false;
        break;
      }
    }
    await saveIndexChanges();
    if (updates.some(Boolean)) {
      updated = true;
    }
    (0, import_log6.log)("Indexing finished", {
      time: Date.now() - startTime
    }, {
      F: __dxlog_file6,
      L: 202,
      S: this,
      C: (f, a) => f(...a)
    });
    return {
      completed,
      updated
    };
  }
  async _updateIndexes(indexes, documents) {
    const updates = [];
    for (const index of indexes) {
      if (this._ctx.disposed) {
        return updates;
      }
      switch (index.kind.kind) {
        case import_indexing7.IndexKind.Kind.FIELD_MATCH:
          (0, import_invariant5.invariant)(index.kind.field, "Field match index kind should have a field", {
            F: __dxlog_file6,
            L: 215,
            S: this,
            A: [
              "index.kind.field",
              "'Field match index kind should have a field'"
            ]
          });
          updates.push(...await updateIndexWithObjects(index, documents.filter((document) => index.kind.field in document.object)));
          break;
        case import_indexing7.IndexKind.Kind.SCHEMA_MATCH:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
        case import_indexing7.IndexKind.Kind.GRAPH:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
        case import_indexing7.IndexKind.Kind.VECTOR:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
        case import_indexing7.IndexKind.Kind.FULL_TEXT:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
      }
    }
    return updates;
  }
  async _saveIndexes() {
    for (const index of this._indexes.values()) {
      if (this._ctx.disposed) {
        return;
      }
      await this._indexStore.save(index);
    }
  }
};
_ts_decorate5([
  import_tracing6.trace.span({
    showInBrowserTimeline: true
  })
], IndexingEngine.prototype, "promoteNewIndexes", null);
_ts_decorate5([
  import_tracing6.trace.span({
    showInBrowserTimeline: true
  })
], IndexingEngine.prototype, "indexUpdatedObjects", null);
_ts_decorate5([
  import_tracing6.trace.span({
    showInBrowserTimeline: true
  })
], IndexingEngine.prototype, "_updateIndexes", null);
_ts_decorate5([
  import_tracing6.trace.span({
    showInBrowserTimeline: true
  }),
  import_async6.synchronized
], IndexingEngine.prototype, "_saveIndexes", null);
var updateIndexWithObjects = async (index, snapshots) => Promise.all(snapshots.map((snapshot) => index.update(snapshot.id, snapshot.object)));
function _ts_decorate6(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file7 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexer.ts";
var DEFAULT_INDEX_UPDATE_BATCH_SIZE = 100;
var DEFAULT_INDEX_COOLDOWN_TIME = 100;
var DEFAULT_INDEX_TIME_BUDGET = 300;
var Indexer = class extends import_context.Resource {
  constructor({ db, metadataStore, indexStore, loadDocuments, indexUpdateBatchSize = DEFAULT_INDEX_UPDATE_BATCH_SIZE, indexCooldownTime = DEFAULT_INDEX_COOLDOWN_TIME, indexTimeBudget = DEFAULT_INDEX_TIME_BUDGET }) {
    super();
    this.updated = new import_async.Event();
    this._lastRunFinishedAt = 0;
    this._db = db;
    this._metadataStore = metadataStore;
    this._indexUpdateBatchSize = indexUpdateBatchSize;
    this._indexCooldownTime = indexCooldownTime;
    this._indexTimeBudget = indexTimeBudget;
    this._engine = new IndexingEngine({
      db,
      metadataStore,
      indexStore,
      documentLoader: {
        loadDocuments
      }
    });
  }
  get initialized() {
    return this._lifecycleState === import_context.LifecycleState.OPEN;
  }
  async setConfig(config) {
    this._indexConfig = config;
    if (this._lifecycleState === import_context.LifecycleState.OPEN) {
      import_log.log.warn("Setting index config after initialization, this is unstable", {
        config
      }, {
        F: __dxlog_file7,
        L: 105,
        S: this,
        C: (f, a) => f(...a)
      });
      for (const kind of this._engine.indexKinds) {
        if (!config.indexes?.some((kind2) => (0, import_lodash.default)(kind2, kind2))) {
          this._engine.deleteIndex(kind);
        }
      }
      await this._loadIndexes();
      this._run.schedule();
    }
  }
  async _open(ctx) {
    if (!this._indexConfig) {
      import_log.log.warn("Index config is not set", void 0, {
        F: __dxlog_file7,
        L: 119,
        S: this,
        C: (f, a) => f(...a)
      });
    }
    await this._engine.open(ctx);
    this._run = new import_async.DeferredTask(this._ctx, async () => {
      try {
        if (this._lifecycleState !== import_context.LifecycleState.OPEN || this._indexConfig?.enabled !== true) {
          return;
        }
        const cooldownMs = this._lastRunFinishedAt + this._indexCooldownTime - Date.now();
        if (cooldownMs > 0) {
          await (0, import_async.sleepWithContext)(this._ctx, cooldownMs);
        }
        if (this._engine.newIndexCount > 0) {
          await this._promoteNewIndexes();
        }
        await this._indexUpdatedObjects();
      } finally {
        this._lastRunFinishedAt = Date.now();
      }
    });
    await this._loadIndexes();
    if (this._indexConfig?.enabled === true) {
      this._metadataStore.dirty.on(this._ctx, () => this._run.schedule());
      this._run.schedule();
    }
  }
  async _close(ctx) {
    await this._run.join();
    await this._engine.close(ctx);
  }
  async _catch(err) {
    import_log.log.catch(err, void 0, {
      F: __dxlog_file7,
      L: 162,
      S: this,
      C: (f, a) => f(...a)
    });
  }
  // TODO(dmaretskyi): Allow consumers to get specific index instances and query them directly.
  async execQuery(filter) {
    if (this._lifecycleState !== import_context.LifecycleState.OPEN || this._indexConfig?.enabled !== true) {
      throw new Error("Indexer is not initialized or not enabled");
    }
    if (filter.graph) {
      const graphIndex = this._engine.getIndex({
        kind: import_indexing.IndexKind.Kind.GRAPH
      });
      if (!graphIndex) {
        return [];
      }
      return graphIndex.find(filter);
    } else if (filter.text?.kind === "vector") {
      const vectorIndex = this._engine.getIndex({
        kind: import_indexing.IndexKind.Kind.VECTOR
      });
      if (!vectorIndex) {
        return [];
      }
      return vectorIndex.find(filter);
    } else if (filter.text?.kind === "text") {
      const textIndex = this._engine.getIndex({
        kind: import_indexing.IndexKind.Kind.FULL_TEXT
      });
      if (!textIndex) {
        return [];
      }
      return textIndex.find(filter);
    } else {
      const typenameIndex = this._engine.getIndex({
        kind: import_indexing.IndexKind.Kind.SCHEMA_MATCH
      });
      if (!typenameIndex) {
        return [];
      }
      return typenameIndex.find(filter);
    }
  }
  async reindex(idToHeads) {
    const batch = this._db.batch();
    this._metadataStore.markDirty(idToHeads, batch);
    this._metadataStore.dropFromClean(Array.from(idToHeads.keys()), batch);
    await batch.write();
    await this._run.runBlocking();
  }
  /**
  * Perform any pending index updates.
  */
  async updateIndexes() {
    await this._run.runBlocking();
  }
  async _loadIndexes() {
    const kinds = await this._engine.loadIndexKindsFromDisk();
    for (const [identifier, kind] of kinds.entries()) {
      if (!this._indexConfig || this._indexConfig.indexes?.some((configKind) => (0, import_lodash.default)(configKind, kind))) {
        try {
          await this._engine.loadIndexFromDisk(identifier);
        } catch (err) {
          import_log.log.warn("Failed to load index", {
            err,
            identifier
          }, {
            F: __dxlog_file7,
            L: 227,
            S: this,
            C: (f, a) => f(...a)
          });
        }
      } else {
        await this._engine.removeIndexFromDisk(identifier);
      }
    }
    for (const kind of this._indexConfig?.indexes || []) {
      if (!this._engine.getIndex(kind)) {
        const IndexConstructor = IndexConstructors[kind.kind];
        (0, import_invariant.invariant)(IndexConstructor, `Index kind ${kind.kind} is not supported`, {
          F: __dxlog_file7,
          L: 240,
          S: this,
          A: [
            "IndexConstructor",
            "`Index kind ${kind.kind} is not supported`"
          ]
        });
        await this._engine.addNewIndex(new IndexConstructor(kind));
      }
    }
  }
  async _promoteNewIndexes() {
    await this._engine.promoteNewIndexes();
    this.updated.emit();
  }
  async _indexUpdatedObjects() {
    if (this._ctx.disposed) {
      return;
    }
    const { completed, updated } = await this._engine.indexUpdatedObjects({
      indexTimeBudget: this._indexTimeBudget,
      indexUpdateBatchSize: this._indexUpdateBatchSize
    });
    if (!completed) {
      this._run.schedule();
    }
    if (updated) {
      this.updated.emit();
    }
  }
};
_ts_decorate6([
  import_async.synchronized
], Indexer.prototype, "setConfig", null);
_ts_decorate6([
  import_tracing.trace.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "_open", null);
_ts_decorate6([
  import_async.synchronized
], Indexer.prototype, "execQuery", null);
_ts_decorate6([
  import_tracing.trace.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "reindex", null);
_ts_decorate6([
  import_tracing.trace.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "_promoteNewIndexes", null);
_ts_decorate6([
  import_tracing.trace.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "_indexUpdatedObjects", null);
Indexer = _ts_decorate6([
  import_tracing.trace.resource()
], Indexer);
var __dxlog_file8 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/store/index-store.ts";
var CODEC_VERSION = 2;
var IndexStore = class {
  constructor({ db }) {
    this._db = db;
    import_tracing7.trace.diagnostic({
      id: "indexes",
      name: "Indexes",
      fetch: async () => {
        const indexes = await this._db.iterator(encodings).all();
        return indexes.map(([identifier, { index, ...rest }]) => ({
          identifier,
          ...rest
        }));
      }
    });
  }
  async save(index) {
    await this._db.put(index.identifier, await indexCodec.encode(index), encodings);
  }
  async load(identifier) {
    const data = await this._db.get(identifier, encodings);
    return indexCodec.decode(identifier, data);
  }
  async remove(identifier) {
    await this._db.del(identifier, encodings);
  }
  /**
  *
  * @returns Map of index identifiers vs their kinds.
  */
  async loadIndexKindsFromDisk() {
    const kinds = /* @__PURE__ */ new Map();
    for await (const [identifier, data] of this._db.iterator(encodings)) {
      data.kind && kinds.set(identifier, data.kind);
    }
    {
      const seenKinds = [];
      const allKinds = Array.from(kinds.values());
      for (const kind of allKinds) {
        if (!seenKinds.some((seenKind) => (0, import_lodash2.default)(seenKind, kind))) {
          seenKinds.push(kind);
          continue;
        }
        const entries2 = Array.from(kinds.entries());
        for (const [identifier, indexKind] of entries2) {
          if ((0, import_lodash2.default)(indexKind, kind)) {
            await this.remove(identifier);
            kinds.delete(identifier);
          }
        }
      }
    }
    return kinds;
  }
};
var encodings = {
  keyEncoding: "utf8",
  valueEncoding: "json"
};
var indexCodec = {
  encode: async (index) => {
    return {
      index: await index.serialize(),
      kind: index.kind,
      version: CODEC_VERSION
    };
  },
  decode: async (identifier, data) => {
    (0, import_invariant6.invariant)(data.version === CODEC_VERSION, `Index version ${data.version} is not supported`, {
      F: __dxlog_file8,
      L: 105,
      S: void 0,
      A: [
        "data.version === CODEC_VERSION",
        "`Index version ${data.version} is not supported`"
      ]
    });
    const IndexConstructor = IndexConstructors[data.kind.kind];
    (0, import_invariant6.invariant)(IndexConstructor, `Index kind ${data.kind.kind} is not supported`, {
      F: __dxlog_file8,
      L: 107,
      S: void 0,
      A: [
        "IndexConstructor",
        "`Index kind ${data.kind.kind} is not supported`"
      ]
    });
    return IndexConstructor.load({
      serialized: data.index,
      indexKind: data.kind,
      identifier
    });
  }
};
function _ts_decorate7(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file9 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/store/index-metadata-store.ts";
var IndexMetadataStore = class {
  constructor({ db }) {
    this.dirty = new import_async7.Event();
    this.clean = new import_async7.Event();
    this._lastSeen = db.sublevel("last-seen", {
      valueEncoding: headsEncoding,
      keyEncoding: "utf8"
    });
    this._lastIndexed = db.sublevel("last-indexed", {
      valueEncoding: headsEncoding,
      keyEncoding: "utf8"
    });
    import_tracing8.trace.diagnostic({
      id: "indexed-documents",
      name: "Indexed Documents",
      fetch: async () => {
        const [dirty, indexed] = await Promise.all([
          this.getDirtyDocuments(),
          this.getAllIndexedDocuments()
        ]);
        return (0, import_util5.joinTables)("id", "id", Array.from(dirty.entries()).map(([id, heads]) => ({
          id,
          dirtyHeads: heads.join(",")
        })), Array.from(indexed.entries()).map(([id, heads]) => ({
          id,
          indexedHeads: heads.join(",")
        })));
      }
    });
  }
  async getDirtyDocuments() {
    return new Map(await this._lastSeen.iterator({}).all());
  }
  /**
  * @returns All document id's that were already indexed. May include dirty documents.
  */
  async getAllIndexedDocuments() {
    return new Map(await this._lastIndexed.iterator({}).all());
  }
  markDirty(idToHeads, batch) {
    (0, import_log7.log)("mark dirty", {
      count: idToHeads.size
    }, {
      F: __dxlog_file9,
      L: 76,
      S: this,
      C: (f, a) => f(...a)
    });
    for (const [id, heads] of idToHeads.entries()) {
      batch.put(id, heads, {
        sublevel: this._lastSeen,
        valueEncoding: headsEncoding
      });
      batch.del(import_protocols2.objectPointerCodec.convertV1ToV0(id), {
        sublevel: this._lastIndexed
      });
    }
  }
  /**
  * Called after leveldb batch commit.
  */
  notifyMarkedDirty() {
    this.dirty.emit();
  }
  markClean(idToHeads, batch) {
    (0, import_log7.log)("mark clean", {
      count: idToHeads.size
    }, {
      F: __dxlog_file9,
      L: 94,
      S: this,
      C: (f, a) => f(...a)
    });
    for (const [id, heads] of idToHeads.entries()) {
      batch.put(id, heads, {
        sublevel: this._lastIndexed,
        valueEncoding: headsEncoding
      });
      batch.del(id, {
        sublevel: this._lastSeen
      });
      batch.del(import_protocols2.objectPointerCodec.convertV1ToV0(id), {
        sublevel: this._lastIndexed
      });
      batch.del(import_protocols2.objectPointerCodec.convertV1ToV0(id), {
        sublevel: this._lastSeen
      });
    }
  }
  /**
  * Called on re-indexing.
  */
  dropFromClean(ids, batch) {
    for (const id of ids) {
      batch.del(id, {
        sublevel: this._lastIndexed
      });
    }
  }
};
_ts_decorate7([
  import_tracing8.trace.span({
    showInBrowserTimeline: true
  })
], IndexMetadataStore.prototype, "getDirtyDocuments", null);
_ts_decorate7([
  import_tracing8.trace.span({
    showInBrowserTimeline: true
  })
], IndexMetadataStore.prototype, "markDirty", null);
_ts_decorate7([
  import_tracing8.trace.span({
    showInBrowserTimeline: true
  })
], IndexMetadataStore.prototype, "markClean", null);
IndexMetadataStore = _ts_decorate7([
  import_tracing8.trace.resource()
], IndexMetadataStore);
var headsCodec;
var getHeadsCodec = () => headsCodec ??= import_proto.schema.getCodecForType("dxos.echo.query.Heads");
var showedWarning = false;
var headsEncoding = {
  encode: (value) => getHeadsCodec().encode({
    hashes: value
  }),
  decode: (encodedValue) => {
    try {
      return getHeadsCodec().decode(encodedValue).hashes;
    } catch (err) {
      if (!showedWarning) {
        showedWarning = true;
        import_log7.log.warn("Detected legacy encoding of heads in the indexer. \nRun `await dxos.client.repair()`", void 0, {
          F: __dxlog_file9,
          L: 130,
          S: void 0,
          C: (f, a) => f(...a)
        });
      }
      const concatenatedHeads = Buffer.from(encodedValue).toString("utf8").replace(/"/g, "");
      (0, import_invariant7.invariant)(concatenatedHeads.length % 64 === 0, "Invalid concatenated heads length", {
        F: __dxlog_file9,
        L: 138,
        S: void 0,
        A: [
          "concatenatedHeads.length % 64 === 0",
          "'Invalid concatenated heads length'"
        ]
      });
      const heads = [];
      for (let i = 0; i < concatenatedHeads.length; i += 64) {
        heads.push(concatenatedHeads.slice(i, i + 64));
      }
      return heads;
    }
  },
  format: "buffer"
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  EscapedPropPath,
  IndexMetadataStore,
  IndexStore,
  Indexer,
  headsEncoding,
  staticImplements
});
//# sourceMappingURL=index.cjs.map
