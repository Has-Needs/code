import { createRequire } from 'node:module';const require = createRequire(import.meta.url);

// packages/core/echo/indexing/src/indexer.ts
import isEqual from "lodash.isequal";
import { DeferredTask, Event as Event5, sleepWithContext, synchronized as synchronized2 } from "@dxos/async";
import { LifecycleState, Resource as Resource7 } from "@dxos/context";
import { invariant as invariant5 } from "@dxos/invariant";
import { log as log6 } from "@dxos/log";
import { IndexKind as IndexKind7 } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace as trace6 } from "@dxos/tracing";

// packages/core/echo/indexing/src/indexes/index-text.ts
import * as Orama from "@orama/orama";
import { Event } from "@dxos/async";
import { Resource } from "@dxos/context";
import { invariant as invariant2 } from "@dxos/invariant";
import { PublicKey } from "@dxos/keys";
import { log } from "@dxos/log";
import { IndexKind } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace } from "@dxos/tracing";

// packages/core/echo/indexing/src/indexes/text.ts
import { decodeReference, isEncodedReference, ObjectStructure } from "@dxos/echo-protocol";
import { visitValues } from "@dxos/util";
var IGNORED_TYPENAMES = [
  "dxos.org/type/Canvas"
];
var extractTextBlocks = (object) => {
  const type = ObjectStructure.getTypeReference(object);
  const dxnType = type && decodeReference(type).toDXN();
  if (IGNORED_TYPENAMES.includes(dxnType?.asTypeDXN()?.type ?? "")) {
    return [];
  }
  const blocks = [];
  const go = (value, _key) => {
    if (isEncodedReference(value)) {
      return;
    }
    if (typeof value === "string") {
      blocks.push({
        content: value
      });
    }
    visitValues(value, go);
  };
  visitValues(object.data, go);
  return blocks;
};

// packages/core/echo/indexing/src/types.ts
import { Schema } from "effect";
import { invariant } from "@dxos/invariant";
var __dxlog_file = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/types.ts";
var staticImplements = () => (constructor) => {
  return constructor;
};
var EscapedPropPath = class extends Schema.String.annotations({
  title: "EscapedPropPath"
}) {
  static escape(path) {
    return path.map((p) => p.toString().replaceAll("\\", "\\\\").replaceAll(".", "\\.")).join(".");
  }
  static unescape(path) {
    const parts = [];
    let current = "";
    for (let i = 0; i < path.length; i++) {
      if (path[i] === "\\") {
        invariant(i + 1 < path.length && (path[i + 1] === "." || path[i + 1] === "\\"), "Malformed escaping.", {
          F: __dxlog_file,
          L: 134,
          S: this,
          A: [
            "i + 1 < path.length && (path[i + 1] === '.' || path[i + 1] === '\\\\')",
            "'Malformed escaping.'"
          ]
        });
        current = current + path[i + 1];
        i++;
      } else if (path[i] === ".") {
        parts.push(current);
        current = "";
      } else {
        current += path[i];
      }
    }
    parts.push(current);
    return parts;
  }
};

// packages/core/echo/indexing/src/indexes/index-text.ts
function _ts_decorate(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file2 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-text.ts";
var IndexText = class _IndexText extends Resource {
  constructor() {
    super(...arguments);
    this._identifier = PublicKey.random().toString();
    this.kind = {
      kind: IndexKind.Kind.FULL_TEXT
    };
    this.updated = new Event();
    this._orama = void 0;
  }
  async _open() {
    this._orama = await Orama.create({
      schema: {
        chunks: "string[]"
      }
    });
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    const blocks = extractTextBlocks(object);
    invariant2(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 63,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama.remove(this._orama, id);
    await Orama.insert(this._orama, {
      id,
      chunks: blocks.map((block) => block.content)
    });
    return true;
  }
  async remove(id) {
    invariant2(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 73,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama.remove(this._orama, id);
  }
  async find(filter) {
    invariant2(filter.typenames.length === 0, "Typenames are not supported", {
      F: __dxlog_file2,
      L: 79,
      S: this,
      A: [
        "filter.typenames.length === 0",
        "'Typenames are not supported'"
      ]
    });
    invariant2(!filter.inverted, "Inverted search is not supported", {
      F: __dxlog_file2,
      L: 80,
      S: this,
      A: [
        "!filter.inverted",
        "'Inverted search is not supported'"
      ]
    });
    invariant2(!filter.graph, "Graph search is not supported", {
      F: __dxlog_file2,
      L: 81,
      S: this,
      A: [
        "!filter.graph",
        "'Graph search is not supported'"
      ]
    });
    invariant2(typeof filter.text?.query === "string", void 0, {
      F: __dxlog_file2,
      L: 82,
      S: this,
      A: [
        "typeof filter.text?.query === 'string'",
        ""
      ]
    });
    invariant2(filter.text?.kind === "text", void 0, {
      F: __dxlog_file2,
      L: 83,
      S: this,
      A: [
        "filter.text?.kind === 'text'",
        ""
      ]
    });
    invariant2(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 85,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    const results = await Orama.search(this._orama, {
      mode: "fulltext",
      term: filter.text.query,
      // TODO(dmaretskyi): Add a way to configure these.
      limit: 10,
      offset: 0
    });
    log.info("Text search results", {
      query: filter.text.query,
      results
    }, {
      F: __dxlog_file2,
      L: 95,
      S: this,
      C: (f, a) => f(...a)
    });
    return results.hits.map((hit) => ({
      id: hit.id,
      rank: hit.score
    }));
  }
  async serialize() {
    invariant2(this._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 105,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    return JSON.stringify(await Orama.save(this._orama), null, 2);
  }
  static async load({ serialized, identifier }) {
    const deserialized = JSON.parse(serialized);
    const index = new _IndexText();
    await index.open();
    invariant2(index._orama, "Index is not initialized", {
      F: __dxlog_file2,
      L: 115,
      S: this,
      A: [
        "index._orama",
        "'Index is not initialized'"
      ]
    });
    index._identifier = identifier;
    await Orama.load(index._orama, deserialized);
    return index;
  }
};
_ts_decorate([
  trace.span({
    showInBrowserTimeline: true
  })
], IndexText.prototype, "update", null);
_ts_decorate([
  trace.span({
    showInBrowserTimeline: true
  })
], IndexText.prototype, "find", null);
_ts_decorate([
  trace.span({
    showInBrowserTimeline: true
  })
], IndexText.prototype, "serialize", null);
_ts_decorate([
  trace.span({
    showInBrowserTimeline: true
  })
], IndexText, "load", null);
IndexText = _ts_decorate([
  trace.resource(),
  staticImplements()
], IndexText);

// packages/core/echo/indexing/src/indexes/index-schema.ts
import { Event as Event2 } from "@dxos/async";
import { Resource as Resource2 } from "@dxos/context";
import { decodeReference as decodeReference2 } from "@dxos/echo-protocol";
import { EXPANDO_TYPENAME } from "@dxos/echo-schema";
import { DXN, PublicKey as PublicKey2 } from "@dxos/keys";
import { log as log2 } from "@dxos/log";
import { IndexKind as IndexKind2 } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace as trace2 } from "@dxos/tracing";
import { defaultMap } from "@dxos/util";
function _ts_decorate2(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file3 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-schema.ts";
var IndexSchema = class _IndexSchema extends Resource2 {
  constructor() {
    super(...arguments);
    this._identifier = PublicKey2.random().toString();
    this.kind = {
      kind: IndexKind2.Kind.SCHEMA_MATCH
    };
    this.updated = new Event2();
    /**
    * Map `typename` -> Set `index id`.
    * @see https://v8.dev/blog/hash-code for performance estimations.
    */
    this._index = /* @__PURE__ */ new Map();
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    if (this._index.get(getTypeFromObject(object))?.has(id)) {
      return false;
    }
    defaultMap(this._index, getTypeFromObject(object), /* @__PURE__ */ new Set()).add(id);
    return true;
  }
  async remove(id) {
    for (const [_, ids] of this._index.entries()) {
      if (ids.has(id)) {
        ids.delete(id);
        return;
      }
    }
  }
  async find(filter) {
    if (filter.inverted) {
      return Array.from(this._index.entries()).filter(([key]) => !filter.typenames.includes(key ?? EXPANDO_TYPENAME) === false).flatMap(([, value]) => Array.from(value)).map((id) => ({
        id,
        rank: 0
      }));
    }
    if (filter.typenames.length === 0) {
      return Array.from(this._index.values()).flatMap((ids) => Array.from(ids)).map((id) => ({
        id,
        rank: 0
      }));
    }
    const results = [];
    for (const typename of filter.typenames) {
      if (typename === EXPANDO_TYPENAME || DXN.isDXNString(typename) && DXN.parse(typename).asTypeDXN()?.type === EXPANDO_TYPENAME) {
        results.push(...Array.from(this._index.get(null) ?? []).map((id) => ({
          id,
          rank: 0
        })));
      } else if (DXN.isDXNString(typename)) {
        const dxn = DXN.parse(typename);
        if (dxn.isLocalObjectId()) {
          const objectId = dxn.parts[1];
          results.push(...Array.from(this._index.get(objectId) ?? []).map((id) => ({
            id,
            rank: 0
          })));
        } else if (dxn.kind === DXN.kind.TYPE) {
          const typename2 = dxn.parts[0];
          results.push(...Array.from(this._index.get(typename2) ?? []).map((id) => ({
            id,
            rank: 0
          })));
        } else {
          log2.warn("Unsupported DXN", {
            dxn
          }, {
            F: __dxlog_file3,
            L: 95,
            S: this,
            C: (f, a) => f(...a)
          });
        }
      } else {
        results.push(...Array.from(this._index.get(typename) ?? []).map((id) => ({
          id,
          rank: 0
        })));
      }
    }
    return results.flat();
  }
  async serialize() {
    return JSON.stringify({
      index: Array.from(this._index.entries()).map(([type, ids]) => ({
        type,
        ids: Array.from(ids)
      }))
    });
  }
  static async load({ serialized, identifier }) {
    const index = new _IndexSchema();
    const serializedIndex = JSON.parse(serialized).index;
    index._identifier = identifier;
    for (const { type, ids } of serializedIndex) {
      index._index.set(type, new Set(ids));
    }
    return index;
  }
};
_ts_decorate2([
  trace2.span({
    showInBrowserTimeline: true
  })
], IndexSchema.prototype, "update", null);
_ts_decorate2([
  trace2.span({
    showInBrowserTimeline: true
  })
], IndexSchema.prototype, "find", null);
_ts_decorate2([
  trace2.span({
    showInBrowserTimeline: true
  })
], IndexSchema.prototype, "serialize", null);
_ts_decorate2([
  trace2.span({
    showInBrowserTimeline: true
  })
], IndexSchema, "load", null);
IndexSchema = _ts_decorate2([
  trace2.resource(),
  staticImplements()
], IndexSchema);
var getTypeFromObject = (object) => object.system?.type ? decodeReference2(object.system.type).objectId ?? null : null;

// packages/core/echo/indexing/src/indexes/index-constructors.ts
import { IndexKind as IndexKind5 } from "@dxos/protocols/proto/dxos/echo/indexing";

// packages/core/echo/indexing/src/indexes/index-graph.ts
import { pipe, Schema as Schema2 } from "effect";
import { Event as Event3 } from "@dxos/async";
import { Resource as Resource3 } from "@dxos/context";
import { decodeReference as decodeReference3, ObjectStructure as ObjectStructure2 } from "@dxos/echo-protocol";
import { EntityKind, ObjectId } from "@dxos/echo-schema";
import { InternalError } from "@dxos/errors";
import { PublicKey as PublicKey3 } from "@dxos/keys";
import { log as log3 } from "@dxos/log";
import { ObjectPointerEncoded } from "@dxos/protocols";
import { IndexKind as IndexKind3 } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace as trace3 } from "@dxos/tracing";
import { defaultMap as defaultMap2, entries } from "@dxos/util";
function _ts_decorate3(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file4 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-graph.ts";
var IndexGraph = class _IndexGraph extends Resource3 {
  constructor() {
    super(...arguments);
    this._identifier = PublicKey3.random().toString();
    this.kind = {
      kind: IndexKind3.Kind.GRAPH
    };
    this.updated = new Event3();
    /**
    * Tracks inbound references for each object.
    *
    * target object id -> prop name -> set of source object ids
    */
    this._inboundReferences = /* @__PURE__ */ new Map();
    /**
    * Tracks relation targets for each object.
    *
    * relation target object id -> set of relation ids
    */
    this._relationTargets = /* @__PURE__ */ new Map();
    /**
    * Tracks relation sources for each object.
    *
    * relation source object id -> set of relation ids
    */
    this._relationSources = /* @__PURE__ */ new Map();
    /**
    * Mapping from the object to the list of reference targets.
    * We need this because on index update we don't know what the previous version of the object was.
    * This mapping is used to remove the old relations on update.
    */
    // TODO(dmaretskyi): Index should have access to the previous state on update.
    this._objectToTargets = /* @__PURE__ */ new Map();
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    const kind = ObjectStructure2.getEntityKind(object);
    switch (kind) {
      case EntityKind.Object: {
        this._removeReferencesFrom(id);
        this._trackOutgoingReferences(id, object);
        break;
      }
      case EntityKind.Relation: {
        this._removeReferencesFrom(id);
        this._trackOutgoingReferences(id, object);
        const targetMapping = defaultMap2(this._objectToTargets, id, () => /* @__PURE__ */ new Set());
        const source = ObjectStructure2.getRelationSource(object);
        const target = ObjectStructure2.getRelationTarget(object);
        if (source) {
          const sourceObject = decodeReference3(source).toDXN().asEchoDXN()?.echoId;
          if (sourceObject) {
            defaultMap2(this._relationSources, sourceObject, () => /* @__PURE__ */ new Set()).add(id);
            targetMapping.add(sourceObject);
          }
        } else {
          log3.warn("relation has no source", {
            id
          }, {
            F: __dxlog_file4,
            L: 98,
            S: this,
            C: (f, a) => f(...a)
          });
        }
        if (target) {
          const targetObject = decodeReference3(target).toDXN().asEchoDXN()?.echoId;
          if (targetObject) {
            defaultMap2(this._relationTargets, targetObject, () => /* @__PURE__ */ new Set()).add(id);
            targetMapping.add(targetObject);
          }
        } else {
          log3.warn("relation has no target", {
            id
          }, {
            F: __dxlog_file4,
            L: 107,
            S: this,
            C: (f, a) => f(...a)
          });
        }
        break;
      }
      default: {
        log3.warn("unknown entity kind", {
          kind
        }, {
          F: __dxlog_file4,
          L: 112,
          S: this,
          C: (f, a) => f(...a)
        });
        break;
      }
    }
    return true;
  }
  async remove(id) {
    this._removeReferencesFrom(id);
  }
  _removeReferencesFrom(id) {
    for (const target of this._objectToTargets.get(id) ?? []) {
      const perField = this._inboundReferences.get(target);
      if (!perField) {
        continue;
      }
      for (const field of perField.keys()) {
        perField.get(field)?.delete(id);
      }
      this._relationTargets.get(target)?.delete(id);
      this._relationSources.get(target)?.delete(id);
    }
    this._objectToTargets.get(id)?.clear();
  }
  _trackOutgoingReferences(id, object) {
    const targetMapping = defaultMap2(this._objectToTargets, id, () => /* @__PURE__ */ new Set());
    const references = ObjectStructure2.getAllOutgoingReferences(object);
    for (const { path, reference } of references) {
      const targetObject = decodeReference3(reference).toDXN().asEchoDXN()?.echoId;
      if (!targetObject) {
        continue;
      }
      const escapedPath = EscapedPropPath.escape(path);
      pipe(this._inboundReferences, (map) => defaultMap2(map, targetObject, () => /* @__PURE__ */ new Map()), (map) => defaultMap2(map, escapedPath, () => /* @__PURE__ */ new Set())).add(id);
      targetMapping.add(targetObject);
    }
  }
  async find(filter) {
    if (filter.inverted || filter.typenames.length > 0 || !filter.graph) {
      throw new InternalError("Invalid filter for graph query");
    }
    const { kind, anchors, property } = filter.graph;
    switch (kind) {
      case "inbound-reference": {
        const results = [];
        for (const anchor of anchors) {
          const sources = this._inboundReferences.get(anchor);
          if (!sources) {
            continue;
          }
          if (property !== null) {
            for (const [escapedProp, source] of sources.entries()) {
              const prop = EscapedPropPath.unescape(escapedProp);
              const firstSegmentMatches = prop[0] === property;
              const secondSegmentIsNumeric = !isNaN(Number(prop[1]));
              if (firstSegmentMatches && (prop.length === 1 || prop.length === 2 && secondSegmentIsNumeric)) {
                results.push(...Array.from(source).map((id) => ({
                  id,
                  rank: 0
                })));
              }
            }
          } else {
            for (const source of sources.values()) {
              results.push(...Array.from(source).map((id) => ({
                id,
                rank: 0
              })));
            }
          }
        }
        return results;
      }
      case "relation-source": {
        const results = [];
        for (const anchor of anchors) {
          const sources = this._relationSources.get(anchor);
          if (!sources) {
            continue;
          }
          results.push(...Array.from(sources).map((id) => ({
            id,
            rank: 0
          })));
        }
        return results;
      }
      case "relation-target": {
        const results = [];
        for (const anchor of anchors) {
          const sources = this._relationTargets.get(anchor);
          if (!sources) {
            continue;
          }
          results.push(...Array.from(sources).map((id) => ({
            id,
            rank: 0
          })));
        }
        return results;
      }
      default: {
        throw new TypeError("Unknown graph query kind");
      }
    }
  }
  async serialize() {
    const data = {
      inboundReferences: Object.fromEntries([
        ...this._inboundReferences.entries()
      ].map(([target, perProp]) => [
        target,
        Object.fromEntries([
          ...perProp.entries()
        ].map(([prop, sources]) => [
          prop,
          Array.from(sources)
        ]))
      ])),
      relationTargets: Object.fromEntries([
        ...this._relationTargets.entries()
      ].map(([target, sources]) => [
        target,
        Array.from(sources)
      ])),
      relationSources: Object.fromEntries([
        ...this._relationSources.entries()
      ].map(([target, sources]) => [
        target,
        Array.from(sources)
      ])),
      objectToTargets: Object.fromEntries([
        ...this._objectToTargets.entries()
      ].map(([target, sources]) => [
        target,
        Array.from(sources)
      ]))
    };
    return JSON.stringify(data);
  }
  static async load({ serialized, identifier }) {
    const index = new _IndexGraph();
    await index.open();
    const data = GraphIndexData.pipe(Schema2.decodeUnknownSync)(JSON.parse(serialized));
    index._loadFrom(data);
    return index;
  }
  _loadFrom(data) {
    this._inboundReferences.clear();
    this._relationTargets.clear();
    this._relationSources.clear();
    this._objectToTargets.clear();
    for (const [target, perProp] of entries(data.inboundReferences)) {
      const propMap = /* @__PURE__ */ new Map();
      this._inboundReferences.set(target, propMap);
      for (const [prop, sources] of entries(perProp)) {
        propMap.set(prop, new Set(sources));
      }
    }
    for (const [target, sources] of entries(data.relationTargets)) {
      this._relationTargets.set(target, new Set(sources));
    }
    for (const [target, sources] of entries(data.relationSources)) {
      this._relationSources.set(target, new Set(sources));
    }
    for (const [target, sources] of entries(data.objectToTargets)) {
      this._objectToTargets.set(target, new Set(sources));
    }
  }
};
_ts_decorate3([
  trace3.span({
    showInBrowserTimeline: true
  })
], IndexGraph.prototype, "update", null);
_ts_decorate3([
  trace3.span({
    showInBrowserTimeline: true
  })
], IndexGraph.prototype, "find", null);
_ts_decorate3([
  trace3.span({
    showInBrowserTimeline: true
  })
], IndexGraph.prototype, "serialize", null);
_ts_decorate3([
  trace3.span({
    showInBrowserTimeline: true
  })
], IndexGraph, "load", null);
IndexGraph = _ts_decorate3([
  trace3.resource(),
  staticImplements()
], IndexGraph);
var GraphIndexData = Schema2.Struct({
  inboundReferences: Schema2.Record({
    key: ObjectId,
    value: Schema2.Record({
      key: EscapedPropPath,
      value: Schema2.Array(ObjectPointerEncoded)
    })
  }),
  relationTargets: Schema2.Record({
    key: ObjectId,
    value: Schema2.Array(ObjectPointerEncoded)
  }),
  relationSources: Schema2.Record({
    key: ObjectId,
    value: Schema2.Array(ObjectPointerEncoded)
  }),
  objectToTargets: Schema2.Record({
    key: ObjectPointerEncoded,
    value: Schema2.Array(ObjectId)
  })
});

// packages/core/echo/indexing/src/indexes/index-vector.ts
import * as Orama2 from "@orama/orama";
import { Event as Event4 } from "@dxos/async";
import { Resource as Resource5 } from "@dxos/context";
import { invariant as invariant3 } from "@dxos/invariant";
import { PublicKey as PublicKey4 } from "@dxos/keys";
import { log as log4 } from "@dxos/log";
import { IndexKind as IndexKind4 } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace as trace4 } from "@dxos/tracing";

// packages/core/echo/indexing/src/indexes/embeddings.ts
import { pipeline } from "@xenova/transformers";
import { Resource as Resource4 } from "@dxos/context";
var DEFAULT_OPTIONS = {
  model: "Xenova/all-MiniLM-L6-v2",
  chunkCombination: "mean",
  maxChunkSize: 500
};
var EmbeddingExtractor = class extends Resource4 {
  constructor(options = {}) {
    super();
    this._extractor = void 0;
    this._options = {
      ...DEFAULT_OPTIONS,
      ...options
    };
  }
  async _open() {
    this._extractor = await pipeline("feature-extraction", this._options.model);
  }
  async _close() {
    await this._extractor?.dispose();
  }
  /**
  * Extracts embeddings from the object.
  * @returns Embeddings for each chunk of the object or a single embedding if chunks are combined.
  */
  async extract(data) {
    const extractor = await pipeline("feature-extraction", this._options.model);
    const chunks = breakIntoChunks(data, this._options.maxChunkSize);
    const embedding = await extractor(chunks.map((block) => block.content), {
      pooling: "mean",
      normalize: true
    });
    let vectors = embedding.tolist();
    vectors = combineChunks(vectors, this._options.chunkCombination);
    return vectors;
  }
};
var combineChunks = (vectors, chunkCombination) => {
  switch (chunkCombination) {
    case "mean": {
      const combined = Array(vectors[0].length).fill(0);
      for (const vector of vectors) {
        for (let i = 0; i < vector.length; i++) {
          combined[i] += vector[i] / vectors.length;
        }
      }
      return [
        combined.map((value) => value / vectors.length)
      ];
    }
    case "max": {
      const combined = Array(vectors[0].length).fill(0);
      for (const vector of vectors) {
        for (let i = 0; i < vector.length; i++) {
          combined[i] = Math.max(combined[i], vector[i]);
        }
      }
      return [
        combined
      ];
    }
    case "disabled":
      return vectors;
  }
};
var breakIntoChunks = (data, maxChunkSize) => {
  const chunks = [];
  for (const block of data) {
    const paragraphs = block.content.split(/\n\s*\n/);
    for (const paragraph of paragraphs) {
      const content = paragraph.trim();
      if (!content) {
        continue;
      }
      if (content.length <= maxChunkSize) {
        chunks.push({
          ...block,
          content
        });
        continue;
      }
      const sentences = content.split(/([.!?]+\s+)/);
      let currentChunk = "";
      for (let i = 0; i < sentences.length; i += 2) {
        const sentence = sentences[i];
        const delimiter = sentences[i + 1] || "";
        const sentenceContent = sentence.trim() + delimiter;
        if (!sentenceContent) {
          continue;
        }
        if (currentChunk.length + sentenceContent.length > maxChunkSize) {
          if (currentChunk) {
            chunks.push({
              ...block,
              content: currentChunk
            });
            currentChunk = "";
          }
          if (sentenceContent.length > maxChunkSize) {
            const words = sentenceContent.split(/(\s+)/);
            currentChunk = "";
            for (let j = 0; j < words.length; j += 2) {
              const word = words[j];
              const wordDelimiter = words[j + 1] || "";
              const wordContent = word.trim() + wordDelimiter;
              if (!wordContent) {
                continue;
              }
              if (currentChunk.length + wordContent.length > maxChunkSize) {
                if (currentChunk) {
                  chunks.push({
                    ...block,
                    content: currentChunk
                  });
                  currentChunk = "";
                }
                if (wordContent.length > maxChunkSize) {
                  for (let k = 0; k < wordContent.length; k += maxChunkSize) {
                    chunks.push({
                      ...block,
                      content: wordContent.slice(k, k + maxChunkSize)
                    });
                  }
                } else {
                  currentChunk = wordContent;
                }
              } else {
                currentChunk += wordContent;
              }
            }
          } else {
            currentChunk = sentenceContent;
          }
        } else {
          currentChunk += sentenceContent;
        }
      }
      if (currentChunk) {
        chunks.push({
          ...block,
          content: currentChunk
        });
      }
    }
  }
  return chunks;
};

// packages/core/echo/indexing/src/indexes/index-vector.ts
function _ts_decorate4(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file5 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexes/index-vector.ts";
var VECTOR_DIMENSION = 384;
var IndexVector = class _IndexVector extends Resource5 {
  constructor() {
    super(...arguments);
    this._identifier = PublicKey4.random().toString();
    this._extractor = new EmbeddingExtractor();
    this.kind = {
      kind: IndexKind4.Kind.VECTOR
    };
    this.updated = new Event4();
    this._orama = void 0;
  }
  async _open() {
    await this._extractor.open();
    this._orama = await Orama2.create({
      schema: {
        embedding: `vector[${VECTOR_DIMENSION}]`
      }
    });
  }
  get identifier() {
    return this._identifier;
  }
  async update(id, object) {
    const blocks = extractTextBlocks(object);
    log4("Extracting embeddings", {
      id,
      blocks
    }, {
      F: __dxlog_file5,
      L: 73,
      S: this,
      C: (f, a) => f(...a)
    });
    if (blocks.length === 0) {
      invariant3(this._orama, "Index is not initialized", {
        F: __dxlog_file5,
        L: 75,
        S: this,
        A: [
          "this._orama",
          "'Index is not initialized'"
        ]
      });
      await Orama2.remove(this._orama, id);
      return true;
    }
    const embeddings = await this._extractor.extract(blocks);
    invariant3(embeddings.length === 1, "Vectors must be combined", {
      F: __dxlog_file5,
      L: 81,
      S: this,
      A: [
        "embeddings.length === 1",
        "'Vectors must be combined'"
      ]
    });
    invariant3(embeddings[0].length === VECTOR_DIMENSION, "Vector dimension mismatch", {
      F: __dxlog_file5,
      L: 82,
      S: this,
      A: [
        "embeddings[0].length === VECTOR_DIMENSION",
        "'Vector dimension mismatch'"
      ]
    });
    invariant3(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 84,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama2.remove(this._orama, id);
    await Orama2.insert(this._orama, {
      id,
      embedding: embeddings[0]
    });
    return true;
  }
  async remove(id) {
    invariant3(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 94,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    await Orama2.remove(this._orama, id);
  }
  async find(filter) {
    invariant3(filter.typenames.length === 0, "Typenames are not supported", {
      F: __dxlog_file5,
      L: 100,
      S: this,
      A: [
        "filter.typenames.length === 0",
        "'Typenames are not supported'"
      ]
    });
    invariant3(!filter.inverted, "Inverted search is not supported", {
      F: __dxlog_file5,
      L: 101,
      S: this,
      A: [
        "!filter.inverted",
        "'Inverted search is not supported'"
      ]
    });
    invariant3(!filter.graph, "Graph search is not supported", {
      F: __dxlog_file5,
      L: 102,
      S: this,
      A: [
        "!filter.graph",
        "'Graph search is not supported'"
      ]
    });
    invariant3(typeof filter.text?.query === "string", void 0, {
      F: __dxlog_file5,
      L: 103,
      S: this,
      A: [
        "typeof filter.text?.query === 'string'",
        ""
      ]
    });
    invariant3(filter.text?.kind === "vector", void 0, {
      F: __dxlog_file5,
      L: 104,
      S: this,
      A: [
        "filter.text?.kind === 'vector'",
        ""
      ]
    });
    const embeddings = await this._extractor.extract([
      {
        content: filter.text.query
      }
    ]);
    invariant3(embeddings.length === 1, "Vectors must be combined", {
      F: __dxlog_file5,
      L: 107,
      S: this,
      A: [
        "embeddings.length === 1",
        "'Vectors must be combined'"
      ]
    });
    invariant3(embeddings[0].length === VECTOR_DIMENSION, "Vector dimension mismatch", {
      F: __dxlog_file5,
      L: 108,
      S: this,
      A: [
        "embeddings[0].length === VECTOR_DIMENSION",
        "'Vector dimension mismatch'"
      ]
    });
    invariant3(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 110,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    const results = await Orama2.search(this._orama, {
      mode: "vector",
      vector: {
        value: embeddings[0],
        property: "embedding"
      },
      // TODO(dmaretskyi): Add a way to configure these.
      similarity: 0.2,
      includeVectors: true,
      limit: 10,
      offset: 0
    });
    log4.info("Vector search results", {
      query: filter.text.query,
      results
    }, {
      F: __dxlog_file5,
      L: 125,
      S: this,
      C: (f, a) => f(...a)
    });
    return results.hits.map((hit) => ({
      id: hit.id,
      rank: hit.score
    }));
  }
  async serialize() {
    invariant3(this._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 135,
      S: this,
      A: [
        "this._orama",
        "'Index is not initialized'"
      ]
    });
    return JSON.stringify(await Orama2.save(this._orama), null, 2);
  }
  static async load({ serialized, identifier }) {
    const deserialized = JSON.parse(serialized);
    const index = new _IndexVector();
    await index.open();
    invariant3(index._orama, "Index is not initialized", {
      F: __dxlog_file5,
      L: 145,
      S: this,
      A: [
        "index._orama",
        "'Index is not initialized'"
      ]
    });
    index._identifier = identifier;
    await Orama2.load(index._orama, deserialized);
    return index;
  }
};
_ts_decorate4([
  trace4.span({
    showInBrowserTimeline: true
  })
], IndexVector.prototype, "update", null);
_ts_decorate4([
  trace4.span({
    showInBrowserTimeline: true
  })
], IndexVector.prototype, "find", null);
_ts_decorate4([
  trace4.span({
    showInBrowserTimeline: true
  })
], IndexVector.prototype, "serialize", null);
_ts_decorate4([
  trace4.span({
    showInBrowserTimeline: true
  })
], IndexVector, "load", null);
IndexVector = _ts_decorate4([
  trace4.resource(),
  staticImplements()
], IndexVector);

// packages/core/echo/indexing/src/indexes/index-constructors.ts
var IndexConstructors = {
  [IndexKind5.Kind.SCHEMA_MATCH]: IndexSchema,
  [IndexKind5.Kind.GRAPH]: IndexGraph,
  [IndexKind5.Kind.VECTOR]: IndexVector,
  [IndexKind5.Kind.FULL_TEXT]: IndexText
};

// packages/core/echo/indexing/src/indexing-engine.ts
import { synchronized } from "@dxos/async";
import { Resource as Resource6 } from "@dxos/context";
import { invariant as invariant4 } from "@dxos/invariant";
import { log as log5 } from "@dxos/log";
import { IndexKind as IndexKind6 } from "@dxos/protocols/proto/dxos/echo/indexing";
import { trace as trace5 } from "@dxos/tracing";
import { ComplexMap } from "@dxos/util";
function _ts_decorate5(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file6 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexing-engine.ts";
var IndexingEngine = class extends Resource6 {
  constructor(options) {
    super();
    /**
    * Indexes that are kept in-sync with the documents and are serialized to disk.
    */
    this._indexes = new ComplexMap((kind) => kind.kind === IndexKind6.Kind.FIELD_MATCH ? `${kind.kind}:${kind.field}` : kind.kind);
    /**
    * Indexes that were recently created and might not be fully caught up with the documents.
    * They are not serialized to disk until they are promoted.
    *
    * This separation is needed because the tracking of processed documents is done globally and not per-index.
    * This means that all indexes will be updated with the same documents in lockstep.
    * This also means that newly created indexes cannot be saved to disk until they have processed all clean documents.
    */
    this._newIndexes = [];
    this._db = options.db;
    this._metadataStore = options.metadataStore;
    this._indexStore = options.indexStore;
    this._documentLoader = options.documentLoader;
  }
  async _open(ctx) {
  }
  async _close(ctx) {
    for (const index of this._indexes.values()) {
      await index.close();
    }
    this._newIndexes.length = 0;
    this._indexes.clear();
  }
  get indexKinds() {
    return [
      ...this._indexes.keys()
    ];
  }
  get indexes() {
    return [
      ...this._indexes.values()
    ];
  }
  get newIndexCount() {
    return this._newIndexes.length;
  }
  getIndex(kind) {
    return this._indexes.get(kind);
  }
  deleteIndex(kind) {
    this._indexes.delete(kind);
  }
  async addPersistentIndex(index) {
    this._indexes.set(index.kind, index);
    await index.open();
  }
  async addNewIndex(index) {
    this._newIndexes.push(index);
    await index.open();
  }
  async loadIndexKindsFromDisk() {
    return this._indexStore.loadIndexKindsFromDisk();
  }
  async loadIndexFromDisk(identifier) {
    const index = await this._indexStore.load(identifier);
    this._indexes.set(index.kind, index);
    await index.open();
  }
  async removeIndexFromDisk(identifier) {
    await this._indexStore.remove(identifier);
  }
  /**
  * Promotes new indexes to the main indexes.
  */
  async promoteNewIndexes() {
    const documentsToIndex = await this._metadataStore.getAllIndexedDocuments();
    for await (const documents of this._documentLoader.loadDocuments(documentsToIndex)) {
      if (this._ctx.disposed) {
        return;
      }
      await this._updateIndexes(this._newIndexes, documents);
    }
    this._newIndexes.forEach((index) => this._indexes.set(index.kind, index));
    this._newIndexes.length = 0;
    await this._saveIndexes();
  }
  /**
  * Indexes updated objects.
  * @returns completed - whether the indexing was completed
  * @returns updated - whether the indexing updated any indexes
  */
  async indexUpdatedObjects(options) {
    let completed = true;
    let updated = false;
    if (this._ctx.disposed) {
      return {
        completed,
        updated
      };
    }
    const idToHeads = await this._metadataStore.getDirtyDocuments();
    log5("dirty objects to index", {
      count: idToHeads.size
    }, {
      F: __dxlog_file6,
      L: 162,
      S: this,
      C: (f, a) => f(...a)
    });
    if (idToHeads.size === 0 || this._ctx.disposed) {
      return {
        completed,
        updated
      };
    }
    const startTime = Date.now();
    const documentsUpdated = [];
    const saveIndexChanges = async () => {
      log5("Saving index changes", {
        count: documentsUpdated.length,
        timeSinceStart: Date.now() - startTime
      }, {
        F: __dxlog_file6,
        L: 170,
        S: this,
        C: (f, a) => f(...a)
      });
      await this._saveIndexes();
      const batch = this._db.batch();
      this._metadataStore.markClean(new Map(documentsUpdated.map((document) => [
        document.id,
        document.heads
      ])), batch);
      await batch.write();
    };
    const updates = [];
    for await (const documents of this._documentLoader.loadDocuments(idToHeads)) {
      if (this._ctx.disposed) {
        return {
          completed,
          updated
        };
      }
      updates.push(...await this._updateIndexes(Array.from(this._indexes.values()), documents));
      documentsUpdated.push(...documents);
      if (documentsUpdated.length >= options.indexUpdateBatchSize) {
        await saveIndexChanges();
        documentsUpdated.length = 0;
      }
      if (Date.now() - startTime > options.indexTimeBudget) {
        if (documentsUpdated.length > 0) {
          await saveIndexChanges();
        }
        log5("Indexing time budget exceeded", {
          time: Date.now() - startTime
        }, {
          F: __dxlog_file6,
          L: 192,
          S: this,
          C: (f, a) => f(...a)
        });
        completed = false;
        break;
      }
    }
    await saveIndexChanges();
    if (updates.some(Boolean)) {
      updated = true;
    }
    log5("Indexing finished", {
      time: Date.now() - startTime
    }, {
      F: __dxlog_file6,
      L: 202,
      S: this,
      C: (f, a) => f(...a)
    });
    return {
      completed,
      updated
    };
  }
  async _updateIndexes(indexes, documents) {
    const updates = [];
    for (const index of indexes) {
      if (this._ctx.disposed) {
        return updates;
      }
      switch (index.kind.kind) {
        case IndexKind6.Kind.FIELD_MATCH:
          invariant4(index.kind.field, "Field match index kind should have a field", {
            F: __dxlog_file6,
            L: 215,
            S: this,
            A: [
              "index.kind.field",
              "'Field match index kind should have a field'"
            ]
          });
          updates.push(...await updateIndexWithObjects(index, documents.filter((document) => index.kind.field in document.object)));
          break;
        case IndexKind6.Kind.SCHEMA_MATCH:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
        case IndexKind6.Kind.GRAPH:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
        case IndexKind6.Kind.VECTOR:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
        case IndexKind6.Kind.FULL_TEXT:
          updates.push(...await updateIndexWithObjects(index, documents));
          break;
      }
    }
    return updates;
  }
  async _saveIndexes() {
    for (const index of this._indexes.values()) {
      if (this._ctx.disposed) {
        return;
      }
      await this._indexStore.save(index);
    }
  }
};
_ts_decorate5([
  trace5.span({
    showInBrowserTimeline: true
  })
], IndexingEngine.prototype, "promoteNewIndexes", null);
_ts_decorate5([
  trace5.span({
    showInBrowserTimeline: true
  })
], IndexingEngine.prototype, "indexUpdatedObjects", null);
_ts_decorate5([
  trace5.span({
    showInBrowserTimeline: true
  })
], IndexingEngine.prototype, "_updateIndexes", null);
_ts_decorate5([
  trace5.span({
    showInBrowserTimeline: true
  }),
  synchronized
], IndexingEngine.prototype, "_saveIndexes", null);
var updateIndexWithObjects = async (index, snapshots) => Promise.all(snapshots.map((snapshot) => index.update(snapshot.id, snapshot.object)));

// packages/core/echo/indexing/src/indexer.ts
function _ts_decorate6(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file7 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/indexer.ts";
var DEFAULT_INDEX_UPDATE_BATCH_SIZE = 100;
var DEFAULT_INDEX_COOLDOWN_TIME = 100;
var DEFAULT_INDEX_TIME_BUDGET = 300;
var Indexer = class extends Resource7 {
  constructor({ db, metadataStore, indexStore, loadDocuments, indexUpdateBatchSize = DEFAULT_INDEX_UPDATE_BATCH_SIZE, indexCooldownTime = DEFAULT_INDEX_COOLDOWN_TIME, indexTimeBudget = DEFAULT_INDEX_TIME_BUDGET }) {
    super();
    this.updated = new Event5();
    this._lastRunFinishedAt = 0;
    this._db = db;
    this._metadataStore = metadataStore;
    this._indexUpdateBatchSize = indexUpdateBatchSize;
    this._indexCooldownTime = indexCooldownTime;
    this._indexTimeBudget = indexTimeBudget;
    this._engine = new IndexingEngine({
      db,
      metadataStore,
      indexStore,
      documentLoader: {
        loadDocuments
      }
    });
  }
  get initialized() {
    return this._lifecycleState === LifecycleState.OPEN;
  }
  async setConfig(config) {
    this._indexConfig = config;
    if (this._lifecycleState === LifecycleState.OPEN) {
      log6.warn("Setting index config after initialization, this is unstable", {
        config
      }, {
        F: __dxlog_file7,
        L: 105,
        S: this,
        C: (f, a) => f(...a)
      });
      for (const kind of this._engine.indexKinds) {
        if (!config.indexes?.some((kind2) => isEqual(kind2, kind2))) {
          this._engine.deleteIndex(kind);
        }
      }
      await this._loadIndexes();
      this._run.schedule();
    }
  }
  async _open(ctx) {
    if (!this._indexConfig) {
      log6.warn("Index config is not set", void 0, {
        F: __dxlog_file7,
        L: 119,
        S: this,
        C: (f, a) => f(...a)
      });
    }
    await this._engine.open(ctx);
    this._run = new DeferredTask(this._ctx, async () => {
      try {
        if (this._lifecycleState !== LifecycleState.OPEN || this._indexConfig?.enabled !== true) {
          return;
        }
        const cooldownMs = this._lastRunFinishedAt + this._indexCooldownTime - Date.now();
        if (cooldownMs > 0) {
          await sleepWithContext(this._ctx, cooldownMs);
        }
        if (this._engine.newIndexCount > 0) {
          await this._promoteNewIndexes();
        }
        await this._indexUpdatedObjects();
      } finally {
        this._lastRunFinishedAt = Date.now();
      }
    });
    await this._loadIndexes();
    if (this._indexConfig?.enabled === true) {
      this._metadataStore.dirty.on(this._ctx, () => this._run.schedule());
      this._run.schedule();
    }
  }
  async _close(ctx) {
    await this._run.join();
    await this._engine.close(ctx);
  }
  async _catch(err) {
    log6.catch(err, void 0, {
      F: __dxlog_file7,
      L: 162,
      S: this,
      C: (f, a) => f(...a)
    });
  }
  // TODO(dmaretskyi): Allow consumers to get specific index instances and query them directly.
  async execQuery(filter) {
    if (this._lifecycleState !== LifecycleState.OPEN || this._indexConfig?.enabled !== true) {
      throw new Error("Indexer is not initialized or not enabled");
    }
    if (filter.graph) {
      const graphIndex = this._engine.getIndex({
        kind: IndexKind7.Kind.GRAPH
      });
      if (!graphIndex) {
        return [];
      }
      return graphIndex.find(filter);
    } else if (filter.text?.kind === "vector") {
      const vectorIndex = this._engine.getIndex({
        kind: IndexKind7.Kind.VECTOR
      });
      if (!vectorIndex) {
        return [];
      }
      return vectorIndex.find(filter);
    } else if (filter.text?.kind === "text") {
      const textIndex = this._engine.getIndex({
        kind: IndexKind7.Kind.FULL_TEXT
      });
      if (!textIndex) {
        return [];
      }
      return textIndex.find(filter);
    } else {
      const typenameIndex = this._engine.getIndex({
        kind: IndexKind7.Kind.SCHEMA_MATCH
      });
      if (!typenameIndex) {
        return [];
      }
      return typenameIndex.find(filter);
    }
  }
  async reindex(idToHeads) {
    const batch = this._db.batch();
    this._metadataStore.markDirty(idToHeads, batch);
    this._metadataStore.dropFromClean(Array.from(idToHeads.keys()), batch);
    await batch.write();
    await this._run.runBlocking();
  }
  /**
  * Perform any pending index updates.
  */
  async updateIndexes() {
    await this._run.runBlocking();
  }
  async _loadIndexes() {
    const kinds = await this._engine.loadIndexKindsFromDisk();
    for (const [identifier, kind] of kinds.entries()) {
      if (!this._indexConfig || this._indexConfig.indexes?.some((configKind) => isEqual(configKind, kind))) {
        try {
          await this._engine.loadIndexFromDisk(identifier);
        } catch (err) {
          log6.warn("Failed to load index", {
            err,
            identifier
          }, {
            F: __dxlog_file7,
            L: 227,
            S: this,
            C: (f, a) => f(...a)
          });
        }
      } else {
        await this._engine.removeIndexFromDisk(identifier);
      }
    }
    for (const kind of this._indexConfig?.indexes || []) {
      if (!this._engine.getIndex(kind)) {
        const IndexConstructor = IndexConstructors[kind.kind];
        invariant5(IndexConstructor, `Index kind ${kind.kind} is not supported`, {
          F: __dxlog_file7,
          L: 240,
          S: this,
          A: [
            "IndexConstructor",
            "`Index kind ${kind.kind} is not supported`"
          ]
        });
        await this._engine.addNewIndex(new IndexConstructor(kind));
      }
    }
  }
  async _promoteNewIndexes() {
    await this._engine.promoteNewIndexes();
    this.updated.emit();
  }
  async _indexUpdatedObjects() {
    if (this._ctx.disposed) {
      return;
    }
    const { completed, updated } = await this._engine.indexUpdatedObjects({
      indexTimeBudget: this._indexTimeBudget,
      indexUpdateBatchSize: this._indexUpdateBatchSize
    });
    if (!completed) {
      this._run.schedule();
    }
    if (updated) {
      this.updated.emit();
    }
  }
};
_ts_decorate6([
  synchronized2
], Indexer.prototype, "setConfig", null);
_ts_decorate6([
  trace6.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "_open", null);
_ts_decorate6([
  synchronized2
], Indexer.prototype, "execQuery", null);
_ts_decorate6([
  trace6.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "reindex", null);
_ts_decorate6([
  trace6.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "_promoteNewIndexes", null);
_ts_decorate6([
  trace6.span({
    showInBrowserTimeline: true
  })
], Indexer.prototype, "_indexUpdatedObjects", null);
Indexer = _ts_decorate6([
  trace6.resource()
], Indexer);

// packages/core/echo/indexing/src/store/index-store.ts
import isEqual2 from "lodash.isequal";
import { invariant as invariant6 } from "@dxos/invariant";
import { trace as trace7 } from "@dxos/tracing";
var __dxlog_file8 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/store/index-store.ts";
var CODEC_VERSION = 2;
var IndexStore = class {
  constructor({ db }) {
    this._db = db;
    trace7.diagnostic({
      id: "indexes",
      name: "Indexes",
      fetch: async () => {
        const indexes = await this._db.iterator(encodings).all();
        return indexes.map(([identifier, { index, ...rest }]) => ({
          identifier,
          ...rest
        }));
      }
    });
  }
  async save(index) {
    await this._db.put(index.identifier, await indexCodec.encode(index), encodings);
  }
  async load(identifier) {
    const data = await this._db.get(identifier, encodings);
    return indexCodec.decode(identifier, data);
  }
  async remove(identifier) {
    await this._db.del(identifier, encodings);
  }
  /**
  *
  * @returns Map of index identifiers vs their kinds.
  */
  async loadIndexKindsFromDisk() {
    const kinds = /* @__PURE__ */ new Map();
    for await (const [identifier, data] of this._db.iterator(encodings)) {
      data.kind && kinds.set(identifier, data.kind);
    }
    {
      const seenKinds = [];
      const allKinds = Array.from(kinds.values());
      for (const kind of allKinds) {
        if (!seenKinds.some((seenKind) => isEqual2(seenKind, kind))) {
          seenKinds.push(kind);
          continue;
        }
        const entries2 = Array.from(kinds.entries());
        for (const [identifier, indexKind] of entries2) {
          if (isEqual2(indexKind, kind)) {
            await this.remove(identifier);
            kinds.delete(identifier);
          }
        }
      }
    }
    return kinds;
  }
};
var encodings = {
  keyEncoding: "utf8",
  valueEncoding: "json"
};
var indexCodec = {
  encode: async (index) => {
    return {
      index: await index.serialize(),
      kind: index.kind,
      version: CODEC_VERSION
    };
  },
  decode: async (identifier, data) => {
    invariant6(data.version === CODEC_VERSION, `Index version ${data.version} is not supported`, {
      F: __dxlog_file8,
      L: 105,
      S: void 0,
      A: [
        "data.version === CODEC_VERSION",
        "`Index version ${data.version} is not supported`"
      ]
    });
    const IndexConstructor = IndexConstructors[data.kind.kind];
    invariant6(IndexConstructor, `Index kind ${data.kind.kind} is not supported`, {
      F: __dxlog_file8,
      L: 107,
      S: void 0,
      A: [
        "IndexConstructor",
        "`Index kind ${data.kind.kind} is not supported`"
      ]
    });
    return IndexConstructor.load({
      serialized: data.index,
      indexKind: data.kind,
      identifier
    });
  }
};

// packages/core/echo/indexing/src/store/index-metadata-store.ts
import { Event as Event6 } from "@dxos/async";
import { invariant as invariant7 } from "@dxos/invariant";
import { log as log7 } from "@dxos/log";
import { objectPointerCodec } from "@dxos/protocols";
import { schema } from "@dxos/protocols/proto";
import { trace as trace8 } from "@dxos/tracing";
import { joinTables } from "@dxos/util";
function _ts_decorate7(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
var __dxlog_file9 = "/home/runner/work/dxos/dxos/packages/core/echo/indexing/src/store/index-metadata-store.ts";
var IndexMetadataStore = class {
  constructor({ db }) {
    this.dirty = new Event6();
    this.clean = new Event6();
    this._lastSeen = db.sublevel("last-seen", {
      valueEncoding: headsEncoding,
      keyEncoding: "utf8"
    });
    this._lastIndexed = db.sublevel("last-indexed", {
      valueEncoding: headsEncoding,
      keyEncoding: "utf8"
    });
    trace8.diagnostic({
      id: "indexed-documents",
      name: "Indexed Documents",
      fetch: async () => {
        const [dirty, indexed] = await Promise.all([
          this.getDirtyDocuments(),
          this.getAllIndexedDocuments()
        ]);
        return joinTables("id", "id", Array.from(dirty.entries()).map(([id, heads]) => ({
          id,
          dirtyHeads: heads.join(",")
        })), Array.from(indexed.entries()).map(([id, heads]) => ({
          id,
          indexedHeads: heads.join(",")
        })));
      }
    });
  }
  async getDirtyDocuments() {
    return new Map(await this._lastSeen.iterator({}).all());
  }
  /**
  * @returns All document id's that were already indexed. May include dirty documents.
  */
  async getAllIndexedDocuments() {
    return new Map(await this._lastIndexed.iterator({}).all());
  }
  markDirty(idToHeads, batch) {
    log7("mark dirty", {
      count: idToHeads.size
    }, {
      F: __dxlog_file9,
      L: 76,
      S: this,
      C: (f, a) => f(...a)
    });
    for (const [id, heads] of idToHeads.entries()) {
      batch.put(id, heads, {
        sublevel: this._lastSeen,
        valueEncoding: headsEncoding
      });
      batch.del(objectPointerCodec.convertV1ToV0(id), {
        sublevel: this._lastIndexed
      });
    }
  }
  /**
  * Called after leveldb batch commit.
  */
  notifyMarkedDirty() {
    this.dirty.emit();
  }
  markClean(idToHeads, batch) {
    log7("mark clean", {
      count: idToHeads.size
    }, {
      F: __dxlog_file9,
      L: 94,
      S: this,
      C: (f, a) => f(...a)
    });
    for (const [id, heads] of idToHeads.entries()) {
      batch.put(id, heads, {
        sublevel: this._lastIndexed,
        valueEncoding: headsEncoding
      });
      batch.del(id, {
        sublevel: this._lastSeen
      });
      batch.del(objectPointerCodec.convertV1ToV0(id), {
        sublevel: this._lastIndexed
      });
      batch.del(objectPointerCodec.convertV1ToV0(id), {
        sublevel: this._lastSeen
      });
    }
  }
  /**
  * Called on re-indexing.
  */
  dropFromClean(ids, batch) {
    for (const id of ids) {
      batch.del(id, {
        sublevel: this._lastIndexed
      });
    }
  }
};
_ts_decorate7([
  trace8.span({
    showInBrowserTimeline: true
  })
], IndexMetadataStore.prototype, "getDirtyDocuments", null);
_ts_decorate7([
  trace8.span({
    showInBrowserTimeline: true
  })
], IndexMetadataStore.prototype, "markDirty", null);
_ts_decorate7([
  trace8.span({
    showInBrowserTimeline: true
  })
], IndexMetadataStore.prototype, "markClean", null);
IndexMetadataStore = _ts_decorate7([
  trace8.resource()
], IndexMetadataStore);
var headsCodec;
var getHeadsCodec = () => headsCodec ??= schema.getCodecForType("dxos.echo.query.Heads");
var showedWarning = false;
var headsEncoding = {
  encode: (value) => getHeadsCodec().encode({
    hashes: value
  }),
  decode: (encodedValue) => {
    try {
      return getHeadsCodec().decode(encodedValue).hashes;
    } catch (err) {
      if (!showedWarning) {
        showedWarning = true;
        log7.warn("Detected legacy encoding of heads in the indexer. \nRun `await dxos.client.repair()`", void 0, {
          F: __dxlog_file9,
          L: 130,
          S: void 0,
          C: (f, a) => f(...a)
        });
      }
      const concatenatedHeads = Buffer.from(encodedValue).toString("utf8").replace(/"/g, "");
      invariant7(concatenatedHeads.length % 64 === 0, "Invalid concatenated heads length", {
        F: __dxlog_file9,
        L: 138,
        S: void 0,
        A: [
          "concatenatedHeads.length % 64 === 0",
          "'Invalid concatenated heads length'"
        ]
      });
      const heads = [];
      for (let i = 0; i < concatenatedHeads.length; i += 64) {
        heads.push(concatenatedHeads.slice(i, i + 64));
      }
      return heads;
    }
  },
  format: "buffer"
};
export {
  EscapedPropPath,
  IndexMetadataStore,
  IndexStore,
  Indexer,
  headsEncoding,
  staticImplements
};
//# sourceMappingURL=index.mjs.map
